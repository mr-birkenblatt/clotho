# pylint: disable=multiple-statements,unused-argument,invalid-name
# pylint: disable=too-few-public-methods,useless-import-alias,unused-import
# pylint: disable=redefined-builtin,super-init-not-called,arguments-renamed
# pylint: disable=abstract-method,too-many-ancestors,import-error
# pylint: disable=relative-beyond-top-level,redefined-outer-name
# pylint: disable=arguments-differ,no-member,keyword-arg-before-vararg
# pylint: disable=signature-differs,blacklisted-name,c-extension-no-member
# pylint: disable=protected-access


from typing import List

import torch
from _typeshed import Incomplete
from torch import Tensor as Tensor
from torch._ops import ops as ops


class FloatFunctional(torch.nn.Module):
    activation_post_process: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x) -> None: ...
    def add(self, x: Tensor, y: Tensor) -> Tensor: ...
    def add_scalar(self, x: Tensor, y: float) -> Tensor: ...
    def mul(self, x: Tensor, y: Tensor) -> Tensor: ...
    def mul_scalar(self, x: Tensor, y: float) -> Tensor: ...
    def cat(self, x: List[Tensor], dim: int = ...) -> Tensor: ...
    def add_relu(self, x: Tensor, y: Tensor) -> Tensor: ...


class FXFloatFunctional(torch.nn.Module):
    def forward(self, x) -> None: ...
    def add(self, x: Tensor, y: Tensor) -> Tensor: ...
    def add_scalar(self, x: Tensor, y: float) -> Tensor: ...
    def mul(self, x: Tensor, y: Tensor) -> Tensor: ...
    def mul_scalar(self, x: Tensor, y: float) -> Tensor: ...
    def cat(self, x: List[Tensor], dim: int = ...) -> Tensor: ...
    def add_relu(self, x: Tensor, y: Tensor) -> Tensor: ...


class QFunctional(torch.nn.Module):
    scale: float
    zero_point: int
    activation_post_process: Incomplete
    def __init__(self) -> None: ...
    def extra_repr(self): ...
    def forward(self, x) -> None: ...
    def add(self, x: Tensor, y: Tensor) -> Tensor: ...
    def add_scalar(self, x: Tensor, y: float) -> Tensor: ...
    def mul(self, x: Tensor, y: Tensor) -> Tensor: ...
    def mul_scalar(self, x: Tensor, y: float) -> Tensor: ...
    def cat(self, x: List[Tensor], dim: int = ...) -> Tensor: ...
    def add_relu(self, x: Tensor, y: Tensor) -> Tensor: ...
    @classmethod
    def from_float(cls, mod): ...
