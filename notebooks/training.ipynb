{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1265ba-c76b-4424-b577-a322e6b512af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a terminal run\n",
    "# > make run-redis NS=train\n",
    "# > make run-redis NS=test\n",
    "# to allow access to the train and test namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e21c530-5f85-4b18-b9ed-c2fbe591b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62721599-23d3-405a-bbb2-88a6f0a17a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "os.environ[\"USER_PATH\"] = \"../userdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c6f1c7-607b-479d-b2f6-3483cb91a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.redis import set_redis_slow_mode\n",
    "from misc.util import highest_number\n",
    "from model.datagenerator import create_train_test\n",
    "from system.namespace.store import get_namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8c7e9a-fa89-435d-a0a2-0a492056581e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a897205-0707-4928-860d-5e8d58cef31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_redis_slow_mode(\"never\")\n",
    "ns_test = get_namespace(\"test\")\n",
    "ns_train = get_namespace(\"train\")\n",
    "now = pd.Timestamp(\"2022-12-17\", tz=\"UTC\")\n",
    "train_plan = [\n",
    "    {\n",
    "        \"left\": {\"mode\": \"valid\", \"flip_pc\": 0.5},\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": 20,\n",
    "        \"skip_weak\": False,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"first_epoch\": 10,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"left\": {\"mode\": \"valid\", \"flip_pc\": 0.5},\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": None,\n",
    "        \"skip_weak\": True,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"first_epoch\": 10,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"left\": {\"mode\": \"random\", \"flip_pc\": 0.0},\n",
    "        \"right\": {\"mode\": \"path\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": 20,\n",
    "        \"skip_weak\": False,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"first_epoch\": None,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 60,\n",
    "    },\n",
    "    {\n",
    "        \"left\": None,\n",
    "        \"right\": {\"mode\": \"path\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": 20,\n",
    "        \"skip_weak\": False,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"first_epoch\": None,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 40,\n",
    "    },\n",
    "     {\n",
    "        \"left\": {\"mode\": \"random\", \"flip_pc\": 0.0},\n",
    "        \"right\": {\"mode\": \"path\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": None,\n",
    "        \"skip_weak\": True,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"first_epoch\": 5,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 60,\n",
    "    },\n",
    "    {\n",
    "        \"left\": None,\n",
    "        \"right\": {\"mode\": \"path\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": None,\n",
    "        \"skip_weak\": True,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"first_epoch\": 5,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 40,\n",
    "    },\n",
    "    {\n",
    "        \"left\": {\"mode\": \"random\", \"flip_pc\": 0.0},\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": None,\n",
    "        \"skip_weak\": True,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"first_epoch\": None,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 60,\n",
    "    },\n",
    "    {\n",
    "        \"left\": None,\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": None,\n",
    "        \"skip_weak\": True,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"first_epoch\": None,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 40,\n",
    "    },\n",
    "    {\n",
    "        \"left\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": None,\n",
    "        \"skip_weak\": False,\n",
    "        \"flip_lr\": 0,\n",
    "        \"first_epoch\": 15,\n",
    "        \"last_epoch\": None,\n",
    "        \"weight\": 50,\n",
    "    }\n",
    "]\n",
    "eval_plan = [\n",
    "    {\n",
    "        \"left\": {\"mode\": \"random\", \"flip_pc\": 0.0},\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": 20,\n",
    "        \"skip_weak\": False,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"weight\": 60,\n",
    "    },\n",
    "    {\n",
    "        \"left\": None,\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": 20,\n",
    "        \"skip_weak\": False,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"weight\": 40,\n",
    "    },\n",
    "    {\n",
    "        \"left\": {\"mode\": \"random\", \"flip_pc\": 0.0},\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": None,\n",
    "        \"skip_weak\": True,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"weight\": 60,\n",
    "    },\n",
    "    {\n",
    "        \"left\": None,\n",
    "        \"right\": {\"mode\": \"valid\", \"flip_pc\": 0.0},\n",
    "        \"min_text_length\": None,\n",
    "        \"skip_weak\": True,\n",
    "        \"flip_lr\": 0.5,\n",
    "        \"weight\": 40,\n",
    "    },\n",
    "]\n",
    "ttgen = create_train_test(\n",
    "    train_ns=ns_train,\n",
    "    train_validation_ns=ns_train,\n",
    "    test_ns=ns_test,\n",
    "    test_validation_ns=ns_test,\n",
    "    train_learning_plan=train_plan,\n",
    "    train_val_learning_plan=eval_plan,\n",
    "    test_learning_plan=eval_plan,\n",
    "    test_val_learning_plan=eval_plan,\n",
    "    batch_size=4 if is_cuda else 8,\n",
    "    epoch_batches=5000 if is_cuda else 500,\n",
    "    train_val_size=10000 if is_cuda else 1000,\n",
    "    test_size=10000 if is_cuda else 1000,\n",
    "    test_val_size=10000 if is_cuda else 1000,\n",
    "    compute_batch_size=100 if is_cuda else 100,\n",
    "    now=now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7acd4d-0d4a-481f-901b-3e524ee02c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927dbcbe-6df3-49c9-8449-041b1ab7a168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if is_cuda else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00819f53-a953-4b85-bcf8-6cba59a8bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypedDict\n",
    "\n",
    "ProviderRole = Literal[\"child\", \"parent\"]\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "EMBED_SIZE = 768\n",
    "\n",
    "TokenizedInput = TypedDict('TokenizedInput', {\n",
    "    \"input_ids\": torch.Tensor,\n",
    "    \"attention_mask\": torch.Tensor,\n",
    "})\n",
    "\n",
    "\n",
    "def tokens(texts: list[str]) -> TokenizedInput:\n",
    "    res = tokenizer(texts.tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    return {k: v.to(device) for k, v in res.items()}\n",
    "\n",
    "\n",
    "class Noise(nn.Module):\n",
    "    def __init__(self, std: float = 1.0, p: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self._std = std\n",
    "        self._dropout = nn.Dropout(p)\n",
    "        self._dhold = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "    def set_std(self, std: float) -> None:\n",
    "        self._std = std\n",
    "\n",
    "    def get_std(self) -> float:\n",
    "        return self._std\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.training:\n",
    "            return x\n",
    "        return x + self._dropout(torch.normal(\n",
    "            mean=0.0, std=self._std, size=x.shape, device=self._dhold.device))\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, version: int) -> None:\n",
    "        super().__init__()\n",
    "        self._bert_parent = DistilBertModel.from_pretrained(\n",
    "            \"distilbert-base-uncased\")\n",
    "        self._bert_child = DistilBertModel.from_pretrained(\n",
    "            \"distilbert-base-uncased\")\n",
    "        if version == 1 or version >= 3:\n",
    "            self._pdense: nn.Sequential | None = nn.Sequential(\n",
    "                nn.Linear(EMBED_SIZE, EMBED_SIZE),\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(EMBED_SIZE, EMBED_SIZE))\n",
    "            self._cdense: nn.Sequential | None = nn.Sequential(\n",
    "                nn.Linear(EMBED_SIZE, EMBED_SIZE),\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(EMBED_SIZE, EMBED_SIZE))\n",
    "        else:\n",
    "            self._pdense = None\n",
    "            self._cdense = None\n",
    "        if version < 4:\n",
    "            self._noise = None\n",
    "        else:\n",
    "            self._noise = Noise(std=1.0, p=0.5)\n",
    "        if version < 2:\n",
    "            self._cos = None\n",
    "        else:\n",
    "            self._cos = torch.nn.CosineSimilarity()\n",
    "        self._version = version\n",
    "\n",
    "    def set_epoch(self, epoch: int) -> None:\n",
    "        noise = self._noise\n",
    "        if noise is not None:\n",
    "            noise.set_std(1 / (1.2 ** epoch))\n",
    "\n",
    "    def get_version(self) -> int:\n",
    "        return self._version\n",
    "\n",
    "    def get_parent_embed(\n",
    "            self,\n",
    "            input_ids: torch.Tensor,\n",
    "            attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        outputs_parent = self._bert_parent(\n",
    "            input_ids=input_ids, attention_mask=attention_mask)\n",
    "        out = outputs_parent.last_hidden_state[:, 0]\n",
    "        if self._pdense is not None:\n",
    "            out = self._pdense(out)\n",
    "        if self._noise is not None:\n",
    "            out = self._noise(out)\n",
    "        return out\n",
    "\n",
    "    def get_child_embed(\n",
    "            self,\n",
    "            input_ids: torch.Tensor,\n",
    "            attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        outputs_child = self._bert_child(\n",
    "            input_ids=input_ids, attention_mask=attention_mask)\n",
    "        out = outputs_child.last_hidden_state[:, 0]\n",
    "        if self._cdense is not None:\n",
    "            out = self._cdense(out)\n",
    "        if self._noise is not None:\n",
    "            out = self._noise(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x: dict[ProviderRole, TokenizedInput]) -> torch.Tensor:\n",
    "        parent_cls = self.get_parent_embed(\n",
    "            input_ids=x[\"parent\"][\"input_ids\"],\n",
    "            attention_mask=x[\"parent\"][\"attention_mask\"])\n",
    "        child_cls = self.get_child_embed(\n",
    "            input_ids=x[\"child\"][\"input_ids\"],\n",
    "            attention_mask=x[\"child\"][\"attention_mask\"])\n",
    "        if self._cos is not None:\n",
    "            return self._cos(parent_cls, child_cls).reshape([-1, 1])\n",
    "        batch_size = parent_cls.shape[0]\n",
    "        return torch.bmm(\n",
    "            parent_cls.reshape([batch_size, 1, -1]),\n",
    "            child_cls.reshape([batch_size, -1, 1])).reshape([-1, 1])\n",
    "\n",
    "\n",
    "class TrainingHarness(nn.Module):\n",
    "    def __init__(self, model: Model) -> None:\n",
    "        super().__init__()\n",
    "        self._model = model\n",
    "        self._softmax = nn.Softmax(dim=1)\n",
    "        self._loss = nn.BCELoss()\n",
    "\n",
    "    def get_version(self) -> int:\n",
    "        return self._model.get_version()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            left: TokenizedInput,\n",
    "            right: TokenizedInput,\n",
    "            labels: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        out_left = self._model(left)\n",
    "        out_right = self._model(right)\n",
    "        preds = self._softmax(torch.hstack((out_left, out_right)))\n",
    "        return preds, self._loss(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f048a983-9daf-4f04-b36e-5da77951bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('harness_v4_lg_9.pkl', 9), 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "model = Model(version=4)\n",
    "model.to(device)\n",
    "harness = TrainingHarness(model)\n",
    "harness.to(device)\n",
    "\n",
    "FORCE_RESTART = False\n",
    "\n",
    "folder = \"checkpoints\"\n",
    "postfix = \"_lg\" if is_cuda else \"\"\n",
    "version_tag = \"\" if harness.get_version() == 0 else f\"_v{harness.get_version()}\"\n",
    "mprev = highest_number(os.listdir(folder), prefix=f\"harness{version_tag}{postfix}_\", postfix=\".pkl\")\n",
    "if not FORCE_RESTART and mprev is not None:\n",
    "    prev_fname, prev_epoch = mprev\n",
    "    harness.load_state_dict(torch.load(os.path.join(folder, prev_fname), map_location=device))\n",
    "    epoch_offset = prev_epoch + 1\n",
    "else:\n",
    "    epoch_offset = 0\n",
    "\n",
    "optimizer = AdamW(harness.parameters(), lr=5e-5)\n",
    "mprev, epoch_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde9030-931f-4f80-a118-d7f5ef2677d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410e66fd8df84778bc657bcf0e4ee46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_name</th>\n",
       "      <th>parent_left</th>\n",
       "      <th>child_left</th>\n",
       "      <th>parent_right</th>\n",
       "      <th>child_right</th>\n",
       "      <th>sway_left</th>\n",
       "      <th>sway_right</th>\n",
       "      <th>correct_is_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random--path;(sw)</td>\n",
       "      <td>You’re not living in a rural area without some...</td>\n",
       "      <td>I keep hearing people saying release the list ...</td>\n",
       "      <td>t/conservative</td>\n",
       "      <td>[Ellen DeGeneres Woke Animated Show Canceled a...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random--valid;(sw)</td>\n",
       "      <td>I don't care who does it, it should be illegal...</td>\n",
       "      <td>Fucked around, found out. And of course he giv...</td>\n",
       "      <td>[Dmitri Medvedev said that Russia would not st...</td>\n",
       "      <td>Ho ? So the whole NATO story wasn’t the reason...</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.880797</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!valid--valid;(mtl:20)</td>\n",
       "      <td>We don't know whether they were bogus, because...</td>\n",
       "      <td>Because that's the way things are, doesn't mea...</td>\n",
       "      <td>Yeah, shocked a country that has lived under t...</td>\n",
       "      <td>Please be respectful when talking about the Qu...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!valid--valid;(mtl:20)</td>\n",
       "      <td>They are supposed to alarm when you cut them.</td>\n",
       "      <td>&gt;nearly seven hours after Francis is believed ...</td>\n",
       "      <td>No. No it isn't. Change the channel. Also, tru...</td>\n",
       "      <td>AND the democrats refuse to pass anything writ...</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gen_name                                        parent_left  \\\n",
       "0       random--path;(sw)  You’re not living in a rural area without some...   \n",
       "1      random--valid;(sw)  I don't care who does it, it should be illegal...   \n",
       "2  !valid--valid;(mtl:20)  We don't know whether they were bogus, because...   \n",
       "3  !valid--valid;(mtl:20)      They are supposed to alarm when you cut them.   \n",
       "\n",
       "                                          child_left  \\\n",
       "0  I keep hearing people saying release the list ...   \n",
       "1  Fucked around, found out. And of course he giv...   \n",
       "2  Because that's the way things are, doesn't mea...   \n",
       "3  >nearly seven hours after Francis is believed ...   \n",
       "\n",
       "                                        parent_right  \\\n",
       "0                                     t/conservative   \n",
       "1  [Dmitri Medvedev said that Russia would not st...   \n",
       "2  Yeah, shocked a country that has lived under t...   \n",
       "3  No. No it isn't. Change the channel. Also, tru...   \n",
       "\n",
       "                                         child_right  sway_left  sway_right  \\\n",
       "0  [Ellen DeGeneres Woke Animated Show Canceled a...   0.000000    1.000000   \n",
       "1  Ho ? So the whole NATO story wasn’t the reason...   0.119203    0.880797   \n",
       "2  Please be respectful when talking about the Qu...   0.000000    1.000000   \n",
       "3  AND the democrats refuse to pass anything writ...   0.268941    0.731059   \n",
       "\n",
       "   correct_is_right  \n",
       "0              True  \n",
       "1              True  \n",
       "2              True  \n",
       "3              True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "\n",
    "def compute(df):\n",
    "    plefts = tokens(df[\"parent_left\"])\n",
    "    clefts = tokens(df[\"child_left\"])\n",
    "    prights = tokens(df[\"parent_right\"])\n",
    "    crights = tokens(df[\"child_right\"])\n",
    "    labels = torch.tensor([~df[\"correct_is_right\"], df[\"correct_is_right\"]], dtype=torch.float32).T.to(device)\n",
    "    return harness({\"parent\": plefts, \"child\": clefts}, {\"parent\": prights, \"child\": crights}, labels)\n",
    "\n",
    "num_epochs = max((100 if is_cuda else 10) - epoch_offset, 3)\n",
    "num_training_steps = num_epochs * ttgen.get_epoch_train_size()\n",
    "warmup = 10000 if is_cuda else 10\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=warmup,\n",
    "    num_training_steps=num_training_steps - warmup)\n",
    "ttgen.set_epoch(epoch_offset)\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    epoch = ttgen.get_epoch()\n",
    "    print(f\"epoch {epoch}\")\n",
    "    \n",
    "    model.train()\n",
    "    harness.train()\n",
    "    model.set_epoch(epoch)\n",
    "    metric_train = evaluate.load(\"accuracy\")\n",
    "    train_loss = []\n",
    "    first = True\n",
    "    with tqdm(desc=\"train\", total=ttgen.get_epoch_train_size()) as progress_bar:\n",
    "        for train_df in ttgen.train_dfs():\n",
    "            preds, loss = compute(train_df)\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(train_df.shape[0])\n",
    "            \n",
    "            predictions = torch.argmax(preds, dim=-1)\n",
    "            metric_train.add_batch(predictions=predictions, references=train_df[\"correct_is_right\"].astype(int))\n",
    "            if first:\n",
    "                display(train_df)\n",
    "                first = False\n",
    "\n",
    "    folder = \"checkpoints\"\n",
    "    postfix = \"_lg\" if is_cuda else \"\"\n",
    "    version_tag = \"\" if harness.get_version() == 0 else f\"_v{harness.get_version()}\"\n",
    "    torch.save(harness.state_dict(), os.path.join(folder, f\"harness{version_tag}{postfix}_{epoch}.pkl\"))\n",
    "            \n",
    "    model.eval()\n",
    "    harness.eval()\n",
    "    with torch.no_grad():\n",
    "        metric_val_train = evaluate.load(\"accuracy\")\n",
    "        train_val_loss = []\n",
    "        with tqdm(desc=\"train val\", total=ttgen.get_epoch_train_validation_size()) as progress_bar:\n",
    "            for train_validation_df in ttgen.train_validation_dfs():\n",
    "                preds, loss = compute(train_validation_df)\n",
    "                train_val_loss.append(loss.item())\n",
    "                predictions = torch.argmax(preds, dim=-1)\n",
    "                metric_val_train.add_batch(\n",
    "                    predictions=predictions, references=train_validation_df[\"correct_is_right\"].astype(int))\n",
    "                progress_bar.update(train_validation_df.shape[0])\n",
    "        \n",
    "        metric_test = evaluate.load(\"accuracy\")\n",
    "        test_loss = []\n",
    "        with tqdm(desc=\"test\", total=ttgen.get_epoch_test_size()) as progress_bar:\n",
    "            for test_df in ttgen.test_dfs():\n",
    "                preds, loss = compute(test_df)\n",
    "                test_loss.append(loss.item())\n",
    "                predictions = torch.argmax(preds, dim=-1)\n",
    "                metric_test.add_batch(\n",
    "                    predictions=predictions, references=test_df[\"correct_is_right\"].astype(int))\n",
    "                progress_bar.update(test_df.shape[0])\n",
    "        \n",
    "        print(f\"train: {metric_train.compute()} loss: {np.mean(train_loss)}\")\n",
    "        print(f\"train val: {metric_val_train.compute()} loss: {np.mean(train_val_loss)}\")\n",
    "        print(f\"test: {metric_test.compute()} loss: {np.mean(test_loss)}\")\n",
    "    ttgen.advance_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a36224-b91d-4f21-9279-fa7c2a0e862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \".\"\n",
    "postfix = \"_lg\" if is_cuda else \"\"\n",
    "version_tag = \"\" if harness.get_version() == 0 else f\"_v{harness.get_version()}\"\n",
    "torch.save(model.state_dict(), os.path.join(folder, f\"model{version_tag}{postfix}.pkl\"))\n",
    "torch.save(harness.state_dict(), os.path.join(folder, f\"harness{version_tag}{postfix}.pkl\"))\n",
    "torch.save(optimizer.state_dict(), os.path.join(folder, f\"optimizer{version_tag}{postfix}.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff582b9-1447-425a-9b0f-36d9366e4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttgen.reset()\n",
    "model.eval()\n",
    "harness.eval()\n",
    "dfs = []\n",
    "with torch.no_grad():\n",
    "    metric_val_test = evaluate.load(\"accuracy\")\n",
    "    test_val_loss = []\n",
    "    with tqdm(desc=\"test val\", total=ttgen.get_epoch_test_validation_size()) as progress_bar:\n",
    "        for test_val_df in ttgen.test_validation_dfs():\n",
    "            preds, loss = compute(test_val_df)\n",
    "            test_val_loss.append(loss.item())\n",
    "            predictions = torch.argmax(preds, dim=-1)\n",
    "            metric_val_test.add_batch(\n",
    "                predictions=predictions, references=test_val_df[\"correct_is_right\"].astype(int))\n",
    "            cur_df = test_val_df.copy()\n",
    "            cur_df[\"logit_left\"] = preds[:, 0].cpu()\n",
    "            cur_df[\"logit_right\"] = preds[:, 1].cpu()\n",
    "            cur_df[\"preds\"] = predictions.cpu()\n",
    "            cur_df[\"truth\"] = test_val_df[\"correct_is_right\"].astype(int)\n",
    "            dfs.append(cur_df)\n",
    "            progress_bar.update(test_val_df.shape[0])\n",
    "print(f\"test val: {metric_val_test.compute()} loss: {np.mean(test_val_loss)}\")\n",
    "validation_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c3406-9ff3-4576-93c2-daf914f3f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix = \"_lg\" if is_cuda else \"\"\n",
    "version_tag = \"\" if harness.get_version() == 0 else f\"_v{harness.get_version()}\"\n",
    "validation_df.to_csv(os.path.join(folder, f\"validation{version_tag}{postfix}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76f390-5d4c-496c-9f47-4fcab527a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df[validation_df[\"preds\"] == validation_df[\"truth\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb0772-acf6-40c0-aad0-6d2adbfcdadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df[validation_df[\"preds\"] != validation_df[\"truth\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e7f88-ff0c-4bad-bb47-2224bfedbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttgen.reset()\n",
    "model.eval()\n",
    "harness.eval()\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for test_val_df in ttgen.test_validation_dfs():\n",
    "        plefts = tokens(test_val_df[\"parent_left\"])\n",
    "        clefts = tokens(test_val_df[\"child_left\"])\n",
    "        prights = tokens(test_val_df[\"parent_right\"])\n",
    "        crights = tokens(test_val_df[\"child_right\"])\n",
    "        display(model.get_child_embed(\n",
    "            clefts[\"input_ids\"],\n",
    "            clefts[\"attention_mask\"]))\n",
    "        display(model.get_child_embed(\n",
    "            crights[\"input_ids\"],\n",
    "            crights[\"attention_mask\"]))\n",
    "        count += 1\n",
    "        if count >= 5:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:clotho]",
   "language": "python",
   "name": "conda-env-clotho-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
