# pylint: disable=multiple-statements,unused-argument,invalid-name
# pylint: disable=too-few-public-methods,useless-import-alias,unused-import
# pylint: disable=redefined-builtin,super-init-not-called,arguments-renamed
# pylint: disable=abstract-method,too-many-ancestors,import-error
# pylint: disable=relative-beyond-top-level,redefined-outer-name
# pylint: disable=arguments-differ,no-member,keyword-arg-before-vararg
# pylint: disable=signature-differs,blacklisted-name,c-extension-no-member
# pylint: disable=protected-access


from typing import Any, Callable, ClassVar, Dict, Iterable, Iterator, List


        Optional, Tuple

from typing import overload

import numpy
import torch


AVG: torch.AggregationType
CONV_BN_FUSION: torch.MobileOptimizerType
FUSE_ADD_RELU: torch.MobileOptimizerType
HOIST_CONV_PACKED_PARAMS: torch.MobileOptimizerType
INSERT_FOLD_PREPACK_OPS: torch.MobileOptimizerType
REMOVE_DROPOUT: torch.MobileOptimizerType
SUM: torch.AggregationType
_GLIBCXX_USE_CXX11_ABI: bool
_PYBIND11_BUILD_ABI: str
_PYBIND11_COMPILER_TYPE: str
_PYBIND11_STDLIB: str
_VariableFunctions: _VariableFunctionsClass
default_generator: Generator
has_cuda: bool
has_cudnn: bool
has_lapack: bool
has_mkl: bool
has_mkldnn: bool
has_mps: bool
has_openmp: bool
has_spectral: bool


class AggregationType:
    __members__: ClassVar[dict] = ...  # read-only
    AVG: ClassVar[torch.AggregationType] = ...
    SUM: ClassVar[torch.AggregationType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: int) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...


class AliasDb:
    def __init__(self, *args, **kwargs) -> None: ...
    def dump(self) -> None: ...
    def has_writers(self, arg0) -> bool: ...
    def may_contain_alias(self, arg0, arg1) -> bool: ...
    def to_graphviz_str(self) -> str: ...


class AnyType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class Argument:
    def __init__(self, *args, **kwargs) -> None: ...
    def has_default_value(self) -> bool_: ...
    @property
    def N(self) -> object: ...
    @property
    def default_value(self) -> object: ...
    @property
    def kwarg_only(self) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def type(self) -> Any: ...


class ArgumentSpec:
    def __init__(self, *args, **kwargs) -> None: ...


class BenchmarkConfig:
    num_calling_threads: int
    num_iters: int
    num_warmup_iters: int
    num_worker_threads: int
    profiler_output_path: str
    def __init__(self) -> None: ...


class BenchmarkExecutionStats:
    def __init__(self, *args, **kwargs) -> None: ...
    @property
    def latency_avg_ms(self) -> float: ...
    @property
    def num_iters(self) -> int: ...


class Block:
    def __init__(self, *args, **kwargs) -> None: ...
    def addInputToBlock(self) -> Value: ...
    def addNode(self, *args, **kwargs) -> Any: ...
    def findAllNodes(self, *args, **kwargs) -> Any: ...
    def findNode(self, *args, **kwargs) -> Any: ...
    def inputs(self) -> Iterator: ...
    def nodes(self) -> Iterator: ...
    def outputs(self) -> Iterator: ...
    def owningNode(self, *args, **kwargs) -> Any: ...
    def paramNode(self, *args, **kwargs) -> Any: ...
    def registerOutput(self, arg0: Value) -> int: ...
    def returnNode(self, *args, **kwargs) -> Any: ...


class BoolType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class BufferDict:
    def __init__(self, arg0: ScriptModule) -> None: ...
    def contains(self, arg0: str) -> bool: ...
    def getattr(self, arg0: str) -> object: ...
    def items(self) -> List[Tuple[str,object]]: ...
    def setattr(self, arg0: str, arg1: object) -> None: ...


class CallStack:

    def __init__(
        self, arg0: str, arg1: _jit_tree_views.SourceRange) -> None: ...


class Capsule:
    def __init__(self, *args, **kwargs) -> None: ...


class ClassType(torch.Type):
    def __init__(self, arg0: str) -> None: ...
    def name(self) -> str: ...
    def qualified_name(self) -> str: ...


class Code:
    def __init__(self, *args, **kwargs) -> None: ...
    def differentiable_op_executor_states(self, *args, **kwargs) -> Any: ...
    def grad_executor_states(self, *args, **kwargs) -> Any: ...
    def num_bailouts(self) -> int: ...
    def request_bailout(self, arg0: int) -> None: ...


class CompilationUnit:
    def __init__(self, lang: str = ..., _frames_up: int = ...) -> None: ...
    def create_function(self, *args, **kwargs) -> Any: ...

    def define(
        self, src: str, rcb: Callable[[str],object] = ...,
        _frames_up: int = ...) -> None: ...

    def drop_all_functions(self) -> None: ...
    def find_function(self, *args, **kwargs) -> Any: ...
    def get_class(self, arg0: str) -> ClassType: ...
    def get_functions(self, *args, **kwargs) -> Any: ...
    def get_interface(self, arg0: str) -> InterfaceType: ...
    def set_optimized(self, arg0: bool) -> None: ...
    def __getattr__(self, name) -> Any: ...


class CompleteArgumentSpec:
    def __init__(self, *args, **kwargs) -> None: ...


class ComplexType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class ConcreteModuleType:
    def __init__(self, *args, **kwargs) -> None: ...

    def _create_hooks(
        self, arg0: List[_jit_tree_views.Def], arg1: List[Callable[[str],
        object]], arg2: List[_jit_tree_views.Def], arg3: List[Callable[[str],
        object]]) -> None: ...

    def _create_methods_and_properties(
        self, arg0: List[_jit_tree_views.Property],
        arg1: List[Callable[[str],object]], arg2: List[_jit_tree_views.Def],
        arg3: List[Callable[[str],object]], arg4: List[Dict[str,
        object]]) -> None: ...

    def dump(self) -> None: ...
    @overload
    def equals(self, arg0: ConcreteModuleType) -> bool: ...
    @overload
    def equals(self, arg0: ConcreteModuleTypeBuilder) -> bool: ...
    def from_jit_type(self, *args, **kwargs) -> Any: ...
    def get_attributes(self) -> Dict[str,Tuple[Type,bool]]: ...
    def get_constants(self) -> Dict[str,object]: ...
    def get_modules(self) -> List[Tuple[str,ConcreteModuleType]]: ...
    def is_ignored_attribute(self, arg0: str) -> bool: ...
    @property
    def jit_type(self) -> Type: ...
    @property
    def py_class(self) -> Optional[object]: ...


class ConcreteModuleTypeBuilder:
    def __init__(self, arg0: object) -> None: ...

    def add_attribute(
        self, arg0: str, arg1: Type, arg2: bool, arg3: bool) -> None: ...

    def add_builtin_function(self, arg0: str, arg1: str) -> None: ...
    def add_constant(self, arg0: str, arg1: object) -> None: ...
    def add_failed_attribute(self, arg0: str, arg1: str) -> None: ...
    def add_forward_hook(self, arg0: object) -> None: ...
    def add_forward_pre_hook(self, arg0: object) -> None: ...

    def add_function_attribute(
        self, arg0: str, arg1: Type, arg2: object) -> None: ...

    def add_ignored_attribute(self, arg0: str) -> None: ...
    def add_ignored_attributes(self, arg0: List[str]) -> None: ...
    def add_module(self, arg0: str, arg1) -> None: ...
    def add_overload(self, arg0: str, arg1: List[str]) -> None: ...
    def build(self, *args, **kwargs) -> Any: ...
    def equals(self, arg0: ConcreteModuleTypeBuilder) -> bool: ...
    def set_module_dict(self) -> None: ...
    def set_module_list(self) -> None: ...
    def set_parameter_dict(self) -> None: ...
    def set_parameter_list(self) -> None: ...
    def set_poisoned(self) -> None: ...


class DeepCopyMemoTable:
    def __init__(self, *args, **kwargs) -> None: ...


class DeserializationStorageContext:
    def __init__(self) -> None: ...
    def add_storage(self, arg0: str, arg1) -> None: ...
    def get_storage(self, *args, **kwargs) -> Any: ...
    def has_storage(self, arg0: str) -> bool: ...


class DeviceObjType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class DictType(torch.Type):
    def __init__(self, arg0: Type, arg1: Type) -> None: ...
    def getKeyType(self) -> Type: ...
    def getValueType(self) -> Type: ...


class DisableTorchFunction:
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def __enter__(self) -> Any: ...
    def __exit__(self, type, value, traceback) -> Any: ...


class EnumType(torch.Type):
    def __init__(self, arg0: str, arg1: Type, arg2: List[object]) -> None: ...


class ErrorReport:
    def __init__(self, arg0: _jit_tree_views.SourceRange) -> None: ...
    def call_stack(self, *args, **kwargs) -> Any: ...
    def what(self) -> str: ...


class ExecutionPlan:
    def __init__(self, *args, **kwargs) -> None: ...
    @property
    def code(self) -> Code: ...
    @property
    def graph(self) -> Any: ...


class FatalError(Exception):
    ...


class FileCheck:
    def __init__(self) -> None: ...
    def check(self, arg0: str) -> FileCheck: ...
    @overload
    def check_count(self, arg0: str, arg1: int, arg2: bool) -> FileCheck: ...

    @overload
    def check_count(
        self, str: str, count: int, exactly: bool = ...) -> FileCheck: ...

    def check_dag(self, arg0: str) -> FileCheck: ...
    def check_next(self, arg0: str) -> FileCheck: ...
    def check_not(self, arg0: str) -> FileCheck: ...
    def check_same(self, arg0: str) -> FileCheck: ...
    def check_source_highlighted(self, arg0: str) -> FileCheck: ...
    @overload
    def run(self, arg0: str) -> None: ...
    @overload
    def run(self, arg0: Graph) -> None: ...
    @overload
    def run(self, checks_file: str, test_file: str) -> None: ...
    @overload
    def run(self, checks_file: str, graph: Graph) -> None: ...


class FloatType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class FunctionSchema:
    __hash__: ClassVar[None] = ...
    def __init__(self, *args, **kwargs) -> None: ...

    def check_forward_compatible_with(
        self, arg0: FunctionSchema) -> Tuple[bool,str]: ...

    def is_backward_compatible_with(self, arg0: FunctionSchema) -> bool: ...
    def __eq__(self, arg0: FunctionSchema) -> bool: ...
    @property
    def arguments(self) -> Any: ...
    @property
    def is_mutable(self) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def overload_name(self) -> str: ...
    @property
    def returns(self) -> Any: ...


class Future:
    def __init__(self, arg0) -> None: ...
    def _set_unwrap_func(self, arg0: function) -> None: ...
    def add_done_callback(self, arg0: function) -> None: ...
    def done(self) -> bool: ...
    def set_result(self, arg0: object) -> None: ...
    def then(self, arg0: function) -> Future: ...
    def value(self) -> object: ...
    def wait(self) -> object: ...
    def __getstate__(self) -> tuple: ...
    def __setstate__(self, arg0: tuple) -> None: ...


class FutureType(torch.Type):
    def __init__(self, arg0: Type) -> None: ...
    def getElementType(self) -> Type: ...


class Generator:
    _cdata: Any
    device: Any
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    @overload
    def get_state(self) -> Tensor: ...
    @overload
    def get_state() -> Any: ...
    @overload
    def initial_seed(self) -> int: ...
    @overload
    def initial_seed() -> Any: ...
    def manual_seed(self, seed) -> Generator: ...
    @overload
    def seed(self) -> int: ...
    @overload
    def seed() -> Any: ...
    def set_state(self, new_state) -> void: ...


class Gradient:
    def __init__(self, *args, **kwargs) -> None: ...
    @property
    def df(self) -> Any: ...
    @property
    def df_input_captured_inputs(self) -> List[int]: ...
    @property
    def df_input_captured_outputs(self) -> List[int]: ...
    @property
    def df_input_vjps(self) -> List[int]: ...
    @property
    def df_output_vjps(self) -> List[int]: ...
    @property
    def f(self) -> Any: ...
    @property
    def f_real_outputs(self) -> int: ...


class Graph:
    global_print_source_ranges: ClassVar[bool] = ...  # read-only
    def __init__(self) -> None: ...
    def _export_onnx(self, *args, **kwargs) -> Any: ...

    def _pretty_print_onnx(
        self, initializers, onnx_opset_version: int = ...,
        defer_weight_export: bool = ...,
        operator_export_type: _onnx.OperatorExportTypes = ...,
        google_printer: bool = ..., keep_initializers_as_inputs: bool = ...,
        custom_opsets: Dict[str,int], add_node_names: bool = ...) -> str: ...

    def addInput(self, *args, **kwargs) -> Any: ...

    def alias_db(
        self, isFrozen: bool = ...,
        descend_function_calls: bool = ...) -> AliasDb: ...

    def appendNode(self, *args, **kwargs) -> Any: ...
    def block(self, *args, **kwargs) -> Any: ...
    def copy(self) -> Graph: ...
    def create(self, *args, **kwargs) -> Any: ...
    def createClone(self, *args, **kwargs) -> Any: ...
    def createCudaFusionGroup(self, *args, **kwargs) -> Any: ...
    def createFusionGroup(self, *args, **kwargs) -> Any: ...
    def dump_alias_db(self) -> None: ...
    def eraseInput(self, arg0: int) -> None: ...
    def eraseOutput(self, arg0: int) -> None: ...
    def findAllNodes(self, *args, **kwargs) -> Any: ...
    def findNode(self, *args, **kwargs) -> Any: ...
    def inputs(self) -> Iterator: ...
    def insert(self, *args, **kwargs) -> Any: ...
    def insertConstant(self, *args, **kwargs) -> Any: ...
    def insertGraph(self, *args, **kwargs) -> Any: ...
    def insertNode(self, *args, **kwargs) -> Any: ...
    def insertPoint(self, *args, **kwargs) -> Any: ...
    @overload
    def insert_point_guard(self, arg0) -> object: ...
    @overload
    def insert_point_guard(self, arg0) -> object: ...
    def lint(self) -> None: ...
    def makeMultiOutputIntoTuple(self) -> None: ...
    def nodes(self) -> Iterator: ...
    def outputs(self) -> Iterator: ...
    def param_node(self, *args, **kwargs) -> Any: ...
    def permuteInputs(self, arg0: List[int]) -> None: ...
    def prependNode(self, *args, **kwargs) -> Any: ...
    def registerOutput(self, arg0) -> int: ...
    def return_node(self, *args, **kwargs) -> Any: ...
    @overload
    def setInsertPoint(self, arg0) -> None: ...
    @overload
    def setInsertPoint(self, arg0) -> None: ...
    def set_global_print_source_ranges(self, *args, **kwargs) -> Any: ...
    def str(self, print_source_ranges: bool = ...) -> str: ...


class GraphExecutorState:
    def __init__(self, *args, **kwargs) -> None: ...
    @property
    def execution_plans(self) -> Dict[ArgumentSpec,ExecutionPlan]: ...
    @property
    def fallback(self) -> ExecutionPlan: ...
    @property
    def graph(self) -> Any: ...


class IODescriptor:
    def __init__(self, *args, **kwargs) -> None: ...


class InferredType:
    @overload
    def __init__(self, arg0: Type) -> None: ...
    @overload
    def __init__(self, arg0: str) -> None: ...
    def reason(self) -> str: ...
    def success(self) -> bool: ...
    def type(self) -> Type: ...


class IntType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class InterfaceType(torch.Type):
    def __init__(self, arg0: str) -> None: ...
    def getMethod(self, arg0: str) -> FunctionSchema: ...
    def getMethodNames(self) -> List[str]: ...


class JITException(Exception):
    ...


class ListType(torch.Type):
    def __init__(self, arg0: Type) -> None: ...
    def getElementType(self) -> Type: ...
    def ofBools(self, *args, **kwargs) -> Any: ...
    def ofComplexDoubles(self, *args, **kwargs) -> Any: ...
    def ofFloats(self, *args, **kwargs) -> Any: ...
    def ofInts(self, *args, **kwargs) -> Any: ...
    def ofTensors(self, *args, **kwargs) -> Any: ...


class LiteScriptModule:
    def __init__(self, arg0, arg1) -> None: ...
    def find_method(self, method_name: str) -> bool: ...
    def forward(self, input_tuple: tuple) -> IValue: ...
    def run_method(self, method_name: str, input_tuple: tuple) -> IValue: ...


class LockingLogger(LoggerBase):
    def __init__(self) -> None: ...
    def get_counter_val(self, arg0: str) -> int: ...

    def set_aggregation_type(
        self, arg0: str, arg1: AggregationType) -> None: ...


class LoggerBase:
    def __init__(self, *args, **kwargs) -> None: ...


class MobileOptimizerType:
    __members__: ClassVar[dict] = ...  # read-only
    CONV_BN_FUSION: ClassVar[torch.MobileOptimizerType] = ...
    FUSE_ADD_RELU: ClassVar[torch.MobileOptimizerType] = ...
    HOIST_CONV_PACKED_PARAMS: ClassVar[torch.MobileOptimizerType] = ...
    INSERT_FOLD_PREPACK_OPS: ClassVar[torch.MobileOptimizerType] = ...
    REMOVE_DROPOUT: ClassVar[torch.MobileOptimizerType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: int) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...


class ModuleDict:
    def __init__(self, arg0: ScriptModule) -> None: ...
    def contains(self, arg0: str) -> bool: ...
    def getattr(self, arg0: str) -> object: ...
    def items(self) -> List[Tuple[str,object]]: ...
    def setattr(self, arg0: str, arg1: object) -> None: ...


class Node:
    def __init__(self, *args, **kwargs) -> None: ...
    def addBlock(self) -> Block: ...
    def addInput(self, arg0: Value) -> Value: ...
    def addOutput(self) -> Value: ...
    def attributeNames(self) -> List[str]: ...
    def blocks(self) -> Iterator: ...
    def c(self, *args, **kwargs) -> Any: ...
    def c_(self, arg0: str, arg1) -> Node: ...
    def cconv(self) -> str: ...
    def copyAttributes(self, arg0: Node) -> Node: ...
    def copyMetadata(self, arg0: Node) -> Node: ...
    def destroy(self) -> None: ...
    def eraseOutput(self, arg0: int) -> None: ...
    def f(self, arg0: str) -> float: ...
    def f_(self, arg0: str, arg1: float) -> Node: ...
    def findAllNodes(self, kind: str, recurse: bool = ...) -> List[Node]: ...
    def findNode(self, kind: str, recurse: bool = ...) -> Node: ...
    def fs(self, arg0: str) -> List[float]: ...
    def fs_(self, arg0: str, arg1: List[float]) -> Node: ...
    def g(self, arg0: str) -> Graph: ...
    def g_(self, arg0: str, arg1: Graph) -> Node: ...
    def getModuleHierarchy(self) -> str: ...
    def gs(self, arg0: str) -> List[Graph]: ...
    def gs_(self, arg0: str, arg1: List[Graph]) -> Node: ...
    def hasAttribute(self, arg0: str) -> bool: ...
    def hasAttributes(self) -> bool: ...
    def hasMultipleOutputs(self) -> bool: ...
    def hasUses(self) -> bool: ...
    def i(self, arg0: str) -> int: ...
    def i_(self, arg0: str, arg1: int) -> Node: ...
    def input(self) -> Value: ...
    def inputs(self) -> Iterator: ...
    def inputsAt(self, arg0: int) -> Value: ...
    def inputsSize(self) -> int: ...
    def insertAfter(self, arg0: Node) -> Node: ...
    def insertBefore(self, arg0: Node) -> Node: ...
    def is(self, arg0: str) -> List[int]: ...
    def isAfter(self, arg0: Node) -> bool: ...
    def isBefore(self, arg0: Node) -> bool: ...
    def isNondeterministic(self) -> bool: ...
    def is_(self, arg0: str, arg1: List[int]) -> Node: ...
    def ival(self, arg0: str) -> IValue: ...
    def ival_(self, arg0: str, arg1: IValue) -> Node: ...
    def kind(self) -> Symbol: ...
    def kindOf(self, arg0: str) -> AttributeKind: ...
    def matches(self, arg0: str) -> bool: ...
    def moveAfter(self, arg0: Node) -> None: ...
    def moveBefore(self, arg0: Node) -> None: ...
    def mustBeNone(self) -> bool: ...
    def namedInput(self, arg0: str) -> Value: ...
    def output(self) -> Value: ...
    def outputs(self) -> Iterator: ...
    def outputsAt(self, arg0: int) -> Value: ...
    def outputsSize(self) -> int: ...
    def owningBlock(self) -> Block: ...
    def prev(self) -> Node: ...
    def pyname(self) -> str: ...
    def pyobj(self) -> object: ...
    def removeAllInputs(self) -> None: ...
    def removeAttribute(self, arg0: str) -> Node: ...
    def removeInput(self, arg0: int) -> None: ...
    def replaceAllUsesWith(self, arg0: Node) -> None: ...
    def replaceInput(self, arg0: int, arg1: Value) -> Value: ...
    def replaceInputWith(self, arg0: Value, arg1: Value) -> None: ...
    def s(self, arg0: str) -> str: ...
    def s_(self, arg0: str, arg1: str) -> Node: ...
    def scalar_args(self) -> list: ...
    def schema(self) -> str: ...
    def scopeName(self) -> str: ...
    def sourceRange(self) -> str: ...
    def ss(self, arg0: str) -> List[str]: ...
    def ss_(self, arg0: str, arg1: List[str]) -> Node: ...
    def t(self, *args, **kwargs) -> Any: ...
    def t_(self, arg0: str, arg1) -> Node: ...
    def ts(self, *args, **kwargs) -> Any: ...
    def ts_(self, arg0: str, arg1) -> Node: ...
    def ty_(self, arg0: str, arg1) -> Node: ...
    def tys_(self, arg0: str, arg1) -> Node: ...
    def z(self, *args, **kwargs) -> Any: ...
    def z_(self, arg0: str, arg1) -> Node: ...
    def zs(self, *args, **kwargs) -> Any: ...
    def zs_(self, arg0: str, arg1) -> Node: ...


class NoneType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class NoopLogger(LoggerBase):
    def __init__(self) -> None: ...


class NumberType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class OperatorInfo:
    def __init__(self, *args, **kwargs) -> None: ...
    @property
    def num_schema_args(self) -> Optional[int]: ...


class OptionalType(torch.Type):
    def __init__(self, arg0: Type) -> None: ...
    def getElementType(self) -> Type: ...
    def ofTensor(self, *args, **kwargs) -> Any: ...


class ParameterDict:
    def __init__(self, arg0: ScriptModule) -> None: ...
    def contains(self, arg0: str) -> bool: ...
    def getattr(self, arg0: str) -> object: ...
    def items(self) -> List[Tuple[str,object]]: ...
    def setattr(self, arg0: str, arg1: object) -> None: ...


class PyObjectType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class PyTorchFileReader:
    @overload
    def __init__(self, arg0: str) -> None: ...
    @overload
    def __init__(self, arg0: object) -> None: ...
    def get_all_records(self) -> List[str]: ...
    def get_record(self, arg0: str) -> bytes: ...
    def get_storage_from_record(self, *args, **kwargs) -> Any: ...
    def has_record(self, arg0: str) -> bool: ...


class PyTorchFileWriter:
    @overload
    def __init__(self, arg0: str) -> None: ...
    @overload
    def __init__(self, arg0: object) -> None: ...
    @overload
    def __init__(self, arg0: Callable[[capsule,int],int]) -> None: ...
    def archive_name(self) -> str: ...
    def get_all_written_records(self) -> Set[str]: ...
    def set_min_version(self, arg0: int) -> None: ...
    def write_end_of_file(self) -> None: ...
    @overload
    def write_record(self, arg0: str, arg1: str, arg2: int) -> None: ...
    @overload
    def write_record(self, arg0: str, arg1: int, arg2: int) -> None: ...


class RRefType(torch.Type):
    def __init__(self, arg0: Type) -> None: ...
    def getElementType(self) -> Type: ...


class ScriptClass:
    def __init__(self, *args, **kwargs) -> None: ...
    def __call__(self, *args, **kwargs) -> object: ...
    def __getattr__(self, arg0: str) -> ScriptClassFunction: ...


class ScriptClassFunction:
    def __init__(self, *args, **kwargs) -> None: ...
    def __call__(self, *args, **kwargs) -> object: ...


class ScriptDict:
    def __init__(self, arg0: dict) -> None: ...
    def items(self) -> ScriptDictIterator: ...
    def keys(self) -> ScriptDictKeyIterator: ...
    def __bool__(self) -> object: ...
    def __contains__(self, arg0: object) -> object: ...
    def __delitem__(self, arg0: object) -> None: ...
    def __getitem__(self, arg0: object) -> object: ...
    def __iter__(self) -> ScriptDictKeyIterator: ...
    def __len__(self) -> object: ...
    def __setitem__(self, arg0: object, arg1: object) -> None: ...


class ScriptDictIterator:
    def __init__(self, *args, **kwargs) -> None: ...
    def __iter__(self) -> ScriptDictIterator: ...
    def __next__(self) -> object: ...


class ScriptDictKeyIterator:
    def __init__(self, *args, **kwargs) -> None: ...
    def __iter__(self) -> ScriptDictKeyIterator: ...
    def __next__(self) -> object: ...


class ScriptFunction:
    graph_for: ClassVar[function] = ...
    __reduce__: ClassVar[function] = ...
    def __init__(self, *args, **kwargs) -> None: ...
    def _debug_flush_compilation_cache(self) -> None: ...
    def _set_ignore_amp(self, arg0: bool) -> None: ...
    def get_debug_state(self) -> GraphExecutorState: ...

    def save(
        self, filename: str, _extra_files: Dict[str,str] = ...) -> None: ...

    def save_to_buffer(self, _extra_files: Dict[str,str] = ...) -> bytes: ...
    def __call__(self, *args, **kwargs) -> object: ...
    @property
    def code(self) -> str: ...
    @property
    def graph(self) -> Graph: ...
    @property
    def inlined_graph(self) -> Graph: ...
    @property
    def name(self) -> str: ...
    @property
    def qualified_name(self) -> str: ...
    @property
    def schema(self) -> FunctionSchema: ...


class ScriptList:
    def __init__(self, arg0: list) -> None: ...
    def append(self, arg0: object) -> None: ...
    def clear(self) -> None: ...
    def count(self, arg0: object) -> int: ...
    @overload
    def extend(self, arg0: list) -> None: ...
    @overload
    def extend(self, arg0: Iterable) -> None: ...
    def insert(self, arg0: int, arg1: object) -> None: ...
    @overload
    def pop(self) -> object: ...
    @overload
    def pop(self, arg0: int) -> object: ...
    def remove(self, arg0: object) -> None: ...
    def __bool__(self) -> object: ...
    def __contains__(self, arg0: object) -> object: ...
    def __delitem__(self, arg0: int) -> None: ...
    @overload
    def __getitem__(self, arg0: int) -> object: ...
    @overload
    def __getitem__(self, arg0: slice) -> ScriptList: ...
    def __getstate__(self) -> list: ...
    def __iter__(self) -> ScriptListIterator: ...
    def __len__(self) -> object: ...
    @overload
    def __setitem__(self, arg0: int, arg1: object) -> None: ...
    @overload
    def __setitem__(self, arg0: slice, arg1: list) -> None: ...
    def __setstate__(self, arg0: list) -> None: ...


class ScriptListIterator:
    def __init__(self, *args, **kwargs) -> None: ...
    def __iter__(self) -> ScriptListIterator: ...
    def __next__(self) -> object: ...


class ScriptMethod:
    graph_for: ClassVar[function] = ...
    def __init__(self, *args, **kwargs) -> None: ...
    def _debug_flush_compilation_cache(self) -> None: ...
    def __call__(self, *args, **kwargs) -> object: ...
    @property
    def code(self) -> str: ...
    @property
    def code_with_constants(self) -> Tuple[str,Dict[str,IValue]]: ...
    @property
    def graph(self) -> Graph: ...
    @property
    def inlined_graph(self) -> Graph: ...
    @property
    def name(self) -> str: ...
    @property
    def owner(self) -> ScriptModule: ...
    @property
    def schema(self) -> FunctionSchema: ...


class ScriptModule(torch.ScriptObject):
    def __init__(self, arg0: str, arg1, arg2: bool) -> None: ...

    def _create_method_from_trace(
        self, name: str, func: function, input_tuple: tuple,
        var_name_lookup_fn: function, strict: bool, force_outplace: bool,
        argument_names: List[str] = ...) -> None: ...

    def _define(
        self, arg0, arg1: str, arg2: Callable[[str],object]) -> None: ...

    def _get_forward_hooks(self, *args, **kwargs) -> Any: ...
    def _get_forward_pre_hooks(self, *args, **kwargs) -> Any: ...

    def _register_attribute(
        self, arg0: str, arg1: Type, arg2: handle) -> None: ...

    def _replicate_for_data_parallel(self) -> ScriptModule: ...

    def _save_for_mobile(
        self, filename: str, _extra_files: Dict[str,str] = ...,
        _save_mobile_debug_info: bool = ...,
        _use_flatbuffer: bool = ...) -> None: ...

    def _save_to_buffer_for_mobile(
        self, _extra_files: Dict[str,str] = ...,
        _save_mobile_debug_info: bool = ...,
        _use_flatbuffer: bool = ...) -> bytes: ...

    def _set_optimized(self, arg0: bool) -> None: ...
    def apply(self, arg0: Callable[[ScriptModule],None]) -> None: ...
    def children(self, *args, **kwargs) -> Any: ...

    def dump(
        self, code: bool = ..., attrs: bool = ...,
        params: bool = ...) -> None: ...

    def dump_to_str(
        self, code: bool = ..., attrs: bool = ...,
        params: bool = ...) -> str: ...

    def get_debug_state(self) -> GraphExecutorState: ...

    def save(
        self, filename: str, _extra_files: Dict[str,str] = ...) -> None: ...

    def save_to_buffer(self, _extra_files: Dict[str,str] = ...) -> bytes: ...
    def __copy__(self) -> ScriptModule: ...
    def __deepcopy__(self, arg0: dict) -> ScriptModule: ...
    def __eq__(self, arg0: object) -> bool: ...
    def __hash__(self) -> int: ...
    @property
    def code(self) -> str: ...
    @property
    def code_with_constants(self) -> Tuple[str,Dict[str,IValue]]: ...
    @property
    def qualified_name(self) -> str: ...


class ScriptModuleSerializer:
    def __init__(self, arg0: PyTorchFileWriter) -> None: ...
    def serialize(self, arg0, arg1: int) -> None: ...
    def storage_context(self, *args, **kwargs) -> Any: ...
    def write_files(self, code_dir: str = ...) -> None: ...


class ScriptObject:
    def __init__(self, *args, **kwargs) -> None: ...
    def _get_method(self, *args, **kwargs) -> Any: ...
    def _has_method(self, arg0: str) -> bool: ...
    def _method_names(self) -> List[str]: ...
    def _properties(self, *args, **kwargs) -> Any: ...
    def _type(self) -> ClassType: ...
    def getattr(self, arg0: str) -> object: ...
    def hasattr(self, arg0: str) -> bool: ...
    def setattr(self, arg0: str, arg1: object) -> None: ...
    def __abs__(self, *args, **kwargs) -> object: ...
    def __add__(self, *args, **kwargs) -> object: ...
    def __and__(self, *args, **kwargs) -> object: ...
    def __concat__(self, *args, **kwargs) -> object: ...
    def __contains__(self, *args, **kwargs) -> object: ...
    def __copy__(self) -> ScriptObject: ...
    def __deepcopy__(self, arg0: dict) -> ScriptObject: ...
    def __delitem__(self, *args, **kwargs) -> object: ...
    def __eq__(self, *args, **kwargs) -> object: ...
    def __floordiv__(self, *args, **kwargs) -> object: ...
    def __ge__(self, *args, **kwargs) -> object: ...
    def __getattr__(self, arg0: str) -> object: ...
    def __getitem__(self, *args, **kwargs) -> object: ...
    def __getstate__(self) -> Tuple[object,str]: ...
    def __gt__(self, *args, **kwargs) -> object: ...
    def __hash__(self) -> int: ...
    def __iadd__(self, *args, **kwargs) -> object: ...
    def __iand__(self, *args, **kwargs) -> object: ...
    def __iconcat__(self, *args, **kwargs) -> object: ...
    def __ifloordiv__(self, *args, **kwargs) -> object: ...
    def __ilshift__(self, *args, **kwargs) -> object: ...
    def __imatmul__(self, *args, **kwargs) -> object: ...
    def __imod__(self, *args, **kwargs) -> object: ...
    def __imul__(self, *args, **kwargs) -> object: ...
    def __index__(self, *args, **kwargs) -> object: ...
    def __inv__(self, *args, **kwargs) -> object: ...
    def __invert__(self, *args, **kwargs) -> object: ...
    def __ior__(self, *args, **kwargs) -> object: ...
    def __ipow__(self, *args, **kwargs) -> object: ...
    def __irshift__(self, *args, **kwargs) -> object: ...
    def __isub__(self, *args, **kwargs) -> object: ...
    def __itruediv__(self, *args, **kwargs) -> object: ...
    def __ixor__(self, *args, **kwargs) -> object: ...
    def __le__(self, *args, **kwargs) -> object: ...
    def __len__(self, *args, **kwargs) -> object: ...
    def __lshift__(self, *args, **kwargs) -> object: ...
    def __lt__(self, *args, **kwargs) -> object: ...
    def __matmul__(self, *args, **kwargs) -> object: ...
    def __mod__(self, *args, **kwargs) -> object: ...
    def __mul__(self, *args, **kwargs) -> object: ...
    def __ne__(self, *args, **kwargs) -> object: ...
    def __neg__(self, *args, **kwargs) -> object: ...
    def __not__(self, *args, **kwargs) -> object: ...
    def __or__(self, *args, **kwargs) -> object: ...
    def __pos__(self, *args, **kwargs) -> object: ...
    def __pow__(self, *args, **kwargs) -> object: ...
    def __rshift__(self, *args, **kwargs) -> object: ...
    def __setattr__(self, arg0: str, arg1: object) -> None: ...
    def __setitem__(self, *args, **kwargs) -> object: ...
    def __setstate__(self, arg0: Tuple[object,str]) -> None: ...
    def __sub__(self, *args, **kwargs) -> object: ...
    def __truediv__(self, *args, **kwargs) -> object: ...
    def __xor__(self, *args, **kwargs) -> object: ...


class ScriptObjectProperty:
    def __init__(self, *args, **kwargs) -> None: ...
    @property
    def getter(self) -> Any: ...
    @property
    def name(self) -> str: ...
    @property
    def setter(self) -> Any: ...


class SerializationStorageContext:
    def __init__(self, *args, **kwargs) -> None: ...
    def get_or_add_storage(self, arg0) -> int: ...
    def has_storage(self, arg0) -> bool: ...


class Size(tuple):
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def numel(self, *args, **kwargs) -> Any: ...
    def __add__(self, other) -> Any: ...
    def __getitem__(self, index) -> Any: ...
    def __mul__(self, other) -> Any: ...
    def __reduce__(self) -> Any: ...
    def __rmul__(self, other) -> Any: ...


class StaticModule:
    class IndividualMetrics:
        def __init__(self, *args, **kwargs) -> None: ...
        @property
        def first_iter_time(self) -> float: ...
        @property
        def instances_per_node_type(self) -> Dict[str,int]: ...
        @property
        def memory_alloc_time(self) -> float: ...
        @property
        def memory_dealloc_time(self) -> float: ...
        @property
        def out_nodes(self) -> Set[str]: ...
        @property
        def out_nodes_count(self) -> int: ...
        @property
        def output_dealloc_time(self) -> float: ...
        @property
        def percent_per_node_type(self) -> Dict[str,float]: ...
        @property
        def setup_time(self) -> float: ...
        @property
        def time_per_node(self) -> List[float]: ...
        @property
        def time_per_node_type(self) -> Dict[str,float]: ...
        @property
        def total_nodes_count(self) -> int: ...
        @property
        def total_time(self) -> float: ...
    def __init__(self, *args, **kwargs) -> None: ...
    def benchmark(self, arg0, arg1, arg2: int, arg3: int) -> None: ...

    def benchmark_individual_ops(
        self, arg0, arg1, arg2: int,
        arg3: int) -> StaticModule.IndividualMetrics: ...

    def __call__(self, *args, **kwargs) -> object: ...


class StorageBase:
    _cdata: Any
    device: Any
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def _expired(self, *args, **kwargs) -> Any: ...
    def _free_weak_ref(self, *args, **kwargs) -> Any: ...
    def _get_shared_fd(self, *args, **kwargs) -> Any: ...
    def _new_shared_cuda(self, *args, **kwargs) -> Any: ...
    def _new_shared_fd_cpu(self, *args, **kwargs) -> Any: ...
    def _new_shared_filename_cpu(self, *args, **kwargs) -> Any: ...
    def _new_using_fd_cpu(self, *args, **kwargs) -> Any: ...
    def _new_using_filename_cpu(self, *args, **kwargs) -> Any: ...
    def _new_with_file(self, *args, **kwargs) -> Any: ...
    @classmethod
    def _new_with_weak_ptr(cls, *args, **kwargs) -> Any: ...
    def _release_ipc_counter_cuda(self, *args, **kwargs) -> Any: ...
    def _set_cdata(self, *args, **kwargs) -> Any: ...
    def _set_from_file(self, *args, **kwargs) -> Any: ...
    def _share_cuda_(self, *args, **kwargs) -> Any: ...
    def _share_fd_cpu_(self, *args, **kwargs) -> Any: ...
    def _share_filename_cpu_(self, *args, **kwargs) -> Any: ...
    def _shared_decref(self, *args, **kwargs) -> Any: ...
    def _shared_incref(self, *args, **kwargs) -> Any: ...
    def _weak_ref(self, *args, **kwargs) -> Any: ...
    def _write_file(self, *args, **kwargs) -> Any: ...
    def copy_(self, *args, **kwargs) -> Any: ...
    def data_ptr(self, *args, **kwargs) -> Any: ...
    def element_size(self, *args, **kwargs) -> Any: ...
    def fill_(self, *args, **kwargs) -> Any: ...
    def from_buffer(self, *args, **kwargs) -> Any: ...
    def from_file(self, *args, **kwargs) -> Any: ...
    def is_pinned(self, *args, **kwargs) -> Any: ...
    def is_shared(self, *args, **kwargs) -> Any: ...
    def nbytes(self, *args, **kwargs) -> Any: ...
    def new(self, *args, **kwargs) -> Any: ...
    def resize_(self, *args, **kwargs) -> Any: ...
    def __delitem__(self, other) -> Any: ...
    def __getitem__(self, index) -> Any: ...
    def __len__(self) -> Any: ...
    def __setitem__(self, index, object) -> Any: ...


class Stream:
    __hash__: ClassVar[None] = ...
    _cdata: Any
    device: Any
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def __eq__(self, other) -> Any: ...


class StreamObjType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class StringType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class SymIntType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, *args, **kwargs) -> Any: ...


class TensorType(torch.Type):
    def __init__(self, *args, **kwargs) -> None: ...
    def create_from_tensor(self, *args, **kwargs) -> Any: ...
    def get(self, *args, **kwargs) -> Any: ...
    def getInferred(self, *args, **kwargs) -> Any: ...


class ThroughputBenchmark:
    @overload
    def __init__(self, arg0: ScriptModule) -> None: ...
    @overload
    def __init__(self, arg0: object) -> None: ...
    def add_input(self, *args, **kwargs) -> None: ...
    def benchmark(self, arg0: BenchmarkConfig) -> BenchmarkExecutionStats: ...
    def run_once(self, *args, **kwargs) -> object: ...


class TracingState:
    def __init__(self, *args, **kwargs) -> None: ...
    def current_scope(self) -> str: ...
    def graph(self) -> Graph: ...
    def pop_scope(self) -> None: ...
    def push_scope(self, arg0: str) -> None: ...
    def set_graph(self, arg0: Graph) -> None: ...


class TupleType(torch.Type):
    def __init__(self, arg0: List[Type]) -> None: ...
    def elements(self) -> List[Type]: ...


class Type:
    __hash__: ClassVar[None] = ...
    def __init__(self, *args, **kwargs) -> None: ...
    def contiguous(self) -> Type: ...
    def device(self) -> object: ...
    def dim(self) -> object: ...
    def dtype(self) -> object: ...
    def isSubtypeOf(self, arg0: Type) -> bool: ...
    def is_interface_type(self) -> bool: ...
    def kind(self) -> str: ...
    def requires_grad(self) -> bool: ...
    def scalarType(self) -> str: ...
    def sizes(self) -> object: ...
    def str(self) -> str: ...
    def strides(self) -> object: ...
    def symbolic_sizes(self) -> object: ...
    def undefined(self) -> object: ...
    def varyingSizes(self) -> object: ...
    def with_device(self, arg0: object) -> object: ...
    def with_dtype(self, arg0: object) -> object: ...
    def with_sizes(self, arg0: Optional[List[Optional[int]]]) -> object: ...
    def __eq__(self, arg0: Type) -> bool: ...
    @property
    def annotation_str(self) -> str: ...


class UnionType(torch.Type):
    def __init__(self, arg0: List[Type]) -> None: ...
    def containedTypes(self) -> List[Type]: ...


class Use:
    def __init__(self, *args, **kwargs) -> None: ...
    def isAfter(self, arg0: Use) -> bool: ...
    @property
    def offset(self) -> int: ...
    @property
    def user(self) -> Node: ...


class Value:
    def __init__(self, *args, **kwargs) -> None: ...
    def copyMetadata(self, arg0: Value) -> Value: ...
    def debugName(self) -> str: ...
    @overload
    def inferTypeFrom(self, arg0) -> None: ...
    @overload
    def inferTypeFrom(self, arg0) -> None: ...
    def isCompleteTensor(self) -> bool: ...
    def node(self, *args, **kwargs) -> Any: ...
    def offset(self) -> int: ...
    def replaceAllUsesAfterNodeWith(self, arg0, arg1: Value) -> None: ...
    def replaceAllUsesWith(self, arg0: Value) -> None: ...
    def requiresGrad(self) -> Optional[bool]: ...
    def requires_grad(self) -> bool: ...
    def setDebugName(self, arg0: str) -> Value: ...
    def setType(self, arg0) -> Value: ...
    def setTypeAs(self, arg0: Value) -> Value: ...
    def toIValue(self) -> Optional[IValue]: ...
    def type(self, *args, **kwargs) -> Any: ...
    def unique(self) -> int: ...
    def uses(self, *args, **kwargs) -> Any: ...


class _CUDAGraph:
    __init__: ClassVar[function] = ...


class _ConvBackend:
    __members__: ClassVar[dict] = ...  # read-only
    CudaDepthwise2d: ClassVar[_ConvBackend] = ...
    CudaDepthwise3d: ClassVar[_ConvBackend] = ...
    Cudnn: ClassVar[_ConvBackend] = ...
    CudnnTranspose: ClassVar[_ConvBackend] = ...
    Empty: ClassVar[_ConvBackend] = ...
    Miopen: ClassVar[_ConvBackend] = ...
    MiopenDepthwise: ClassVar[_ConvBackend] = ...
    MiopenTranspose: ClassVar[_ConvBackend] = ...
    Mkldnn: ClassVar[_ConvBackend] = ...
    MkldnnEmpty: ClassVar[_ConvBackend] = ...
    NnpackSpatial: ClassVar[_ConvBackend] = ...
    Overrideable: ClassVar[_ConvBackend] = ...
    Slow2d: ClassVar[_ConvBackend] = ...
    Slow3d: ClassVar[_ConvBackend] = ...
    SlowDilated2d: ClassVar[_ConvBackend] = ...
    SlowDilated3d: ClassVar[_ConvBackend] = ...
    SlowTranspose2d: ClassVar[_ConvBackend] = ...
    SlowTranspose3d: ClassVar[_ConvBackend] = ...
    Winograd3x3Depthwise: ClassVar[_ConvBackend] = ...
    Xnnpack2d: ClassVar[_ConvBackend] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: int) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...


class _CudaEventBase:
    __init__: ClassVar[function] = ...


class _CudaStreamBase:
    __init__: ClassVar[function] = ...


class _DisableTorchDispatch:
    def __init__(self) -> None: ...


class _DispatchModule:
    def __init__(self, *args, **kwargs) -> None: ...
    def def_(self, schema: str, alias: str = ...) -> object: ...
    def def_legacy(self, schema: str) -> object: ...

    def def_name_t_t(
        self, name: str, dispatch: str = ..., debug: str = ...) -> object: ...

    def def_schema_t_t(
        self, name: str, dispatch: str = ..., alias: str = ...,
        debug: str = ...) -> object: ...

    def define(self, schema: str, alias_analysis: str = ...) -> str: ...
    def fallback_fallthrough(self, dispatch: str = ...) -> object: ...
    def impl(self, name: str, dispatch: str, func: object) -> None: ...

    def impl_t_t(
        self, name: str, dispatch: str = ..., debug: str = ...) -> object: ...

    def impl_tt_t(
        self, name: str, dispatch: str = ..., debug: str = ...) -> object: ...


class _DispatchOperatorHandle:
    def __init__(self, *args, **kwargs) -> None: ...
    def schema(self) -> FunctionSchema: ...


class _FunctionBase:
    _raw_saved_tensors: Any
    dirty_tensors: Any
    materialize_grads: Any
    metadata: Any
    needs_input_grad: Any
    next_functions: Any
    non_differentiable: Any
    requires_grad: Any
    saved_for_forward: Any
    saved_tensors: Any
    saved_variables: Any
    to_save: Any
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def _register_hook_dict(self, *args, **kwargs) -> Any: ...
    @classmethod
    def apply(cls, *args, **kwargs) -> Any: ...
    def name(self, *args, **kwargs) -> Any: ...
    def register_hook(self, *args, **kwargs) -> Any: ...


class _ImperativeEngine:
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def is_checkpoint_valid(self, *args, **kwargs) -> Any: ...
    def queue_callback(self, *args, **kwargs) -> Any: ...
    def run_backward(self, *args, **kwargs) -> Any: ...


class _InferenceMode:
    def __init__(self, arg0: bool) -> None: ...


class _LegacyVariableBase:
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...


class _LinAlgError(RuntimeError):
    ...


class _LinalgBackend:
    __members__: ClassVar[dict] = ...  # read-only
    Cusolver: ClassVar[_LinalgBackend] = ...
    Default: ClassVar[_LinalgBackend] = ...
    Magma: ClassVar[_LinalgBackend] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: int) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...


class _RestorePythonTLSSnapshot:
    def __init__(self) -> None: ...


class _ShapeComputeGraphMapping:
    def __init__(self, *args, **kwargs) -> None: ...
    def graph_output_to_symbolic_shape_dim(self) -> Dict[Value,int]: ...
    def partial_eval_shape_graph(self) -> Graph: ...


class _TensorBase:
    __hash__: ClassVar[None] = ...
    H: Any
    T: Any
    _backward_hooks: Any
    _base: Any
    _cdata: Any
    _grad: Any
    _grad_fn: Any
    _python_dispatch: Any
    _version: Any
    data: Any
    device: Any
    dtype: Any
    grad: Any
    grad_fn: Any
    imag: Any
    is_cuda: Any
    is_ipu: Any
    is_leaf: Any
    is_meta: Any
    is_mkldnn: Any
    is_mps: Any
    is_nested: Any
    is_ort: Any
    is_quantized: Any
    is_sparse: Any
    is_sparse_csr: Any
    is_vulkan: Any
    is_xpu: Any
    layout: Any
    mH: Any
    mT: Any
    name: Any
    names: Any
    ndim: Any
    output_nr: Any
    real: Any
    requires_grad: Any
    retains_grad: Any
    shape: Any
    volatile: Any
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def _addmm_activation(self, *args, **kwargs) -> Any: ...
    def _autocast_to_full_precision(self, *args, **kwargs) -> Any: ...
    def _autocast_to_reduced_precision(self, *args, **kwargs) -> Any: ...
    def _coalesced_(self, *args, **kwargs) -> Any: ...
    def _conj(self, *args, **kwargs) -> Any: ...
    def _conj_physical(self, *args, **kwargs) -> Any: ...
    def _dimI(self, *args, **kwargs) -> Any: ...
    def _dimV(self, *args, **kwargs) -> Any: ...
    def _fix_weakref(self, *args, **kwargs) -> Any: ...
    def _indices(self, *args, **kwargs) -> Any: ...
    def _is_view(self, *args, **kwargs) -> Any: ...
    def _is_zerotensor(self, *args, **kwargs) -> Any: ...
    def _make_subclass(self, *args, **kwargs) -> Any: ...
    def _make_wrapper_subclass(self, *args, **kwargs) -> Any: ...
    def _neg_view(self, *args, **kwargs) -> Any: ...
    def _nested_tensor_layer_norm(self, *args, **kwargs) -> Any: ...
    def _nnz(self, *args, **kwargs) -> Any: ...
    def _storage(self, *args, **kwargs) -> Any: ...
    def _to_dense(self, *args, **kwargs) -> Any: ...
    def _values(self, *args, **kwargs) -> Any: ...
    def abs(self) -> Tensor: ...
    def abs_(self) -> Tensor: ...
    def absolute(self) -> Tensor: ...
    def absolute_(self) -> Tensor: ...
    def acos(self) -> Tensor: ...
    def acos_(self) -> Tensor: ...
    def acosh(self) -> Tensor: ...
    def acosh_(self) -> Tensor: ...
    def add(self, *args, **kwargs) -> Any: ...
    def add_(self, *args, **kwargs) -> Any: ...
    def addbmm(self, *args, **kwargs) -> Any: ...
    def addbmm_(self, *args, **kwargs) -> Any: ...
    def addcdiv(self, *args, **kwargs) -> Any: ...
    def addcdiv_(self, *args, **kwargs) -> Any: ...
    def addcmul(self, *args, **kwargs) -> Any: ...
    def addcmul_(self, *args, **kwargs) -> Any: ...
    def addmm(self, *args, **kwargs) -> Any: ...
    def addmm_(self, *args, **kwargs) -> Any: ...
    def addmv(self, *args, **kwargs) -> Any: ...
    def addmv_(self, *args, **kwargs) -> Any: ...
    def addr(self, *args, **kwargs) -> Any: ...
    def addr_(self, *args, **kwargs) -> Any: ...
    def adjoint(self) -> Tensor: ...
    @overload
    def align_as(self, other) -> Tensor: ...
    @overload
    def align_as(imgs) -> Any: ...
    @overload
    def align_as(input) -> Any: ...
    def align_to(self, *args, **kwargs) -> Any: ...
    def all(self, dim = ..., keepdim = ...) -> Tensor: ...

    def allclose(
        self, other, rtol = ..., atol = ..., equal_nan = ...) -> Tensor: ...

    def amax(self, dim = ..., keepdim = ...) -> Tensor: ...
    def amin(self, dim = ..., keepdim = ...) -> Tensor: ...
    def aminmax(self, *args, **kwargs) -> Any: ...
    def angle(self) -> Tensor: ...
    def any(self, dim = ..., keepdim = ...) -> Tensor: ...
    def apply_(self, callable) -> Tensor: ...
    def arccos(self) -> Tensor: ...
    def arccos_(self) -> Tensor: ...
    def arccosh(self, *args, **kwargs) -> Any: ...
    def arccosh_(self, *args, **kwargs) -> Any: ...
    def arcsin(self) -> Tensor: ...
    def arcsin_(self) -> Tensor: ...
    def arcsinh(self) -> Tensor: ...
    def arcsinh_(self) -> Tensor: ...
    def arctan(self) -> Tensor: ...
    def arctan2(self, other) -> Tensor: ...
    def arctan2_(self, *args, **kwargs) -> Any: ...
    def arctan_(self) -> Tensor: ...
    def arctanh(self) -> Tensor: ...
    def arctanh_(self, other) -> Tensor: ...
    def argmax(self, dim = ..., keepdim = ...) -> LongTensor: ...
    def argmin(self, dim = ..., keepdim = ...) -> LongTensor: ...
    def argsort(self, dim = ..., descending = ...) -> LongTensor: ...
    def argwhere(self) -> Tensor: ...
    def as_strided(self, size, stride, storage_offset = ...) -> Tensor: ...
    def as_strided_(self, *args, **kwargs) -> Any: ...
    def as_subclass(self, cls) -> Tensor: ...
    def asin(self) -> Tensor: ...
    def asin_(self) -> Tensor: ...
    def asinh(self) -> Tensor: ...
    def asinh_(self) -> Tensor: ...
    def atan(self) -> Tensor: ...
    def atan2(self, other) -> Tensor: ...
    def atan2_(self, other) -> Tensor: ...
    def atan_(self) -> Tensor: ...
    def atanh(self) -> Tensor: ...
    def atanh_(self, other) -> Tensor: ...
    def baddbmm(self, *args, **kwargs) -> Any: ...
    def baddbmm_(self, *args, **kwargs) -> Any: ...
    def bernoulli(self, *args, **kwargs) -> Any: ...
    def bernoulli_(self, *args, **kwargs) -> Any: ...
    @overload
    def bfloat16(self, memory_format = ...) -> Tensor: ...
    @overload
    def bfloat16() -> Any: ...
    def bincount(self, weights = ..., minlength = ...) -> Tensor: ...
    def bitwise_and(self) -> Tensor: ...
    def bitwise_and_(self) -> Tensor: ...
    def bitwise_left_shift(self, other) -> Tensor: ...
    def bitwise_left_shift_(self, other) -> Tensor: ...
    def bitwise_not(self) -> Tensor: ...
    def bitwise_not_(self) -> Tensor: ...
    def bitwise_or(self) -> Tensor: ...
    def bitwise_or_(self) -> Tensor: ...
    def bitwise_right_shift(self, other) -> Tensor: ...
    def bitwise_right_shift_(self, other) -> Tensor: ...
    def bitwise_xor(self) -> Tensor: ...
    def bitwise_xor_(self) -> Tensor: ...
    def bmm(self, batch2) -> Tensor: ...
    @overload
    def bool(self, memory_format = ...) -> Tensor: ...
    @overload
    def bool() -> Any: ...
    def broadcast_to(self, shape) -> Tensor: ...
    @overload
    def byte(self, memory_format = ...) -> Tensor: ...
    @overload
    def byte() -> Any: ...
    def cauchy_(self, *args, **kwargs) -> Any: ...
    def ccol_indices(self, *args, **kwargs) -> Any: ...
    @overload
    def cdouble(self, memory_format = ...) -> Tensor: ...
    @overload
    def cdouble() -> Any: ...
    def ceil(self) -> Tensor: ...
    def ceil_(self) -> Tensor: ...
    @overload
    def cfloat(self, memory_format = ...) -> Tensor: ...
    @overload
    def cfloat() -> Any: ...
    @overload
    def chalf(self, memory_format = ...) -> Tensor: ...
    @overload
    def chalf() -> Any: ...
    @overload
    def char(self, memory_format = ...) -> Tensor: ...
    @overload
    def char() -> Any: ...
    def cholesky(self, upper = ...) -> Tensor: ...
    def cholesky_inverse(self, upper = ...) -> Tensor: ...
    def cholesky_solve(self, input2, upper = ...) -> Tensor: ...
    def chunk(self, chunks, dim = ...) -> ListofTensors: ...
    def clamp(self, min = ..., max = ...) -> Tensor: ...
    def clamp_(self, min = ..., max = ...) -> Tensor: ...
    def clamp_max(self, *args, **kwargs) -> Any: ...
    def clamp_max_(self, *args, **kwargs) -> Any: ...
    def clamp_min(self, *args, **kwargs) -> Any: ...
    def clamp_min_(self, *args, **kwargs) -> Any: ...
    def clip(self, min = ..., max = ...) -> Tensor: ...
    def clip_(self, min = ..., max = ...) -> Tensor: ...
    def clone(self, *args, **kwargs) -> Any: ...
    def coalesce(self) -> Tensor: ...
    @overload
    def col_indices(self) -> IntTensor: ...
    @overload
    def col_indices() -> Any: ...
    def conj(self) -> Tensor: ...
    def conj_physical(self) -> Tensor: ...
    def conj_physical_(self) -> Tensor: ...
    def contiguous(self, memory_format = ...) -> Tensor: ...
    def copy_(self, src, non_blocking = ...) -> Tensor: ...
    def copysign(self, other) -> Tensor: ...
    def copysign_(self, other) -> Tensor: ...
    def corrcoef(self) -> Tensor: ...
    def cos(self) -> Tensor: ...
    def cos_(self) -> Tensor: ...
    def cosh(self) -> Tensor: ...
    def cosh_(self) -> Tensor: ...
    def count_nonzero(self, dim = ...) -> Tensor: ...
    def cov(self, *args, **kwargs) -> Any: ...
    def cpu(self, memory_format = ...) -> Tensor: ...
    def cross(self, other, dim = ...) -> Tensor: ...
    @overload
    def crow_indices(self) -> IntTensor: ...
    @overload
    def crow_indices() -> Any: ...

    def cuda(
        self, device = ..., non_blocking = ...,
        memory_format = ...) -> Tensor: ...

    def cummax(self, *args, **kwargs) -> Any: ...
    def cummin(self, *args, **kwargs) -> Any: ...
    def cumprod(self, dim, dtype = ...) -> Tensor: ...
    def cumprod_(self, dim, dtype = ...) -> Tensor: ...
    def cumsum(self, dim, dtype = ...) -> Tensor: ...
    def cumsum_(self, dim, dtype = ...) -> Tensor: ...
    def data_ptr(self) -> int: ...
    def deg2rad(self) -> Tensor: ...
    def deg2rad_(self) -> Tensor: ...
    def dense_dim(self) -> int: ...
    def dequantize(self) -> Tensor: ...
    def det(self) -> Tensor: ...
    def detach(self, *args, **kwargs) -> Any: ...
    def detach_(self, *args, **kwargs) -> Any: ...
    def diag(self, diagonal = ...) -> Tensor: ...
    def diag_embed(self, offset = ..., dim1 = ..., dim2 = ...) -> Tensor: ...
    def diagflat(self, offset = ...) -> Tensor: ...
    def diagonal(self, offset = ..., dim1 = ..., dim2 = ...) -> Tensor: ...
    def diagonal_scatter(self, *args, **kwargs) -> Any: ...

    def diff(
        self, n = ..., dim = ..., prepend = ..., append = ...) -> Tensor: ...

    def digamma(self) -> Tensor: ...
    def digamma_(self) -> Tensor: ...
    def dim(self) -> int: ...
    def dist(self, other, p = ...) -> Tensor: ...
    def div(self, *args, **kwargs) -> Any: ...
    def div_(self, *args, **kwargs) -> Any: ...
    def divide(self, *args, **kwargs) -> Any: ...
    def divide_(self, *args, **kwargs) -> Any: ...
    def dot(self, other) -> Tensor: ...
    @overload
    def double(self, memory_format = ...) -> Tensor: ...
    @overload
    def double() -> Any: ...
    def dsplit(self, split_size_or_sections) -> ListofTensors: ...
    def eig(self, *args, **kwargs) -> Any: ...
    @overload
    def element_size(self) -> int: ...
    @overload
    def element_size() -> Any: ...
    @overload
    def element_size() -> Any: ...
    def eq(self, other) -> Tensor: ...
    def eq_(self, other) -> Tensor: ...
    def equal(self, other) -> bool: ...
    def erf(self) -> Tensor: ...
    def erf_(self) -> Tensor: ...
    def erfc(self) -> Tensor: ...
    def erfc_(self) -> Tensor: ...
    def erfinv(self) -> Tensor: ...
    def erfinv_(self) -> Tensor: ...
    def exp(self) -> Tensor: ...
    def exp2(self) -> Tensor: ...
    def exp2_(self) -> Tensor: ...
    def exp_(self) -> Tensor: ...
    def expand(self, *sizes) -> Tensor: ...
    @overload
    def expand_as(self, other) -> Tensor: ...
    @overload
    def expand_as(other) -> Any: ...
    def expm1(self) -> Tensor: ...
    def expm1_(self) -> Tensor: ...
    def exponential_(self, *args, **kwargs) -> Any: ...
    def fill_(self, value) -> Tensor: ...
    def fill_diagonal_(self, fill_value, wrap = ...) -> Tensor: ...
    def fix(self) -> Tensor: ...
    def fix_(self) -> Tensor: ...
    def flatten(self, start_dim = ..., end_dim = ...) -> Tensor: ...
    def flip(self, dims) -> Tensor: ...
    def fliplr(self) -> Tensor: ...
    def flipud(self) -> Tensor: ...
    @overload
    def float(self, memory_format = ...) -> Tensor: ...
    @overload
    def float() -> Any: ...
    def float_power(self, exponent) -> Tensor: ...
    def float_power_(self, exponent) -> Tensor: ...
    def floor(self) -> Tensor: ...
    def floor_(self) -> Tensor: ...
    def floor_divide(self, value) -> Tensor: ...
    def floor_divide_(self, value) -> Tensor: ...
    def fmax(self, other) -> Tensor: ...
    def fmin(self, other) -> Tensor: ...
    def fmod(self, divisor) -> Tensor: ...
    def fmod_(self, divisor) -> Tensor: ...
    def frac(self) -> Tensor: ...
    def frac_(self) -> Tensor: ...
    def frexp(self, *args, **kwargs) -> Any: ...
    def gather(self, dim, index) -> Tensor: ...
    def gcd(self, other) -> Tensor: ...
    def gcd_(self, other) -> Tensor: ...
    def ge(self, other) -> Tensor: ...
    def ge_(self, other) -> Tensor: ...
    def geometric_(self, *args, **kwargs) -> Any: ...
    def geqrf(self, *args, **kwargs) -> Any: ...
    def ger(self, vec2) -> Tensor: ...
    @overload
    def get_device(self) -> Any: ...
    @overload
    def get_device() -> Any: ...
    def greater(self, other) -> Tensor: ...
    def greater_(self, other) -> Tensor: ...
    def greater_equal(self, other) -> Tensor: ...
    def greater_equal_(self, other) -> Tensor: ...
    def gt(self, other) -> Tensor: ...
    def gt_(self, other) -> Tensor: ...
    @overload
    def half(self, memory_format = ...) -> Tensor: ...
    @overload
    def half() -> Any: ...
    def hardshrink(self, lambd = ...) -> Tensor: ...
    def has_names(self, *args, **kwargs) -> Any: ...
    def heaviside(self, values) -> Tensor: ...
    def heaviside_(self, values) -> Tensor: ...
    def histc(self, bins = ..., min = ..., max = ...) -> Tensor: ...
    def histogram(self, *args, **kwargs) -> Any: ...
    def hsplit(self, split_size_or_sections) -> ListofTensors: ...
    def hypot(self, other) -> Tensor: ...
    def hypot_(self, other) -> Tensor: ...
    def i0(self) -> Tensor: ...
    def i0_(self) -> Tensor: ...
    def igamma(self, other) -> Tensor: ...
    def igamma_(self, other) -> Tensor: ...
    def igammac(self, other) -> Tensor: ...
    def igammac_(self, other) -> Tensor: ...
    def index_add(self, *args, **kwargs) -> Any: ...
    def index_add_(self, *args, **kwargs) -> Any: ...
    def index_copy(self, dim, index, tensor2) -> Tensor: ...
    def index_copy_(self, dim, index, tensor) -> Tensor: ...
    def index_fill(self, dim, index, value) -> Tensor: ...
    def index_fill_(self, dim, index, value) -> Tensor: ...
    def index_put(self, indices, values, accumulate = ...) -> Tensor: ...
    @overload
    def index_put_(self, indices, values, accumulate = ...) -> Tensor: ...
    @overload
    def index_put_(indices, values) -> Any: ...
    def index_reduce(self, *args, **kwargs) -> Any: ...
    def index_reduce_(self, *args, **kwargs) -> Any: ...
    def index_select(self, dim, index) -> Tensor: ...
    def indices(self) -> Tensor: ...
    def inner(self, other) -> Tensor: ...
    @overload
    def int(self, memory_format = ...) -> Tensor: ...
    @overload
    def int() -> Any: ...
    @overload
    def int_repr(self) -> Tensor: ...
    @overload
    def int_repr() -> Any: ...
    def inverse(self) -> Tensor: ...

    def ipu(
        self, device = ..., non_blocking = ...,
        memory_format = ...) -> Tensor: ...

    def is_coalesced(self) -> bool: ...
    def is_complex(self) -> bool: ...
    def is_conj(self) -> bool: ...
    def is_contiguous(self, memory_format = ...) -> bool: ...
    def is_distributed(self, *args, **kwargs) -> Any: ...
    def is_floating_point(self) -> bool: ...
    def is_inference(self) -> bool: ...
    def is_neg(self) -> bool: ...
    def is_nonzero(self, *args, **kwargs) -> Any: ...
    def is_pinned(self, *args, **kwargs) -> Any: ...
    def is_same_size(self, *args, **kwargs) -> Any: ...
    def is_set_to(self, tensor) -> bool: ...
    def is_signed(self) -> bool: ...

    def isclose(
        self, other, rtol = ..., atol = ..., equal_nan = ...) -> Tensor: ...

    def isfinite(self) -> Tensor: ...
    def isinf(self) -> Tensor: ...
    def isnan(self) -> Tensor: ...
    def isneginf(self) -> Tensor: ...
    def isposinf(self) -> Tensor: ...
    def isreal(self) -> Tensor: ...
    def istft(self, n_fft, hop_length = ..., win_length = ..., window = ..., 


center = ..., normalized = ..., onesided = ..., length = ...) -> Tensor: ...
    @overload
    def item(self) -> number: ...
    @overload
    def item() -> Any: ...
    def kron(self, other) -> Tensor: ...
    def kthvalue(self, *args, **kwargs) -> Any: ...
    def lcm(self, other) -> Tensor: ...
    def lcm_(self, other) -> Tensor: ...
    def ldexp(self, other) -> Tensor: ...
    def ldexp_(self, other) -> Tensor: ...
    def le(self, other) -> Tensor: ...
    def le_(self, other) -> Tensor: ...
    def lerp(self, end, weight) -> Tensor: ...
    def lerp_(self, end, weight) -> Tensor: ...
    def less(self, *args, **kwargs) -> Any: ...
    def less_(self, other) -> Tensor: ...
    def less_equal(self, other) -> Tensor: ...
    def less_equal_(self, other) -> Tensor: ...
    def lgamma(self) -> Tensor: ...
    def lgamma_(self) -> Tensor: ...
    def log(self) -> Tensor: ...
    def log10(self) -> Tensor: ...
    def log10_(self) -> Tensor: ...
    def log1p(self) -> Tensor: ...
    def log1p_(self) -> Tensor: ...
    def log2(self) -> Tensor: ...
    def log2_(self) -> Tensor: ...
    def log_(self) -> Tensor: ...
    def log_normal_(self, *args, **kwargs) -> Any: ...
    def log_softmax(self, *args, **kwargs) -> Any: ...
    def logaddexp(self, other) -> Tensor: ...
    def logaddexp2(self, other) -> Tensor: ...
    def logcumsumexp(self, dim) -> Tensor: ...
    def logdet(self) -> Tensor: ...
    def logical_and(self) -> Tensor: ...
    def logical_and_(self) -> Tensor: ...
    def logical_not(self) -> Tensor: ...
    def logical_not_(self) -> Tensor: ...
    def logical_or(self) -> Tensor: ...
    def logical_or_(self) -> Tensor: ...
    def logical_xor(self) -> Tensor: ...
    def logical_xor_(self) -> Tensor: ...
    def logit(self) -> Tensor: ...
    def logit_(self) -> Tensor: ...
    def logsumexp(self, dim, keepdim = ...) -> Tensor: ...
    @overload
    def long(self, memory_format = ...) -> Tensor: ...
    @overload
    def long() -> Any: ...
    def lstsq(self, *args, **kwargs) -> Any: ...
    def lt(self, other) -> Tensor: ...
    def lt_(self, other) -> Tensor: ...
    def lu_solve(self, LU_data, LU_pivots) -> Tensor: ...
    def map2_(self, *args, **kwargs) -> Any: ...
    def map_(self, tensor, callable) -> Any: ...
    def masked_fill(self, mask, value) -> Tensor: ...
    def masked_fill_(self, mask, value) -> Any: ...
    def masked_scatter(self, mask, tensor) -> Tensor: ...
    def masked_scatter_(self, mask, source) -> Any: ...
    def masked_select(self, mask) -> Tensor: ...
    def matmul(self, tensor2) -> Tensor: ...
    def matrix_exp(self) -> Tensor: ...
    def matrix_power(self, n) -> Tensor: ...
    def max(self, *args, **kwargs) -> Any: ...
    def maximum(self, other) -> Tensor: ...
    def mean(self, *args, **kwargs) -> Any: ...
    def median(self, *args, **kwargs) -> Any: ...
    def min(self, *args, **kwargs) -> Any: ...
    def minimum(self, other) -> Tensor: ...
    def mm(self, mat2) -> Tensor: ...
    def mode(self, *args, **kwargs) -> Any: ...
    def moveaxis(self, source, destination) -> Tensor: ...
    def movedim(self, source, destination) -> Tensor: ...
    def msort(self) -> Tensor: ...
    def mul(self, value) -> Tensor: ...
    def mul_(self, value) -> Tensor: ...
    def multinomial(self, *args, **kwargs) -> Any: ...
    def multiply(self, value) -> Tensor: ...
    def multiply_(self, value) -> Tensor: ...
    def mv(self, vec) -> Tensor: ...
    def mvlgamma(self, p) -> Tensor: ...
    def mvlgamma_(self, p) -> Tensor: ...
    def nan_to_num(self, nan = ..., posinf = ..., neginf = ...) -> Tensor: ...
    def nan_to_num_(self, nan = ..., posinf = ..., neginf = ...) -> Tensor: ...
    def nanmean(self, *args, **kwargs) -> Any: ...
    def nanmedian(self, *args, **kwargs) -> Any: ...
    def nanquantile(self, *args, **kwargs) -> Any: ...
    def nansum(self, dim = ..., keepdim = ..., dtype = ...) -> Tensor: ...
    def narrow(self, dimension, start, length) -> Tensor: ...
    def narrow_copy(self, dimension, start, length) -> Tensor: ...
    def ndimension(self) -> int: ...
    def ne(self, other) -> Tensor: ...
    def ne_(self, other) -> Tensor: ...
    def neg(self) -> Tensor: ...
    def neg_(self) -> Tensor: ...
    def negative(self) -> Tensor: ...
    def negative_(self) -> Tensor: ...
    def nelement(self) -> int: ...
    def new(self, *args, **kwargs) -> Any: ...

    def new_empty(
        self, size, dtype = ..., device = ...,
        requires_grad = ...) -> Tensor: ...

    def new_empty_strided(
        self, size, stride, dtype = ..., device = ...,
        requires_grad = ...) -> Tensor: ...

    def new_full(
        self, size, fill_value, dtype = ..., device = ...,
        requires_grad = ...) -> Tensor: ...

    def new_ones(
        self, size, dtype = ..., device = ...,
        requires_grad = ...) -> Tensor: ...

    @overload
    def new_tensor(
        self, data, dtype = ..., device = ...,
        requires_grad = ...) -> Tensor: ...

    @overload
    def new_tensor() -> Any: ...
    @overload
    def new_tensor(x) -> Any: ...
    @overload
    def new_tensor(x, requires_grad = ...) -> Any: ...
    @overload
    def new_tensor(data) -> Any: ...

    def new_zeros(
        self, size, dtype = ..., device = ...,
        requires_grad = ...) -> Tensor: ...

    def nextafter(self, other) -> Tensor: ...
    def nextafter_(self, other) -> Tensor: ...
    def nonzero(self) -> LongTensor: ...
    def norm(self, p = ..., dim = ..., keepdim = ...) -> Tensor: ...
    def normal_(self, *args, **kwargs) -> Any: ...
    def not_equal(self, other) -> Tensor: ...
    def not_equal_(self, other) -> Tensor: ...
    def numel(self) -> int: ...
    def numpy(self) -> numpy.ndarray: ...
    def orgqr(self, input2) -> Tensor: ...
    def ormqr(self, input2, input3, left = ..., transpose = ...) -> Tensor: ...
    def outer(self, vec2) -> Tensor: ...
    def permute(self, *dims) -> Tensor: ...
    def pin_memory(self) -> Tensor: ...
    def pinverse(self) -> Tensor: ...
    def polygamma(self, n) -> Tensor: ...
    def polygamma_(self, n) -> Tensor: ...
    def positive(self) -> Tensor: ...
    def pow(self, exponent) -> Tensor: ...
    def pow_(self, exponent) -> Tensor: ...
    def prelu(self, *args, **kwargs) -> Any: ...
    def prod(self, dim = ..., keepdim = ..., dtype = ...) -> Tensor: ...
    def put(self, input, index, source, accumulate = ...) -> Tensor: ...
    def put_(self, index, source, accumulate = ...) -> Tensor: ...
    def q_per_channel_axis(self) -> int: ...
    def q_per_channel_scales(self) -> Tensor: ...
    def q_per_channel_zero_points(self) -> Tensor: ...
    def q_scale(self) -> float: ...
    def q_zero_point(self) -> int: ...
    def qr(self, *args, **kwargs) -> Any: ...
    def qscheme(self) -> torch.qscheme: ...
    def quantile(self, *args, **kwargs) -> Any: ...
    def rad2deg(self) -> Tensor: ...
    def rad2deg_(self) -> Tensor: ...
    def random_(self) -> Any: ...
    def ravel(self) -> Tensor: ...
    def reciprocal(self) -> Tensor: ...
    def reciprocal_(self) -> Tensor: ...
    def record_stream(self, stream) -> Any: ...
    def refine_names(self, *args, **kwargs) -> Any: ...
    def relu(self, *args, **kwargs) -> Any: ...
    def relu_(self, *args, **kwargs) -> Any: ...
    def remainder(self, divisor) -> Tensor: ...
    def remainder_(self, divisor) -> Tensor: ...
    def rename(self, *args, **kwargs) -> Any: ...
    def rename_(self, *args, **kwargs) -> Any: ...
    def renorm(self, p, dim, maxnorm) -> Tensor: ...
    def renorm_(self, p, dim, maxnorm) -> Tensor: ...
    def repeat(self, *sizes) -> Tensor: ...
    def repeat_interleave(self, *args, **kwargs) -> Any: ...
    @overload
    def requires_grad_(self, requires_grad = ...) -> Tensor: ...
    @overload
    def requires_grad_() -> Any: ...
    @overload
    def requires_grad_() -> Any: ...
    def reshape(self, *shape) -> Tensor: ...
    @overload
    def reshape_as(self, other) -> Tensor: ...
    @overload
    def reshape_as(other) -> Any: ...
    def resize_(self, *sizes, memory_format = ...) -> Tensor: ...
    def resize_as_(self, tensor, memory_format = ...) -> Tensor: ...
    def resize_as_sparse_(self, *args, **kwargs) -> Any: ...
    def resolve_conj(self) -> Tensor: ...
    def resolve_neg(self) -> Tensor: ...
    def retain_grad(self) -> None: ...
    def roll(self, shifts, dims) -> Tensor: ...
    def rot90(self, k, dims) -> Tensor: ...
    def round(self, decimals = ...) -> Tensor: ...
    def round_(self, decimals = ...) -> Tensor: ...
    def row_indices(self, *args, **kwargs) -> Any: ...
    def rsqrt(self) -> Tensor: ...
    def rsqrt_(self) -> Tensor: ...
    def scatter(self, dim, index, src) -> Tensor: ...
    def scatter_(self, dim, index, src, reduce = ...) -> Tensor: ...
    def scatter_add(self, dim, index, src) -> Tensor: ...
    def scatter_add_(self, dim, index, src) -> Tensor: ...
    def scatter_reduce(self, *args, **kwargs) -> Any: ...
    def scatter_reduce_(self, *args, **kwargs) -> Any: ...
    def select(self, dim, index) -> Tensor: ...
    def select_scatter(self, src, dim, index) -> Tensor: ...

    def set_(
        self, source = ..., storage_offset = ..., size = ...,
        stride = ...) -> Tensor: ...

    def sgn(self) -> Tensor: ...
    def sgn_(self) -> Tensor: ...
    @overload
    def short(self, memory_format = ...) -> Tensor: ...
    @overload
    def short() -> Any: ...
    def sigmoid(self) -> Tensor: ...
    def sigmoid_(self) -> Tensor: ...
    def sign(self) -> Tensor: ...
    def sign_(self) -> Tensor: ...
    def signbit(self) -> Tensor: ...
    def sin(self) -> Tensor: ...
    def sin_(self) -> Tensor: ...
    def sinc(self) -> Tensor: ...
    def sinc_(self) -> Tensor: ...
    def sinh(self) -> Tensor: ...
    def sinh_(self) -> Tensor: ...
    @overload
    def size(self, dim = ...) -> torch.Sizeorint: ...
    @overload
    def size() -> Any: ...
    @overload
    def size(dim = ...) -> Any: ...

    def slice_scatter(
        self, src, dim = ..., start = ..., end = ...,
        step = ...) -> Tensor: ...

    def slogdet(self, *args, **kwargs) -> Any: ...
    def smm(self, mat) -> Tensor: ...
    def softmax(self, *args, **kwargs) -> Any: ...
    def sort(self, *args, **kwargs) -> Any: ...
    def sparse_dim(self) -> int: ...
    @overload
    def sparse_mask(self, mask) -> Tensor: ...
    @overload
    def sparse_mask(S) -> Any: ...
    def sparse_resize_(self, size, sparse_dim, dense_dim) -> Tensor: ...

    def sparse_resize_and_clear_(
        self, size, sparse_dim, dense_dim) -> Tensor: ...

    def split(self, *args, **kwargs) -> Any: ...
    def split_with_sizes(self, *args, **kwargs) -> Any: ...
    def sqrt(self) -> Tensor: ...
    def sqrt_(self) -> Tensor: ...
    def square(self) -> Tensor: ...
    def square_(self) -> Tensor: ...
    def squeeze(self, dim = ...) -> Tensor: ...
    def squeeze_(self, dim = ...) -> Tensor: ...
    def sspaddmm(self, *args, **kwargs) -> Any: ...
    @overload
    def std(self, dim, unbiased = ..., keepdim = ...) -> Tensor: ...
    @overload
    def std(unbiased = ...) -> Tensor: ...

    def stft(
        self, frame_length, hop, fft_size = ..., return_onesided = ...,
        window = ..., pad_end = ...) -> Tensor: ...

    @overload
    def storage_offset(self) -> int: ...
    @overload
    def storage_offset() -> Any: ...
    @overload
    def storage_offset() -> Any: ...
    @overload
    def stride(self, dim) -> tupleorint: ...
    @overload
    def stride() -> Any: ...
    def sub(self, *args, **kwargs) -> Any: ...
    def sub_(self, *args, **kwargs) -> Any: ...
    def subtract(self, *args, **kwargs) -> Any: ...
    def subtract_(self, *args, **kwargs) -> Any: ...
    def sum(self, dim = ..., keepdim = ..., dtype = ...) -> Tensor: ...
    def sum_to_size(self, *size) -> Tensor: ...
    def svd(self, *args, **kwargs) -> Any: ...
    def swapaxes(self, axis0, axis1) -> Tensor: ...
    def swapaxes_(self, axis0, axis1) -> Tensor: ...
    def swapdims(self, dim0, dim1) -> Tensor: ...
    def swapdims_(self, dim0, dim1) -> Tensor: ...
    def symeig(self, *args, **kwargs) -> Any: ...
    def t(self) -> Tensor: ...
    def t_(self) -> Tensor: ...
    def take(self, indices) -> Tensor: ...
    def take_along_dim(self, indices, dim) -> Tensor: ...
    def tan(self) -> Tensor: ...
    def tan_(self) -> Tensor: ...
    def tanh(self) -> Tensor: ...
    def tanh_(self) -> Tensor: ...

    def tensor_split(
        self, indices_or_sections, dim = ...) -> ListofTensors: ...

    def tile(self, *reps) -> Tensor: ...

    @overload
    def to(
        self, dtype, non_blocking = ..., copy = ...,
        memory_format = ...) -> Tensor: ...

    @overload
    def to(
        device = ..., dtype = ..., non_blocking = ..., copy = ...,
        memory_format = ...) -> Tensor: ...

    @overload
    def to(other, non_blocking = ..., copy = ...) -> Tensor: ...
    @overload
    def to(cuda0) -> Any: ...
    @overload
    def to(cuda0, dtype = ...) -> Any: ...
    @overload
    def to(other, non_blocking = ...) -> Any: ...
    @overload
    def to(*args, **kwargs) -> Tensor: ...
    @overload
    def to(*args, **kwargs) -> Any: ...
    @overload
    def to_dense(self) -> Tensor: ...
    @overload
    def to_dense() -> Any: ...
    def to_mkldnn(self) -> Tensor: ...
    def to_padded_tensor(self, *args, **kwargs) -> Any: ...
    @overload
    def to_sparse(self, sparseDims) -> Tensor: ...
    @overload
    def to_sparse() -> Any: ...
    def to_sparse_bsc(self, *args, **kwargs) -> Any: ...
    def to_sparse_bsr(self, blocksize) -> Tensor: ...
    def to_sparse_csc(self, *args, **kwargs) -> Any: ...
    @overload
    def to_sparse_csr(self) -> Tensor: ...
    @overload
    def to_sparse_csr() -> Any: ...
    @overload
    def tolist(self) -> listornumber: ...
    @overload
    def tolist() -> Any: ...
    @overload
    def tolist() -> Any: ...
    def topk(self, *args, **kwargs) -> Any: ...
    def trace(self) -> Tensor: ...
    def transpose(self, dim0, dim1) -> Tensor: ...
    def transpose_(self, dim0, dim1) -> Tensor: ...
    def triangular_solve(self, *args, **kwargs) -> Any: ...
    def tril(self, diagonal = ...) -> Tensor: ...
    def tril_(self, diagonal = ...) -> Tensor: ...
    def triu(self, diagonal = ...) -> Tensor: ...
    def triu_(self, diagonal = ...) -> Tensor: ...
    def true_divide(self, value) -> Tensor: ...
    def true_divide_(self, value) -> Tensor: ...
    def trunc(self) -> Tensor: ...
    def trunc_(self) -> Tensor: ...

    def type(
        self, dtype = ..., non_blocking = ..., **kwargs) -> strorTensor: ...

    def type_as(self, tensor) -> Tensor: ...
    def unbind(self, dim = ...) -> seq: ...
    def unflatten(self, *args, **kwargs) -> Any: ...
    def unfold(self, dimension, size, step) -> Tensor: ...
    def uniform_(self, from = ..., to = ...) -> Tensor: ...
    def unsafe_chunk(self, chunks, dim = ...) -> ListofTensors: ...
    def unsafe_split(self, split_size, dim = ...) -> ListofTensors: ...
    def unsafe_split_with_sizes(self, *args, **kwargs) -> Any: ...
    def unsqueeze(self, dim) -> Tensor: ...
    def unsqueeze_(self, dim) -> Tensor: ...
    def values(self) -> Tensor: ...
    @overload
    def var(self, dim, unbiased = ..., keepdim = ...) -> Tensor: ...
    @overload
    def var(unbiased = ...) -> Tensor: ...
    def vdot(self, other) -> Tensor: ...
    @overload
    def view(self, *shape) -> Tensor: ...
    @overload
    def view(dtype) -> Tensor: ...
    @overload
    def view_as(self, other) -> Tensor: ...
    @overload
    def view_as(other) -> Any: ...
    def vsplit(self, split_size_or_sections) -> ListofTensors: ...
    def where(self, condition, y) -> Tensor: ...
    def xlogy(self, other) -> Tensor: ...
    def xlogy_(self, other) -> Tensor: ...

    def xpu(
        self, device = ..., non_blocking = ...,
        memory_format = ...) -> Tensor: ...

    def zero_(self) -> Tensor: ...
    def __add__(self, other) -> Any: ...
    def __and__(self, other) -> Any: ...
    def __bool__(self) -> Any: ...
    def __complex__(self) -> Any: ...
    def __delitem__(self, other) -> Any: ...
    def __div__(self, *args, **kwargs) -> Any: ...
    def __eq__(self, other) -> Any: ...
    def __float__(self) -> Any: ...
    def __floordiv__(self, other) -> Any: ...
    def __ge__(self, other) -> Any: ...
    def __getitem__(self, index) -> Any: ...
    def __gt__(self, other) -> Any: ...
    def __iadd__(self, other) -> Any: ...
    def __iand__(self, other) -> Any: ...
    def __idiv__(self, *args, **kwargs) -> Any: ...
    def __ifloordiv__(self, other) -> Any: ...
    def __ilshift__(self, other) -> Any: ...
    def __imod__(self, other) -> Any: ...
    def __imul__(self, other) -> Any: ...
    def __index__(self) -> Any: ...
    def __int__(self) -> Any: ...
    def __invert__(self) -> Any: ...
    def __ior__(self, other) -> Any: ...
    def __irshift__(self, other) -> Any: ...
    def __isub__(self, other) -> Any: ...
    def __ixor__(self, other) -> Any: ...
    def __le__(self, other) -> Any: ...
    def __len__(self) -> Any: ...
    def __long__(self, *args, **kwargs) -> Any: ...
    def __lshift__(self, other) -> Any: ...
    def __lt__(self, other) -> Any: ...
    def __matmul__(self, *args, **kwargs) -> Any: ...
    def __mod__(self, other) -> Any: ...
    def __mul__(self, other) -> Any: ...
    def __ne__(self, other) -> Any: ...
    def __nonzero__(self, *args, **kwargs) -> Any: ...
    def __or__(self, other) -> Any: ...
    def __radd__(self, other) -> Any: ...
    def __rand__(self, other) -> Any: ...
    def __rmul__(self, other) -> Any: ...
    def __ror__(self, other) -> Any: ...
    def __rshift__(self, other) -> Any: ...
    def __rxor__(self, other) -> Any: ...
    def __setitem__(self, index, object) -> Any: ...
    def __sub__(self, other) -> Any: ...
    def __truediv__(self, other) -> Any: ...
    def __xor__(self, other) -> Any: ...


class _TensorMeta(type):
    def __init__(self, *args, **kwargs) -> None: ...


class _UpgraderEntry:
    def __init__(self, arg0: int, arg1: str, arg2: str) -> None: ...
    @property
    def bumped_at_version(self) -> int: ...
    @property
    def old_schema(self) -> str: ...
    @property
    def upgrader_name(self) -> str: ...


class _UpgraderRange:
    def __init__(self, arg0: int, arg1: int) -> None: ...
    @property
    def max_version(self) -> int: ...
    @property
    def min_version(self) -> int: ...


class _VariableFunctionsClass:
    def _adaptive_avg_pool2d(self, *args, **kwargs) -> Any: ...
    def _adaptive_avg_pool3d(self, *args, **kwargs) -> Any: ...
    def _add_batch_dim(self, *args, **kwargs) -> Any: ...
    def _add_relu(self, *args, **kwargs) -> Any: ...
    def _add_relu_(self, *args, **kwargs) -> Any: ...
    def _addmm_activation(self, *args, **kwargs) -> Any: ...
    def _aminmax(self, *args, **kwargs) -> Any: ...

    def _amp_foreach_non_finite_check_and_unscale_(
        self, *args, **kwargs) -> Any: ...

    def _amp_update_scale_(self, *args, **kwargs) -> Any: ...
    def _assert_async(self, *args, **kwargs) -> Any: ...
    def _batch_norm_impl_index(self, *args, **kwargs) -> Any: ...
    def _cast_Byte(self, *args, **kwargs) -> Any: ...
    def _cast_Char(self, *args, **kwargs) -> Any: ...
    def _cast_Double(self, *args, **kwargs) -> Any: ...
    def _cast_Float(self, *args, **kwargs) -> Any: ...
    def _cast_Half(self, *args, **kwargs) -> Any: ...
    def _cast_Int(self, *args, **kwargs) -> Any: ...
    def _cast_Long(self, *args, **kwargs) -> Any: ...
    def _cast_Short(self, *args, **kwargs) -> Any: ...
    def _choose_qparams_per_tensor(self, *args, **kwargs) -> Any: ...
    def _coalesce(self, *args, **kwargs) -> Any: ...
    def _compute_linear_combination(self, *args, **kwargs) -> Any: ...
    def _conj(self, *args, **kwargs) -> Any: ...
    def _conj_copy(self, *args, **kwargs) -> Any: ...
    def _conj_physical(self, *args, **kwargs) -> Any: ...
    def _convert_indices_from_coo_to_csr(self, *args, **kwargs) -> Any: ...
    def _convert_indices_from_csr_to_coo(self, *args, **kwargs) -> Any: ...
    def _convolution(self, *args, **kwargs) -> Any: ...
    def _convolution_mode(self, *args, **kwargs) -> Any: ...
    def _copy_from(self, *args, **kwargs) -> Any: ...
    def _copy_from_and_resize(self, *args, **kwargs) -> Any: ...
    def _ctc_loss(self, *args, **kwargs) -> Any: ...
    def _cudnn_ctc_loss(self, *args, **kwargs) -> Any: ...
    def _cudnn_init_dropout_state(self, *args, **kwargs) -> Any: ...
    def _cudnn_rnn(self, *args, **kwargs) -> Any: ...
    def _cudnn_rnn_flatten_weight(self, *args, **kwargs) -> Any: ...
    def _cufft_clear_plan_cache(self, *args, **kwargs) -> Any: ...
    def _cufft_get_plan_cache_max_size(self, *args, **kwargs) -> Any: ...
    def _cufft_get_plan_cache_size(self, *args, **kwargs) -> Any: ...
    def _cufft_set_plan_cache_max_size(self, *args, **kwargs) -> Any: ...
    def _cummax_helper(self, *args, **kwargs) -> Any: ...
    def _cummin_helper(self, *args, **kwargs) -> Any: ...
    def _debug_has_internal_overlap(self, *args, **kwargs) -> Any: ...
    def _det_lu_based_helper(self, *args, **kwargs) -> Any: ...
    def _det_lu_based_helper_backward_helper(self, *args, **kwargs) -> Any: ...
    def _dim_arange(self, *args, **kwargs) -> Any: ...
    def _dirichlet_grad(self, *args, **kwargs) -> Any: ...
    def _disable_functionalization(self, *args, **kwargs) -> Any: ...
    def _efficientzerotensor(self, *args, **kwargs) -> Any: ...
    def _embedding_bag(self, *args, **kwargs) -> Any: ...
    def _embedding_bag_forward_only(self, *args, **kwargs) -> Any: ...
    def _empty_affine_quantized(self, *args, **kwargs) -> Any: ...
    def _empty_per_channel_affine_quantized(self, *args, **kwargs) -> Any: ...
    def _enable_functionalization(self, *args, **kwargs) -> Any: ...
    def _euclidean_dist(self, *args, **kwargs) -> Any: ...

    def _fake_quantize_learnable_per_channel_affine(
        self, *args, **kwargs) -> Any: ...

    def _fake_quantize_learnable_per_tensor_affine(
        self, *args, **kwargs) -> Any: ...

    def _fake_quantize_per_tensor_affine_cachemask_tensor_qparams(
        self, *args, **kwargs) -> Any: ...

    def _fft_c2c(self, *args, **kwargs) -> Any: ...
    def _fft_c2r(self, *args, **kwargs) -> Any: ...
    def _fft_r2c(self, *args, **kwargs) -> Any: ...
    def _foreach_abs(self, *args, **kwargs) -> Any: ...
    def _foreach_abs_(self, *args, **kwargs) -> Any: ...
    def _foreach_acos(self, *args, **kwargs) -> Any: ...
    def _foreach_acos_(self, *args, **kwargs) -> Any: ...
    def _foreach_add(self, *args, **kwargs) -> Any: ...
    def _foreach_add_(self, *args, **kwargs) -> Any: ...
    def _foreach_addcdiv(self, *args, **kwargs) -> Any: ...
    def _foreach_addcdiv_(self, *args, **kwargs) -> Any: ...
    def _foreach_addcmul(self, *args, **kwargs) -> Any: ...
    def _foreach_addcmul_(self, *args, **kwargs) -> Any: ...
    def _foreach_asin(self, *args, **kwargs) -> Any: ...
    def _foreach_asin_(self, *args, **kwargs) -> Any: ...
    def _foreach_atan(self, *args, **kwargs) -> Any: ...
    def _foreach_atan_(self, *args, **kwargs) -> Any: ...
    def _foreach_ceil(self, *args, **kwargs) -> Any: ...
    def _foreach_ceil_(self, *args, **kwargs) -> Any: ...
    def _foreach_cos(self, *args, **kwargs) -> Any: ...
    def _foreach_cos_(self, *args, **kwargs) -> Any: ...
    def _foreach_cosh(self, *args, **kwargs) -> Any: ...
    def _foreach_cosh_(self, *args, **kwargs) -> Any: ...
    def _foreach_div(self, *args, **kwargs) -> Any: ...
    def _foreach_div_(self, *args, **kwargs) -> Any: ...
    def _foreach_erf(self, *args, **kwargs) -> Any: ...
    def _foreach_erf_(self, *args, **kwargs) -> Any: ...
    def _foreach_erfc(self, *args, **kwargs) -> Any: ...
    def _foreach_erfc_(self, *args, **kwargs) -> Any: ...
    def _foreach_exp(self, *args, **kwargs) -> Any: ...
    def _foreach_exp_(self, *args, **kwargs) -> Any: ...
    def _foreach_expm1(self, *args, **kwargs) -> Any: ...
    def _foreach_expm1_(self, *args, **kwargs) -> Any: ...
    def _foreach_floor(self, *args, **kwargs) -> Any: ...
    def _foreach_floor_(self, *args, **kwargs) -> Any: ...
    def _foreach_frac(self, *args, **kwargs) -> Any: ...
    def _foreach_frac_(self, *args, **kwargs) -> Any: ...
    def _foreach_lgamma(self, *args, **kwargs) -> Any: ...
    def _foreach_lgamma_(self, *args, **kwargs) -> Any: ...
    def _foreach_log(self, *args, **kwargs) -> Any: ...
    def _foreach_log10(self, *args, **kwargs) -> Any: ...
    def _foreach_log10_(self, *args, **kwargs) -> Any: ...
    def _foreach_log1p(self, *args, **kwargs) -> Any: ...
    def _foreach_log1p_(self, *args, **kwargs) -> Any: ...
    def _foreach_log2(self, *args, **kwargs) -> Any: ...
    def _foreach_log2_(self, *args, **kwargs) -> Any: ...
    def _foreach_log_(self, *args, **kwargs) -> Any: ...
    def _foreach_maximum(self, *args, **kwargs) -> Any: ...
    def _foreach_minimum(self, *args, **kwargs) -> Any: ...
    def _foreach_mul(self, *args, **kwargs) -> Any: ...
    def _foreach_mul_(self, *args, **kwargs) -> Any: ...
    def _foreach_neg(self, *args, **kwargs) -> Any: ...
    def _foreach_neg_(self, *args, **kwargs) -> Any: ...
    def _foreach_norm(self, *args, **kwargs) -> Any: ...
    def _foreach_reciprocal(self, *args, **kwargs) -> Any: ...
    def _foreach_reciprocal_(self, *args, **kwargs) -> Any: ...
    def _foreach_round(self, *args, **kwargs) -> Any: ...
    def _foreach_round_(self, *args, **kwargs) -> Any: ...
    def _foreach_sigmoid(self, *args, **kwargs) -> Any: ...
    def _foreach_sigmoid_(self, *args, **kwargs) -> Any: ...
    def _foreach_sin(self, *args, **kwargs) -> Any: ...
    def _foreach_sin_(self, *args, **kwargs) -> Any: ...
    def _foreach_sinh(self, *args, **kwargs) -> Any: ...
    def _foreach_sinh_(self, *args, **kwargs) -> Any: ...
    def _foreach_sqrt(self, *args, **kwargs) -> Any: ...
    def _foreach_sqrt_(self, *args, **kwargs) -> Any: ...
    def _foreach_sub(self, *args, **kwargs) -> Any: ...
    def _foreach_sub_(self, *args, **kwargs) -> Any: ...
    def _foreach_tan(self, *args, **kwargs) -> Any: ...
    def _foreach_tan_(self, *args, **kwargs) -> Any: ...
    def _foreach_tanh(self, *args, **kwargs) -> Any: ...
    def _foreach_tanh_(self, *args, **kwargs) -> Any: ...
    def _foreach_trunc(self, *args, **kwargs) -> Any: ...
    def _foreach_trunc_(self, *args, **kwargs) -> Any: ...
    def _foreach_zero_(self, *args, **kwargs) -> Any: ...
    def _from_functional_tensor(self, *args, **kwargs) -> Any: ...
    def _fused_dropout(self, *args, **kwargs) -> Any: ...
    def _fused_moving_avg_obs_fq_helper(self, *args, **kwargs) -> Any: ...
    def _fw_primal_copy(self, *args, **kwargs) -> Any: ...
    def _grid_sampler_2d_cpu_fallback(self, *args, **kwargs) -> Any: ...
    def _has_compatible_shallow_copy_type(self, *args, **kwargs) -> Any: ...
    def _histogramdd_bin_edges(self, *args, **kwargs) -> Any: ...
    def _histogramdd_from_bin_cts(self, *args, **kwargs) -> Any: ...
    def _histogramdd_from_bin_tensors(self, *args, **kwargs) -> Any: ...
    def _index_put_impl_(self, *args, **kwargs) -> Any: ...
    def _indices_copy(self, *args, **kwargs) -> Any: ...
    def _is_functional_tensor(self, *args, **kwargs) -> Any: ...
    def _is_zerotensor(self, *args, **kwargs) -> Any: ...
    def _linalg_check_errors(self, *args, **kwargs) -> Any: ...
    def _linalg_inv_out_helper_(self, *args, **kwargs) -> Any: ...
    def _linalg_qr_helper(self, *args, **kwargs) -> Any: ...
    def _linalg_svd(self, *args, **kwargs) -> Any: ...
    def _log_softmax(self, *args, **kwargs) -> Any: ...
    def _log_softmax_backward_data(self, *args, **kwargs) -> Any: ...
    def _logcumsumexp(self, *args, **kwargs) -> Any: ...
    def _lstm_mps(self, *args, **kwargs) -> Any: ...
    def _lu_with_info(self, *args, **kwargs) -> Any: ...
    def _make_dual(self, *args, **kwargs) -> Any: ...
    def _make_dual_copy(self, *args, **kwargs) -> Any: ...
    def _make_per_channel_quantized_tensor(self, *args, **kwargs) -> Any: ...
    def _make_per_tensor_quantized_tensor(self, *args, **kwargs) -> Any: ...
    def _masked_scale(self, *args, **kwargs) -> Any: ...
    def _masked_softmax(self, *args, **kwargs) -> Any: ...
    def _mkldnn_reshape(self, *args, **kwargs) -> Any: ...
    def _mkldnn_transpose(self, *args, **kwargs) -> Any: ...
    def _mkldnn_transpose_(self, *args, **kwargs) -> Any: ...
    def _mps_convolution(self, *args, **kwargs) -> Any: ...
    def _mps_convolution_transpose(self, *args, **kwargs) -> Any: ...
    def _mps_linear_backward_weights(self, *args, **kwargs) -> Any: ...
    def _mps_max_pool2d(self, *args, **kwargs) -> Any: ...
    def _native_multi_head_attention(self, *args, **kwargs) -> Any: ...
    def _neg_view(self, *args, **kwargs) -> Any: ...
    def _neg_view_copy(self, *args, **kwargs) -> Any: ...
    def _nested_from_padded(self, *args, **kwargs) -> Any: ...

    def _nested_from_padded_and_nested_example(
        self, *args, **kwargs) -> Any: ...

    def _nested_tensor_from_mask(self, *args, **kwargs) -> Any: ...
    def _nnpack_available(self, *args, **kwargs) -> Any: ...
    def _nnpack_spatial_convolution(self, *args, **kwargs) -> Any: ...
    def _pack_padded_sequence(self, *args, **kwargs) -> Any: ...
    def _pad_packed_sequence(self, *args, **kwargs) -> Any: ...
    def _pin_memory(self, *args, **kwargs) -> Any: ...
    def _remove_batch_dim(self, *args, **kwargs) -> Any: ...
    def _reshape_alias_copy(self, *args, **kwargs) -> Any: ...
    def _reshape_from_tensor(self, *args, **kwargs) -> Any: ...
    def _resize_output_(self, *args, **kwargs) -> Any: ...
    def _rowwise_prune(self, *args, **kwargs) -> Any: ...
    def _sample_dirichlet(self, *args, **kwargs) -> Any: ...
    def _saturate_weight_to_fp16(self, *args, **kwargs) -> Any: ...
    def _shape_as_tensor(self, *args, **kwargs) -> Any: ...
    def _sobol_engine_draw(self, *args, **kwargs) -> Any: ...
    def _sobol_engine_ff_(self, *args, **kwargs) -> Any: ...
    def _sobol_engine_initialize_state_(self, *args, **kwargs) -> Any: ...
    def _sobol_engine_scramble_(self, *args, **kwargs) -> Any: ...
    def _softmax(self, *args, **kwargs) -> Any: ...
    def _softmax_backward_data(self, *args, **kwargs) -> Any: ...
    def _sparse_broadcast_to(self, *args, **kwargs) -> Any: ...
    def _sparse_broadcast_to_copy(self, *args, **kwargs) -> Any: ...
    def _sparse_bsc_tensor_unsafe(self, *args, **kwargs) -> Any: ...
    def _sparse_bsr_tensor_unsafe(self, *args, **kwargs) -> Any: ...
    def _sparse_compressed_tensor_unsafe(self, *args, **kwargs) -> Any: ...
    def _sparse_coo_tensor_unsafe(self, *args, **kwargs) -> Any: ...
    def _sparse_csc_tensor_unsafe(self, *args, **kwargs) -> Any: ...
    def _sparse_csr_prod(self, *args, **kwargs) -> Any: ...
    def _sparse_csr_sum(self, *args, **kwargs) -> Any: ...
    def _sparse_csr_tensor_unsafe(self, *args, **kwargs) -> Any: ...
    def _sparse_log_softmax_backward_data(self, *args, **kwargs) -> Any: ...
    def _sparse_mask_helper(self, *args, **kwargs) -> Any: ...
    def _sparse_softmax_backward_data(self, *args, **kwargs) -> Any: ...
    def _sparse_sparse_matmul(self, *args, **kwargs) -> Any: ...
    def _sparse_sum(self, *args, **kwargs) -> Any: ...
    def _stack(self, *args, **kwargs) -> Any: ...
    def _standard_gamma(self, *args, **kwargs) -> Any: ...
    def _standard_gamma_grad(self, *args, **kwargs) -> Any: ...
    def _sync(self, *args, **kwargs) -> Any: ...
    def _test_serialization_subcmul(self, *args, **kwargs) -> Any: ...
    def _to_cpu(self, *args, **kwargs) -> Any: ...
    def _to_functional_tensor(self, *args, **kwargs) -> Any: ...
    def _torch_cuda_cu_linker_symbol_op(self, *args, **kwargs) -> Any: ...
    def _transform_bias_rescale_qkv(self, *args, **kwargs) -> Any: ...
    def _transformer_encoder_layer_fwd(self, *args, **kwargs) -> Any: ...
    def _trilinear(self, *args, **kwargs) -> Any: ...
    def _unique(self, *args, **kwargs) -> Any: ...
    def _unique2(self, *args, **kwargs) -> Any: ...
    def _unpack_dual(self, *args, **kwargs) -> Any: ...
    def _use_cudnn_ctc_loss(self, *args, **kwargs) -> Any: ...
    def _use_cudnn_rnn_flatten_weight(self, *args, **kwargs) -> Any: ...
    def _validate_sparse_bsc_tensor_args(self, *args, **kwargs) -> Any: ...
    def _validate_sparse_bsr_tensor_args(self, *args, **kwargs) -> Any: ...

    def _validate_sparse_compressed_tensor_args(
        self, *args, **kwargs) -> Any: ...

    def _validate_sparse_coo_tensor_args(self, *args, **kwargs) -> Any: ...
    def _validate_sparse_csc_tensor_args(self, *args, **kwargs) -> Any: ...
    def _validate_sparse_csr_tensor_args(self, *args, **kwargs) -> Any: ...
    def _values_copy(self, *args, **kwargs) -> Any: ...
    def _weight_norm(self, *args, **kwargs) -> Any: ...
    def _weight_norm_interface(self, *args, **kwargs) -> Any: ...
    def abs(self, *args, **kwargs) -> Any: ...
    def abs_(self, *args, **kwargs) -> Any: ...
    def absolute(self, *args, **kwargs) -> Any: ...
    def acos(self, *args, **kwargs) -> Any: ...
    def acos_(self, *args, **kwargs) -> Any: ...
    def acosh(self, *args, **kwargs) -> Any: ...
    def acosh_(self, *args, **kwargs) -> Any: ...
    def adaptive_avg_pool1d(self, *args, **kwargs) -> Any: ...
    def adaptive_max_pool1d(self, *args, **kwargs) -> Any: ...
    def add(self, *args, **kwargs) -> Any: ...
    def addbmm(self, *args, **kwargs) -> Any: ...
    def addcdiv(self, *args, **kwargs) -> Any: ...
    def addcmul(self, *args, **kwargs) -> Any: ...
    def addmm(self, *args, **kwargs) -> Any: ...
    def addmv(self, *args, **kwargs) -> Any: ...
    def addmv_(self, *args, **kwargs) -> Any: ...
    def addr(self, *args, **kwargs) -> Any: ...
    def adjoint(self, *args, **kwargs) -> Any: ...
    def affine_grid_generator(self, *args, **kwargs) -> Any: ...
    def alias_copy(self, *args, **kwargs) -> Any: ...
    def align_tensors(self, *args, **kwargs) -> Any: ...
    def all(self, *args, **kwargs) -> Any: ...
    def allclose(self, *args, **kwargs) -> Any: ...
    def alpha_dropout(self, *args, **kwargs) -> Any: ...
    def alpha_dropout_(self, *args, **kwargs) -> Any: ...
    def amax(self, *args, **kwargs) -> Any: ...
    def amin(self, *args, **kwargs) -> Any: ...
    def aminmax(self, *args, **kwargs) -> Any: ...
    def angle(self, *args, **kwargs) -> Any: ...
    def any(self, *args, **kwargs) -> Any: ...
    def arange(self, *args, **kwargs) -> Any: ...
    def arccos(self, *args, **kwargs) -> Any: ...
    def arccos_(self, *args, **kwargs) -> Any: ...
    def arccosh(self, *args, **kwargs) -> Any: ...
    def arccosh_(self, *args, **kwargs) -> Any: ...
    def arcsin(self, *args, **kwargs) -> Any: ...
    def arcsin_(self, *args, **kwargs) -> Any: ...
    def arcsinh(self, *args, **kwargs) -> Any: ...
    def arcsinh_(self, *args, **kwargs) -> Any: ...
    def arctan(self, *args, **kwargs) -> Any: ...
    def arctan2(self, *args, **kwargs) -> Any: ...
    def arctan_(self, *args, **kwargs) -> Any: ...
    def arctanh(self, *args, **kwargs) -> Any: ...
    def arctanh_(self, *args, **kwargs) -> Any: ...
    def argmax(self, *args, **kwargs) -> Any: ...
    def argmin(self, *args, **kwargs) -> Any: ...
    def argsort(self, *args, **kwargs) -> Any: ...
    def argwhere(self, *args, **kwargs) -> Any: ...
    def as_strided(self, *args, **kwargs) -> Any: ...
    def as_strided_(self, *args, **kwargs) -> Any: ...
    def as_strided_copy(self, *args, **kwargs) -> Any: ...
    def as_tensor(self, *args, **kwargs) -> Any: ...
    def asarray(self, *args, **kwargs) -> Any: ...
    def asin(self, *args, **kwargs) -> Any: ...
    def asin_(self, *args, **kwargs) -> Any: ...
    def asinh(self, *args, **kwargs) -> Any: ...
    def asinh_(self, *args, **kwargs) -> Any: ...
    def atan(self, *args, **kwargs) -> Any: ...
    def atan2(self, *args, **kwargs) -> Any: ...
    def atan_(self, *args, **kwargs) -> Any: ...
    def atanh(self, *args, **kwargs) -> Any: ...
    def atanh_(self, *args, **kwargs) -> Any: ...
    def atleast_1d(self, *args, **kwargs) -> Any: ...
    def atleast_2d(self, *args, **kwargs) -> Any: ...
    def atleast_3d(self, *args, **kwargs) -> Any: ...
    def avg_pool1d(self, *args, **kwargs) -> Any: ...
    def baddbmm(self, *args, **kwargs) -> Any: ...
    def bartlett_window(self, *args, **kwargs) -> Any: ...
    def batch_norm(self, *args, **kwargs) -> Any: ...
    def batch_norm_backward_elemt(self, *args, **kwargs) -> Any: ...
    def batch_norm_backward_reduce(self, *args, **kwargs) -> Any: ...
    def batch_norm_elemt(self, *args, **kwargs) -> Any: ...
    def batch_norm_gather_stats(self, *args, **kwargs) -> Any: ...
    def batch_norm_gather_stats_with_counts(self, *args, **kwargs) -> Any: ...
    def batch_norm_stats(self, *args, **kwargs) -> Any: ...
    def batch_norm_update_stats(self, *args, **kwargs) -> Any: ...
    def bernoulli(self, *args, **kwargs) -> Any: ...
    def bilinear(self, *args, **kwargs) -> Any: ...
    def binary_cross_entropy_with_logits(self, *args, **kwargs) -> Any: ...
    def bincount(self, *args, **kwargs) -> Any: ...
    def binomial(self, *args, **kwargs) -> Any: ...
    def bitwise_and(self, *args, **kwargs) -> Any: ...
    def bitwise_left_shift(self, *args, **kwargs) -> Any: ...
    def bitwise_not(self, *args, **kwargs) -> Any: ...
    def bitwise_or(self, *args, **kwargs) -> Any: ...
    def bitwise_right_shift(self, *args, **kwargs) -> Any: ...
    def bitwise_xor(self, *args, **kwargs) -> Any: ...
    def blackman_window(self, *args, **kwargs) -> Any: ...
    def block_diag(self, *args, **kwargs) -> Any: ...
    def bmm(self, *args, **kwargs) -> Any: ...
    def broadcast_tensors(self, *args, **kwargs) -> Any: ...
    def broadcast_to(self, *args, **kwargs) -> Any: ...
    def bucketize(self, *args, **kwargs) -> Any: ...
    def can_cast(self, *args, **kwargs) -> Any: ...
    def cartesian_prod(self, *args, **kwargs) -> Any: ...
    def cat(self, *args, **kwargs) -> Any: ...
    def ccol_indices_copy(self, *args, **kwargs) -> Any: ...
    def cdist(self, *args, **kwargs) -> Any: ...
    def ceil(self, *args, **kwargs) -> Any: ...
    def ceil_(self, *args, **kwargs) -> Any: ...
    def celu(self, *args, **kwargs) -> Any: ...
    def celu_(self, *args, **kwargs) -> Any: ...
    def chain_matmul(self, *args, **kwargs) -> Any: ...
    def channel_shuffle(self, *args, **kwargs) -> Any: ...
    def cholesky(self, *args, **kwargs) -> Any: ...
    def cholesky_inverse(self, *args, **kwargs) -> Any: ...
    def cholesky_solve(self, *args, **kwargs) -> Any: ...
    def choose_qparams_optimized(self, *args, **kwargs) -> Any: ...
    def chunk(self, *args, **kwargs) -> Any: ...
    def clamp(self, *args, **kwargs) -> Any: ...
    def clamp_(self, *args, **kwargs) -> Any: ...
    def clamp_max(self, *args, **kwargs) -> Any: ...
    def clamp_max_(self, *args, **kwargs) -> Any: ...
    def clamp_min(self, *args, **kwargs) -> Any: ...
    def clamp_min_(self, *args, **kwargs) -> Any: ...
    def clip(self, *args, **kwargs) -> Any: ...
    def clip_(self, *args, **kwargs) -> Any: ...
    def clone(self, *args, **kwargs) -> Any: ...
    def col_indices_copy(self, *args, **kwargs) -> Any: ...
    def column_stack(self, *args, **kwargs) -> Any: ...
    def combinations(self, *args, **kwargs) -> Any: ...
    def complex(self, *args, **kwargs) -> Any: ...
    def concat(self, *args, **kwargs) -> Any: ...
    def conj(self, *args, **kwargs) -> Any: ...
    def conj_physical(self, *args, **kwargs) -> Any: ...
    def conj_physical_(self, *args, **kwargs) -> Any: ...
    def constant_pad_nd(self, *args, **kwargs) -> Any: ...
    def conv1d(self, *args, **kwargs) -> Any: ...
    def conv2d(self, *args, **kwargs) -> Any: ...
    def conv3d(self, *args, **kwargs) -> Any: ...
    def conv_tbc(self, *args, **kwargs) -> Any: ...
    def conv_transpose1d(self, *args, **kwargs) -> Any: ...
    def conv_transpose2d(self, *args, **kwargs) -> Any: ...
    def conv_transpose3d(self, *args, **kwargs) -> Any: ...
    def convolution(self, *args, **kwargs) -> Any: ...
    def copysign(self, *args, **kwargs) -> Any: ...
    def corrcoef(self, *args, **kwargs) -> Any: ...
    def cos(self, *args, **kwargs) -> Any: ...
    def cos_(self, *args, **kwargs) -> Any: ...
    def cosh(self, *args, **kwargs) -> Any: ...
    def cosh_(self, *args, **kwargs) -> Any: ...
    def cosine_embedding_loss(self, *args, **kwargs) -> Any: ...
    def cosine_similarity(self, *args, **kwargs) -> Any: ...
    def count_nonzero(self, *args, **kwargs) -> Any: ...
    def cov(self, *args, **kwargs) -> Any: ...
    def cross(self, *args, **kwargs) -> Any: ...
    def crow_indices_copy(self, *args, **kwargs) -> Any: ...
    def ctc_loss(self, *args, **kwargs) -> Any: ...
    def cudnn_affine_grid_generator(self, *args, **kwargs) -> Any: ...
    def cudnn_batch_norm(self, *args, **kwargs) -> Any: ...
    def cudnn_convolution(self, *args, **kwargs) -> Any: ...
    def cudnn_convolution_add_relu(self, *args, **kwargs) -> Any: ...
    def cudnn_convolution_relu(self, *args, **kwargs) -> Any: ...
    def cudnn_convolution_transpose(self, *args, **kwargs) -> Any: ...
    def cudnn_grid_sampler(self, *args, **kwargs) -> Any: ...
    def cudnn_is_acceptable(self, *args, **kwargs) -> Any: ...
    def cummax(self, *args, **kwargs) -> Any: ...
    def cummin(self, *args, **kwargs) -> Any: ...
    def cumprod(self, *args, **kwargs) -> Any: ...
    def cumsum(self, *args, **kwargs) -> Any: ...
    def cumulative_trapezoid(self, *args, **kwargs) -> Any: ...
    def deg2rad(self, *args, **kwargs) -> Any: ...
    def deg2rad_(self, *args, **kwargs) -> Any: ...
    def dequantize(self, *args, **kwargs) -> Any: ...
    def det(self, *args, **kwargs) -> Any: ...
    def detach(self, *args, **kwargs) -> Any: ...
    def detach_(self, *args, **kwargs) -> Any: ...
    def detach_copy(self, *args, **kwargs) -> Any: ...
    def diag(self, *args, **kwargs) -> Any: ...
    def diag_embed(self, *args, **kwargs) -> Any: ...
    def diagflat(self, *args, **kwargs) -> Any: ...
    def diagonal(self, *args, **kwargs) -> Any: ...
    def diagonal_copy(self, *args, **kwargs) -> Any: ...
    def diagonal_scatter(self, *args, **kwargs) -> Any: ...
    def diff(self, *args, **kwargs) -> Any: ...
    def digamma(self, *args, **kwargs) -> Any: ...
    def dist(self, *args, **kwargs) -> Any: ...
    def div(self, *args, **kwargs) -> Any: ...
    def divide(self, *args, **kwargs) -> Any: ...
    def dot(self, *args, **kwargs) -> Any: ...
    def dropout(self, *args, **kwargs) -> Any: ...
    def dropout_(self, *args, **kwargs) -> Any: ...
    def dsmm(self, *args, **kwargs) -> Any: ...
    def dsplit(self, *args, **kwargs) -> Any: ...
    def dstack(self, *args, **kwargs) -> Any: ...
    def eig(self, *args, **kwargs) -> Any: ...
    def einsum(self, *args, **kwargs) -> Any: ...
    def embedding(self, *args, **kwargs) -> Any: ...
    def embedding_bag(self, *args, **kwargs) -> Any: ...
    def embedding_renorm_(self, *args, **kwargs) -> Any: ...
    def empty(self, *args, **kwargs) -> Any: ...
    def empty_like(self, *args, **kwargs) -> Any: ...
    def empty_quantized(self, *args, **kwargs) -> Any: ...
    def empty_strided(self, *args, **kwargs) -> Any: ...
    def eq(self, *args, **kwargs) -> Any: ...
    def equal(self, *args, **kwargs) -> Any: ...
    def erf(self, *args, **kwargs) -> Any: ...
    def erf_(self, *args, **kwargs) -> Any: ...
    def erfc(self, *args, **kwargs) -> Any: ...
    def erfc_(self, *args, **kwargs) -> Any: ...
    def erfinv(self, *args, **kwargs) -> Any: ...
    def exp(self, *args, **kwargs) -> Any: ...
    def exp2(self, *args, **kwargs) -> Any: ...
    def exp2_(self, *args, **kwargs) -> Any: ...
    def exp_(self, *args, **kwargs) -> Any: ...
    def expand_copy(self, *args, **kwargs) -> Any: ...
    def expm1(self, *args, **kwargs) -> Any: ...
    def expm1_(self, *args, **kwargs) -> Any: ...
    def eye(self, *args, **kwargs) -> Any: ...
    def fake_quantize_per_channel_affine(self, *args, **kwargs) -> Any: ...
    def fake_quantize_per_tensor_affine(self, *args, **kwargs) -> Any: ...
    def fbgemm_linear_fp16_weight(self, *args, **kwargs) -> Any: ...

    def fbgemm_linear_fp16_weight_fp32_activation(
        self, *args, **kwargs) -> Any: ...

    def fbgemm_linear_int8_weight(self, *args, **kwargs) -> Any: ...

    def fbgemm_linear_int8_weight_fp32_activation(
        self, *args, **kwargs) -> Any: ...

    def fbgemm_linear_quantize_weight(self, *args, **kwargs) -> Any: ...
    def fbgemm_pack_gemm_matrix_fp16(self, *args, **kwargs) -> Any: ...
    def fbgemm_pack_quantized_matrix(self, *args, **kwargs) -> Any: ...
    def feature_alpha_dropout(self, *args, **kwargs) -> Any: ...
    def feature_alpha_dropout_(self, *args, **kwargs) -> Any: ...
    def feature_dropout(self, *args, **kwargs) -> Any: ...
    def feature_dropout_(self, *args, **kwargs) -> Any: ...
    def fill(self, *args, **kwargs) -> Any: ...
    def fill_(self, *args, **kwargs) -> Any: ...
    def fix(self, *args, **kwargs) -> Any: ...
    def fix_(self, *args, **kwargs) -> Any: ...
    def flatten(self, *args, **kwargs) -> Any: ...
    def flip(self, *args, **kwargs) -> Any: ...
    def fliplr(self, *args, **kwargs) -> Any: ...
    def flipud(self, *args, **kwargs) -> Any: ...
    def float_power(self, *args, **kwargs) -> Any: ...
    def floor(self, *args, **kwargs) -> Any: ...
    def floor_(self, *args, **kwargs) -> Any: ...
    def floor_divide(self, *args, **kwargs) -> Any: ...
    def fmax(self, *args, **kwargs) -> Any: ...
    def fmin(self, *args, **kwargs) -> Any: ...
    def fmod(self, *args, **kwargs) -> Any: ...
    def frac(self, *args, **kwargs) -> Any: ...
    def frac_(self, *args, **kwargs) -> Any: ...
    def frexp(self, *args, **kwargs) -> Any: ...
    def frobenius_norm(self, *args, **kwargs) -> Any: ...
    def from_file(self, *args, **kwargs) -> Any: ...
    def from_numpy(self, *args, **kwargs) -> Any: ...
    def frombuffer(self, *args, **kwargs) -> Any: ...
    def full(self, *args, **kwargs) -> Any: ...
    def full_like(self, *args, **kwargs) -> Any: ...
    def fused_moving_avg_obs_fake_quant(self, *args, **kwargs) -> Any: ...
    def gather(self, *args, **kwargs) -> Any: ...
    def gcd(self, *args, **kwargs) -> Any: ...
    def gcd_(self, *args, **kwargs) -> Any: ...
    def ge(self, *args, **kwargs) -> Any: ...
    def geqrf(self, *args, **kwargs) -> Any: ...
    def ger(self, *args, **kwargs) -> Any: ...
    def get_device(self, *args, **kwargs) -> Any: ...
    def gradient(self, *args, **kwargs) -> Any: ...
    def greater(self, *args, **kwargs) -> Any: ...
    def greater_equal(self, *args, **kwargs) -> Any: ...
    def grid_sampler(self, *args, **kwargs) -> Any: ...
    def grid_sampler_2d(self, *args, **kwargs) -> Any: ...
    def grid_sampler_3d(self, *args, **kwargs) -> Any: ...
    def group_norm(self, *args, **kwargs) -> Any: ...
    def gru(self, *args, **kwargs) -> Any: ...
    def gru_cell(self, *args, **kwargs) -> Any: ...
    def gt(self, *args, **kwargs) -> Any: ...
    def hamming_window(self, *args, **kwargs) -> Any: ...
    def hann_window(self, *args, **kwargs) -> Any: ...
    def hardshrink(self, *args, **kwargs) -> Any: ...
    def heaviside(self, *args, **kwargs) -> Any: ...
    def hinge_embedding_loss(self, *args, **kwargs) -> Any: ...
    def histc(self, *args, **kwargs) -> Any: ...
    def histogram(self, *args, **kwargs) -> Any: ...
    def histogramdd(self, *args, **kwargs) -> Any: ...
    def hsmm(self, *args, **kwargs) -> Any: ...
    def hsplit(self, *args, **kwargs) -> Any: ...
    def hspmm(self, *args, **kwargs) -> Any: ...
    def hstack(self, *args, **kwargs) -> Any: ...
    def hypot(self, *args, **kwargs) -> Any: ...
    def i0(self, *args, **kwargs) -> Any: ...
    def i0_(self, *args, **kwargs) -> Any: ...
    def igamma(self, *args, **kwargs) -> Any: ...
    def igammac(self, *args, **kwargs) -> Any: ...
    def imag(self, *args, **kwargs) -> Any: ...
    def index_add(self, *args, **kwargs) -> Any: ...
    def index_copy(self, *args, **kwargs) -> Any: ...
    def index_fill(self, *args, **kwargs) -> Any: ...
    def index_put(self, *args, **kwargs) -> Any: ...
    def index_put_(self, *args, **kwargs) -> Any: ...
    def index_reduce(self, *args, **kwargs) -> Any: ...
    def index_select(self, *args, **kwargs) -> Any: ...
    def indices_copy(self, *args, **kwargs) -> Any: ...
    def inner(self, *args, **kwargs) -> Any: ...
    def instance_norm(self, *args, **kwargs) -> Any: ...
    def int_repr(self, *args, **kwargs) -> Any: ...
    def inverse(self, *args, **kwargs) -> Any: ...
    def is_complex(self, *args, **kwargs) -> Any: ...
    def is_conj(self, *args, **kwargs) -> Any: ...
    def is_distributed(self, *args, **kwargs) -> Any: ...
    def is_floating_point(self, *args, **kwargs) -> Any: ...
    def is_inference(self, *args, **kwargs) -> Any: ...
    def is_neg(self, *args, **kwargs) -> Any: ...
    def is_nonzero(self, *args, **kwargs) -> Any: ...
    def is_same_size(self, *args, **kwargs) -> Any: ...
    def is_signed(self, *args, **kwargs) -> Any: ...
    def is_vulkan_available(self, *args, **kwargs) -> Any: ...
    def isclose(self, *args, **kwargs) -> Any: ...
    def isfinite(self, *args, **kwargs) -> Any: ...
    def isin(self, *args, **kwargs) -> Any: ...
    def isinf(self, *args, **kwargs) -> Any: ...
    def isnan(self, *args, **kwargs) -> Any: ...
    def isneginf(self, *args, **kwargs) -> Any: ...
    def isposinf(self, *args, **kwargs) -> Any: ...
    def isreal(self, *args, **kwargs) -> Any: ...
    def istft(self, *args, **kwargs) -> Any: ...
    def kaiser_window(self, *args, **kwargs) -> Any: ...
    def kl_div(self, *args, **kwargs) -> Any: ...
    def kron(self, *args, **kwargs) -> Any: ...
    def kthvalue(self, *args, **kwargs) -> Any: ...
    def layer_norm(self, *args, **kwargs) -> Any: ...
    def lcm(self, *args, **kwargs) -> Any: ...
    def lcm_(self, *args, **kwargs) -> Any: ...
    def ldexp(self, *args, **kwargs) -> Any: ...
    def ldexp_(self, *args, **kwargs) -> Any: ...
    def le(self, *args, **kwargs) -> Any: ...
    def lerp(self, *args, **kwargs) -> Any: ...
    def less(self, *args, **kwargs) -> Any: ...
    def less_equal(self, *args, **kwargs) -> Any: ...
    def lgamma(self, *args, **kwargs) -> Any: ...
    def linspace(self, *args, **kwargs) -> Any: ...
    def log(self, *args, **kwargs) -> Any: ...
    def log10(self, *args, **kwargs) -> Any: ...
    def log10_(self, *args, **kwargs) -> Any: ...
    def log1p(self, *args, **kwargs) -> Any: ...
    def log1p_(self, *args, **kwargs) -> Any: ...
    def log2(self, *args, **kwargs) -> Any: ...
    def log2_(self, *args, **kwargs) -> Any: ...
    def log_(self, *args, **kwargs) -> Any: ...
    def log_softmax(self, *args, **kwargs) -> Any: ...
    def logaddexp(self, *args, **kwargs) -> Any: ...
    def logaddexp2(self, *args, **kwargs) -> Any: ...
    def logcumsumexp(self, *args, **kwargs) -> Any: ...
    def logdet(self, *args, **kwargs) -> Any: ...
    def logical_and(self, *args, **kwargs) -> Any: ...
    def logical_not(self, *args, **kwargs) -> Any: ...
    def logical_or(self, *args, **kwargs) -> Any: ...
    def logical_xor(self, *args, **kwargs) -> Any: ...
    def logit(self, *args, **kwargs) -> Any: ...
    def logit_(self, *args, **kwargs) -> Any: ...
    def logspace(self, *args, **kwargs) -> Any: ...
    def logsumexp(self, *args, **kwargs) -> Any: ...
    def lstm(self, *args, **kwargs) -> Any: ...
    def lstm_cell(self, *args, **kwargs) -> Any: ...
    def lstsq(self, *args, **kwargs) -> Any: ...
    def lt(self, *args, **kwargs) -> Any: ...
    def lu_solve(self, *args, **kwargs) -> Any: ...
    def lu_unpack(self, *args, **kwargs) -> Any: ...
    def margin_ranking_loss(self, *args, **kwargs) -> Any: ...
    def masked_fill(self, *args, **kwargs) -> Any: ...
    def masked_scatter(self, *args, **kwargs) -> Any: ...
    def masked_select(self, *args, **kwargs) -> Any: ...
    def matmul(self, *args, **kwargs) -> Any: ...
    def matrix_exp(self, *args, **kwargs) -> Any: ...
    def matrix_power(self, *args, **kwargs) -> Any: ...
    def matrix_rank(self, *args, **kwargs) -> Any: ...
    def max(self, *args, **kwargs) -> Any: ...
    def max_pool1d(self, *args, **kwargs) -> Any: ...
    def max_pool1d_with_indices(self, *args, **kwargs) -> Any: ...
    def max_pool2d(self, *args, **kwargs) -> Any: ...
    def max_pool3d(self, *args, **kwargs) -> Any: ...
    def maximum(self, *args, **kwargs) -> Any: ...
    def mean(self, *args, **kwargs) -> Any: ...
    def median(self, *args, **kwargs) -> Any: ...
    def meshgrid(self, *args, **kwargs) -> Any: ...
    def min(self, *args, **kwargs) -> Any: ...
    def minimum(self, *args, **kwargs) -> Any: ...
    def miopen_batch_norm(self, *args, **kwargs) -> Any: ...
    def miopen_convolution(self, *args, **kwargs) -> Any: ...
    def miopen_convolution_transpose(self, *args, **kwargs) -> Any: ...
    def miopen_depthwise_convolution(self, *args, **kwargs) -> Any: ...
    def miopen_rnn(self, *args, **kwargs) -> Any: ...
    def mkldnn_adaptive_avg_pool2d(self, *args, **kwargs) -> Any: ...
    def mkldnn_convolution(self, *args, **kwargs) -> Any: ...
    def mkldnn_linear_backward_weights(self, *args, **kwargs) -> Any: ...
    def mkldnn_max_pool2d(self, *args, **kwargs) -> Any: ...
    def mkldnn_max_pool3d(self, *args, **kwargs) -> Any: ...
    def mm(self, *args, **kwargs) -> Any: ...
    def mode(self, *args, **kwargs) -> Any: ...
    def moveaxis(self, *args, **kwargs) -> Any: ...
    def movedim(self, *args, **kwargs) -> Any: ...
    def msort(self, *args, **kwargs) -> Any: ...
    def mul(self, *args, **kwargs) -> Any: ...
    def multinomial(self, *args, **kwargs) -> Any: ...
    def multiply(self, *args, **kwargs) -> Any: ...
    def mv(self, *args, **kwargs) -> Any: ...
    def mvlgamma(self, *args, **kwargs) -> Any: ...
    def nan_to_num(self, *args, **kwargs) -> Any: ...
    def nan_to_num_(self, *args, **kwargs) -> Any: ...
    def nanmean(self, *args, **kwargs) -> Any: ...
    def nanmedian(self, *args, **kwargs) -> Any: ...
    def nanquantile(self, *args, **kwargs) -> Any: ...
    def nansum(self, *args, **kwargs) -> Any: ...
    def narrow(self, *args, **kwargs) -> Any: ...
    def narrow_copy(self, *args, **kwargs) -> Any: ...
    def native_batch_norm(self, *args, **kwargs) -> Any: ...
    def native_channel_shuffle(self, *args, **kwargs) -> Any: ...
    def native_dropout(self, *args, **kwargs) -> Any: ...
    def native_group_norm(self, *args, **kwargs) -> Any: ...
    def native_layer_norm(self, *args, **kwargs) -> Any: ...
    def native_norm(self, *args, **kwargs) -> Any: ...
    def ne(self, *args, **kwargs) -> Any: ...
    def neg(self, *args, **kwargs) -> Any: ...
    def neg_(self, *args, **kwargs) -> Any: ...
    def negative(self, *args, **kwargs) -> Any: ...
    def negative_(self, *args, **kwargs) -> Any: ...
    def nested_tensor(self, *args, **kwargs) -> Any: ...
    def nextafter(self, *args, **kwargs) -> Any: ...
    def nonzero(self, *args, **kwargs) -> Any: ...
    def norm(self, *args, **kwargs) -> Any: ...
    def norm_except_dim(self, *args, **kwargs) -> Any: ...
    def normal(self, *args, **kwargs) -> Any: ...
    def not_equal(self, *args, **kwargs) -> Any: ...
    def nuclear_norm(self, *args, **kwargs) -> Any: ...
    def numel(self, *args, **kwargs) -> Any: ...
    def ones(self, *args, **kwargs) -> Any: ...
    def ones_like(self, *args, **kwargs) -> Any: ...
    def orgqr(self, *args, **kwargs) -> Any: ...
    def ormqr(self, *args, **kwargs) -> Any: ...
    def outer(self, *args, **kwargs) -> Any: ...
    def pairwise_distance(self, *args, **kwargs) -> Any: ...
    def pdist(self, *args, **kwargs) -> Any: ...
    def permute(self, *args, **kwargs) -> Any: ...
    def permute_copy(self, *args, **kwargs) -> Any: ...
    def pinverse(self, *args, **kwargs) -> Any: ...
    def pixel_shuffle(self, *args, **kwargs) -> Any: ...
    def pixel_unshuffle(self, *args, **kwargs) -> Any: ...
    def poisson(self, *args, **kwargs) -> Any: ...
    def poisson_nll_loss(self, *args, **kwargs) -> Any: ...
    def polar(self, *args, **kwargs) -> Any: ...
    def polygamma(self, *args, **kwargs) -> Any: ...
    def positive(self, *args, **kwargs) -> Any: ...
    def pow(self, *args, **kwargs) -> Any: ...
    def prelu(self, *args, **kwargs) -> Any: ...
    def prod(self, *args, **kwargs) -> Any: ...
    def promote_types(self, *args, **kwargs) -> Any: ...
    def put(self, *args, **kwargs) -> Any: ...
    def q_per_channel_axis(self, *args, **kwargs) -> Any: ...
    def q_per_channel_scales(self, *args, **kwargs) -> Any: ...
    def q_per_channel_zero_points(self, *args, **kwargs) -> Any: ...
    def q_scale(self, *args, **kwargs) -> Any: ...
    def q_zero_point(self, *args, **kwargs) -> Any: ...
    def qr(self, *args, **kwargs) -> Any: ...
    def quantile(self, *args, **kwargs) -> Any: ...
    def quantize_per_channel(self, *args, **kwargs) -> Any: ...
    def quantize_per_tensor(self, *args, **kwargs) -> Any: ...
    def quantize_per_tensor_dynamic(self, *args, **kwargs) -> Any: ...
    def quantized_batch_norm(self, *args, **kwargs) -> Any: ...
    def quantized_gru_cell(self, *args, **kwargs) -> Any: ...
    def quantized_lstm_cell(self, *args, **kwargs) -> Any: ...
    def quantized_max_pool1d(self, *args, **kwargs) -> Any: ...
    def quantized_max_pool2d(self, *args, **kwargs) -> Any: ...
    def quantized_rnn_relu_cell(self, *args, **kwargs) -> Any: ...
    def quantized_rnn_tanh_cell(self, *args, **kwargs) -> Any: ...
    def rad2deg(self, *args, **kwargs) -> Any: ...
    def rad2deg_(self, *args, **kwargs) -> Any: ...
    def rand(self, *args, **kwargs) -> Any: ...
    def rand_like(self, *args, **kwargs) -> Any: ...
    def randint(self, *args, **kwargs) -> Any: ...
    def randint_like(self, *args, **kwargs) -> Any: ...
    def randn(self, *args, **kwargs) -> Any: ...
    def randn_like(self, *args, **kwargs) -> Any: ...
    def randperm(self, *args, **kwargs) -> Any: ...
    def range(self, *args, **kwargs) -> Any: ...
    def ravel(self, *args, **kwargs) -> Any: ...
    def real(self, *args, **kwargs) -> Any: ...
    def reciprocal(self, *args, **kwargs) -> Any: ...
    def reciprocal_(self, *args, **kwargs) -> Any: ...
    def relu(self, *args, **kwargs) -> Any: ...
    def relu_(self, *args, **kwargs) -> Any: ...
    def remainder(self, *args, **kwargs) -> Any: ...
    def renorm(self, *args, **kwargs) -> Any: ...
    def repeat_interleave(self, *args, **kwargs) -> Any: ...
    def reshape(self, *args, **kwargs) -> Any: ...
    def resize_as_(self, *args, **kwargs) -> Any: ...
    def resize_as_sparse_(self, *args, **kwargs) -> Any: ...
    def resolve_conj(self, *args, **kwargs) -> Any: ...
    def resolve_neg(self, *args, **kwargs) -> Any: ...
    def result_type(self, *args, **kwargs) -> Any: ...
    def rnn_relu(self, *args, **kwargs) -> Any: ...
    def rnn_relu_cell(self, *args, **kwargs) -> Any: ...
    def rnn_tanh(self, *args, **kwargs) -> Any: ...
    def rnn_tanh_cell(self, *args, **kwargs) -> Any: ...
    def roll(self, *args, **kwargs) -> Any: ...
    def rot90(self, *args, **kwargs) -> Any: ...
    def round(self, *args, **kwargs) -> Any: ...
    def round_(self, *args, **kwargs) -> Any: ...
    def row_indices_copy(self, *args, **kwargs) -> Any: ...
    def row_stack(self, *args, **kwargs) -> Any: ...
    def rrelu(self, *args, **kwargs) -> Any: ...
    def rrelu_(self, *args, **kwargs) -> Any: ...
    def rsqrt(self, *args, **kwargs) -> Any: ...
    def rsqrt_(self, *args, **kwargs) -> Any: ...
    def rsub(self, *args, **kwargs) -> Any: ...
    def saddmm(self, *args, **kwargs) -> Any: ...
    def scalar_tensor(self, *args, **kwargs) -> Any: ...
    def scatter(self, *args, **kwargs) -> Any: ...
    def scatter_add(self, *args, **kwargs) -> Any: ...
    def scatter_reduce(self, *args, **kwargs) -> Any: ...
    def searchsorted(self, *args, **kwargs) -> Any: ...
    def segment_reduce(self, *args, **kwargs) -> Any: ...
    def select(self, *args, **kwargs) -> Any: ...
    def select_copy(self, *args, **kwargs) -> Any: ...
    def select_scatter(self, *args, **kwargs) -> Any: ...
    def selu(self, *args, **kwargs) -> Any: ...
    def selu_(self, *args, **kwargs) -> Any: ...
    def sgn(self, *args, **kwargs) -> Any: ...
    def sigmoid(self, *args, **kwargs) -> Any: ...
    def sigmoid_(self, *args, **kwargs) -> Any: ...
    def sign(self, *args, **kwargs) -> Any: ...
    def signbit(self, *args, **kwargs) -> Any: ...
    def sin(self, *args, **kwargs) -> Any: ...
    def sin_(self, *args, **kwargs) -> Any: ...
    def sinc(self, *args, **kwargs) -> Any: ...
    def sinc_(self, *args, **kwargs) -> Any: ...
    def sinh(self, *args, **kwargs) -> Any: ...
    def sinh_(self, *args, **kwargs) -> Any: ...
    def slice_copy(self, *args, **kwargs) -> Any: ...
    def slice_scatter(self, *args, **kwargs) -> Any: ...
    def slogdet(self, *args, **kwargs) -> Any: ...
    def smm(self, *args, **kwargs) -> Any: ...
    def softmax(self, *args, **kwargs) -> Any: ...
    def sort(self, *args, **kwargs) -> Any: ...
    def sparse_bsc_tensor(self, *args, **kwargs) -> Any: ...
    def sparse_bsr_tensor(self, *args, **kwargs) -> Any: ...
    def sparse_compressed_tensor(self, *args, **kwargs) -> Any: ...
    def sparse_coo_tensor(self, *args, **kwargs) -> Any: ...
    def sparse_csc_tensor(self, *args, **kwargs) -> Any: ...
    def sparse_csr_tensor(self, *args, **kwargs) -> Any: ...
    def split(self, *args, **kwargs) -> Any: ...
    def split_copy(self, *args, **kwargs) -> Any: ...
    def split_with_sizes(self, *args, **kwargs) -> Any: ...
    def split_with_sizes_copy(self, *args, **kwargs) -> Any: ...
    def spmm(self, *args, **kwargs) -> Any: ...
    def sqrt(self, *args, **kwargs) -> Any: ...
    def sqrt_(self, *args, **kwargs) -> Any: ...
    def square(self, *args, **kwargs) -> Any: ...
    def square_(self, *args, **kwargs) -> Any: ...
    def squeeze(self, *args, **kwargs) -> Any: ...
    def squeeze_copy(self, *args, **kwargs) -> Any: ...
    def sspaddmm(self, *args, **kwargs) -> Any: ...
    def stack(self, *args, **kwargs) -> Any: ...
    def std(self, *args, **kwargs) -> Any: ...
    def std_mean(self, *args, **kwargs) -> Any: ...
    def stft(self, *args, **kwargs) -> Any: ...
    def sub(self, *args, **kwargs) -> Any: ...
    def subtract(self, *args, **kwargs) -> Any: ...
    def sum(self, *args, **kwargs) -> Any: ...
    def svd(self, *args, **kwargs) -> Any: ...
    def swapaxes(self, *args, **kwargs) -> Any: ...
    def swapdims(self, *args, **kwargs) -> Any: ...
    def symeig(self, *args, **kwargs) -> Any: ...
    def t(self, *args, **kwargs) -> Any: ...
    def t_copy(self, *args, **kwargs) -> Any: ...
    def take(self, *args, **kwargs) -> Any: ...
    def take_along_dim(self, *args, **kwargs) -> Any: ...
    def tan(self, *args, **kwargs) -> Any: ...
    def tan_(self, *args, **kwargs) -> Any: ...
    def tanh(self, *args, **kwargs) -> Any: ...
    def tanh_(self, *args, **kwargs) -> Any: ...
    def tensor(self, *args, **kwargs) -> Any: ...
    def tensor_split(self, *args, **kwargs) -> Any: ...
    def tensordot(self, *args, **kwargs) -> Any: ...
    def threshold(self, *args, **kwargs) -> Any: ...
    def threshold_(self, *args, **kwargs) -> Any: ...
    def tile(self, *args, **kwargs) -> Any: ...
    def topk(self, *args, **kwargs) -> Any: ...
    def trace(self, *args, **kwargs) -> Any: ...
    def transpose(self, *args, **kwargs) -> Any: ...
    def transpose_copy(self, *args, **kwargs) -> Any: ...
    def trapezoid(self, *args, **kwargs) -> Any: ...
    def trapz(self, *args, **kwargs) -> Any: ...
    def triangular_solve(self, *args, **kwargs) -> Any: ...
    def tril(self, *args, **kwargs) -> Any: ...
    def tril_indices(self, *args, **kwargs) -> Any: ...
    def triplet_margin_loss(self, *args, **kwargs) -> Any: ...
    def triu(self, *args, **kwargs) -> Any: ...
    def triu_indices(self, *args, **kwargs) -> Any: ...
    def true_divide(self, *args, **kwargs) -> Any: ...
    def trunc(self, *args, **kwargs) -> Any: ...
    def trunc_(self, *args, **kwargs) -> Any: ...
    def unbind(self, *args, **kwargs) -> Any: ...
    def unbind_copy(self, *args, **kwargs) -> Any: ...
    def unfold_copy(self, *args, **kwargs) -> Any: ...
    def unique_consecutive(self, *args, **kwargs) -> Any: ...
    def unique_dim(self, *args, **kwargs) -> Any: ...
    def unsafe_chunk(self, *args, **kwargs) -> Any: ...
    def unsafe_split(self, *args, **kwargs) -> Any: ...
    def unsafe_split_with_sizes(self, *args, **kwargs) -> Any: ...
    def unsqueeze(self, *args, **kwargs) -> Any: ...
    def unsqueeze_copy(self, *args, **kwargs) -> Any: ...
    def values_copy(self, *args, **kwargs) -> Any: ...
    def vander(self, *args, **kwargs) -> Any: ...
    def var(self, *args, **kwargs) -> Any: ...
    def var_mean(self, *args, **kwargs) -> Any: ...
    def vdot(self, *args, **kwargs) -> Any: ...
    def view_as_complex(self, *args, **kwargs) -> Any: ...
    def view_as_complex_copy(self, *args, **kwargs) -> Any: ...
    def view_as_real(self, *args, **kwargs) -> Any: ...
    def view_as_real_copy(self, *args, **kwargs) -> Any: ...
    def view_copy(self, *args, **kwargs) -> Any: ...
    def vsplit(self, *args, **kwargs) -> Any: ...
    def vstack(self, *args, **kwargs) -> Any: ...
    def where(self, *args, **kwargs) -> Any: ...
    def xlogy(self, *args, **kwargs) -> Any: ...
    def xlogy_(self, *args, **kwargs) -> Any: ...
    def zero_(self, *args, **kwargs) -> Any: ...
    def zeros(self, *args, **kwargs) -> Any: ...
    def zeros_like(self, *args, **kwargs) -> Any: ...
    def __and__(self, other) -> Any: ...
    def __lshift__(self, other) -> Any: ...
    def __or__(self, other) -> Any: ...
    def __rshift__(self, other) -> Any: ...
    def __xor__(self, other) -> Any: ...


class _WeakTensorRef:
    def __init__(self, arg0: object) -> None: ...
    def expired(self) -> bool: ...


class _cuda_isCurrentStreamCapturing:
    __init__: ClassVar[function] = ...


class _graph_pool_handle:
    __init__: ClassVar[function] = ...


class device:
    index: Any
    type: Any
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def __eq__(self, other) -> Any: ...
    def __ge__(self, other) -> Any: ...
    def __gt__(self, other) -> Any: ...
    def __hash__(self) -> Any: ...
    def __le__(self, other) -> Any: ...
    def __lt__(self, other) -> Any: ...
    def __ne__(self, other) -> Any: ...
    def __reduce__(self) -> Any: ...


class dtype:
    is_complex: Any
    is_floating_point: Any
    is_signed: Any
    def __reduce__(self) -> Any: ...


class finfo:
    __hash__: ClassVar[None] = ...
    bits: Any
    dtype: Any
    eps: Any
    max: Any
    min: Any
    resolution: Any
    smallest_normal: Any
    tiny: Any
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def __eq__(self, other) -> Any: ...
    def __ge__(self, other) -> Any: ...
    def __gt__(self, other) -> Any: ...
    def __le__(self, other) -> Any: ...
    def __lt__(self, other) -> Any: ...
    def __ne__(self, other) -> Any: ...


class iinfo:
    __hash__: ClassVar[None] = ...
    bits: Any
    dtype: Any
    max: Any
    min: Any
    @classmethod
    def __init__(cls, *args, **kwargs) -> None: ...
    def __eq__(self, other) -> Any: ...
    def __ge__(self, other) -> Any: ...
    def __gt__(self, other) -> Any: ...
    def __le__(self, other) -> Any: ...
    def __lt__(self, other) -> Any: ...
    def __ne__(self, other) -> Any: ...


class layout:
    ...


class memory_format:
    ...


class qscheme:
    def __reduce__(self) -> Any: ...


def _add_docstr(*args, **kwargs) -> Any: ...


def _autograd_init(*args, **kwargs) -> Any: ...


def _backport_for_mobile(arg0: str, arg1: str, arg2: int) -> bool: ...


def _backport_for_mobile_from_buffer(
    arg0: str, arg1: str, arg2: int) -> bool: ...


def _backport_for_mobile_from_buffer_to_buffer(
    arg0: str, arg1: int) -> bytes: ...


def _backport_for_mobile_to_buffer(arg0: str, arg1: int) -> bytes: ...


def _calculate_package_version_based_on_upgraders(arg0: bool) -> None: ...


def _check_onnx_proto(proto_string: str, full_check: bool = ...) -> None: ...


def _collect_all(arg0: List[Future]) -> Future: ...


def _compile_graph_to_code_table(arg0: str, arg1: Graph) -> IValue: ...


def _crash_if_aten_asan(*args, **kwargs) -> Any: ...


def _crash_if_csrc_asan(*args, **kwargs) -> Any: ...


def _crash_if_csrc_ubsan(*args, **kwargs) -> Any: ...


def _create_function_from_graph(arg0: str, arg1: Graph) -> ScriptFunction: ...


def _create_function_from_trace(
    name: str, func: function, input_tuple: tuple,
    var_name_lookup_fn: function, strict: bool, force_outplace: bool,
    argument_names: List[str] = ...) -> ScriptFunction: ...


def _create_graph_by_tracing(
    func: function, inputs: List[IValue], var_name_lookup_fn: function,
    strict: bool, force_outplace: bool, self = ...,
    argument_names: List[str] = ...) -> Tuple[Graph,List[IValue]]: ...


def _create_module_with_type(arg0: ClassType) -> ScriptModule: ...


def _create_object_with_type(arg0: ClassType) -> ScriptObject: ...


def _cxx_flags(*args, **kwargs) -> Any: ...


def _debug_get_fusion_group_inlining() -> bool: ...


def _debug_only_are_vmap_fallback_warnings_enabled(*args, **kwargs) -> Any: ...


def _debug_only_display_vmap_fallback_warnings(*args, **kwargs) -> Any: ...


def _debug_set_autodiff_subgraph_inlining(arg0: bool) -> None: ...


def _debug_set_fusion_group_inlining(arg0: bool) -> None: ...


def _demangle(arg0: str) -> str: ...


def _disabled_torch_dispatch_impl(*args, **kwargs) -> Any: ...


def _disabled_torch_function_impl(*args, **kwargs) -> Any: ...


def _dispatch_check_all_invariants() -> None: ...


def _dispatch_check_invariants(arg0: str) -> None: ...


def _dispatch_dump(arg0: str) -> str: ...


def _dispatch_dump_table(arg0: str) -> str: ...


def _dispatch_find_dangling_impls() -> List[str]: ...


def _dispatch_has_kernel(arg0: str) -> bool: ...


def _dispatch_has_kernel_for_dispatch_key(arg0: str, arg1: str) -> bool: ...


def _dispatch_library(
    kind: str, name: str, dispatch: str, file: str = ...,
    linenum: int = ...) -> _DispatchModule: ...


def _dispatch_print_registrations_for_dispatch_key(
    dispatch_key: str = ...) -> None: ...


def _dump_upgraders_map() -> Dict[str,Graph]: ...


def _enable_mobile_interface_call_export() -> None: ...


def _enter_dual_level(*args, **kwargs) -> Any: ...


def _error_if_any_worker_fails(*args, **kwargs) -> Any: ...


def _exit_dual_level(*args, **kwargs) -> Any: ...


def _export_operator_list(arg0: LiteScriptModule) -> set: ...


def _export_opnames(arg0: ScriptModule) -> list: ...


def _freeze_module(*args, **kwargs) -> Any: ...


def _from_dlpack(*args, **kwargs) -> Any: ...


@overload
def _fuse_to_static_module(
    module: ScriptModule, min_size: int = ...) -> None: ...


@overload
def _fuse_to_static_module(graph: Graph, min_size: int = ...) -> None: ...


def _generate_upgraders_graph() -> Dict[str,Graph]: ...


def _get_backcompat_broadcast_warn(*args, **kwargs) -> Any: ...


def _get_backcompat_keepdim_warn(*args, **kwargs) -> Any: ...


def _get_caught_jit_exception_class_name() -> str: ...


def _get_caught_jit_exception_original_msg() -> str: ...


def _get_cublas_allow_fp16_reduced_precision_reduction(
    *args, **kwargs) -> Any: ...


def _get_cublas_allow_tf32(*args, **kwargs) -> Any: ...


def _get_cudnn_allow_tf32(*args, **kwargs) -> Any: ...


def _get_cudnn_benchmark(*args, **kwargs) -> Any: ...


def _get_cudnn_deterministic(*args, **kwargs) -> Any: ...


def _get_cudnn_enabled(*args, **kwargs) -> Any: ...


def _get_custom_class_python_wrapper(arg0: str, arg1: str) -> ScriptClass: ...


def _get_default_device(*args, **kwargs) -> Any: ...


def _get_deterministic_algorithms(*args, **kwargs) -> Any: ...


def _get_deterministic_algorithms_warn_only(*args, **kwargs) -> Any: ...


def _get_file_format(arg0: str) -> str: ...


def _get_float32_matmul_precision(*args, **kwargs) -> Any: ...


def _get_graph_executor_optimize(
    new_settings: Optional[bool] = ...) -> bool: ...


def _get_linalg_preferred_backend() -> _LinalgBackend: ...


def _get_max_operator_version() -> int: ...


def _get_mkldnn_enabled(*args, **kwargs) -> Any: ...


def _get_mobile_model_contained_types(arg0: str) -> Set[str]: ...


def _get_mobile_model_contained_types_from_buffer(arg0: str) -> Set[str]: ...


def _get_model_bytecode_version(arg0: str) -> int: ...


def _get_model_bytecode_version_from_buffer(arg0: str) -> int: ...


def _get_model_ops_and_info(arg0: str) -> Dict[str,OperatorInfo]: ...


def _get_model_ops_and_info_from_buffer(
    arg0: str) -> Dict[str,OperatorInfo]: ...


def _get_operation_overload(arg0: str, arg1: str) -> cpp_function: ...


def _get_operator_version_map() -> Dict[str,List[_UpgraderEntry]]: ...


def _get_qengine(*args, **kwargs) -> Any: ...


def _get_schema(*args, **kwargs) -> Any: ...


def _get_torch_dispatch_mode(*args, **kwargs) -> Any: ...


def _get_torch_function_mode(*args, **kwargs) -> Any: ...


def _get_tracing_state() -> TracingState: ...


def _get_upgrader_ranges(arg0: str) -> List[_UpgraderRange]: ...


def _get_upgraders_map_size() -> int: ...


def _get_value_trace(arg0) -> Value: ...


def _get_version_calculator_flag() -> bool: ...


def _get_warnAlways(*args, **kwargs) -> Any: ...


def _hack_do_not_use_clone_module_with_class(*args, **kwargs) -> Any: ...


def _has_distributed(*args, **kwargs) -> Any: ...


def _has_tensorexpr_cpp_tests() -> bool: ...


def _has_torch_function(*args, **kwargs) -> Any: ...


def _has_torch_function_unary(*args, **kwargs) -> Any: ...


def _has_torch_function_variadic(*args, **kwargs) -> Any: ...


def _import_ir_module_from_package(
    arg0: CompilationUnit, arg1: PyTorchFileReader,
    arg2: DeserializationStorageContext, arg3: object,
    arg4: str) -> ScriptModule: ...


def _infer_size(*args, **kwargs) -> Any: ...


def _initExtension(*args, **kwargs) -> Any: ...


def _init_names(*args, **kwargs) -> Any: ...


def _is_mps_available() -> bool: ...


def _is_torch_function_enabled(*args, **kwargs) -> Any: ...


def _is_tracing() -> bool: ...


def _is_upgraders_enabled() -> bool: ...


def _is_xnnpack_enabled(*args, **kwargs) -> Any: ...


def _ivalue_debug_python_object(arg0: object) -> object: ...


def _ivalue_tags_match(arg0: ScriptModule, arg1: ScriptModule) -> bool: ...


def _jit_assert_is_instance(arg0: object, arg1) -> None: ...


def _jit_can_fuse_on_cpu() -> bool: ...


def _jit_can_fuse_on_cpu_legacy() -> bool: ...


def _jit_can_fuse_on_gpu() -> bool: ...


def _jit_cat_wo_conditionals(arg0: bool) -> None: ...


def _jit_check_alias_annotation(arg0, arg1: tuple, arg2: str) -> None: ...


def _jit_clear_class_registry() -> None: ...


def _jit_debug_fuser_num_cached_kernel_specs() -> int: ...


def _jit_debug_module_iterators(arg0: ScriptModule) -> dict: ...


def _jit_decay_packed_param_input_types(arg0) -> None: ...


def _jit_decomposition_graph_for_node(*args, **kwargs) -> Any: ...


def _jit_differentiate(*args, **kwargs) -> Any: ...


def _jit_erase_non_input_shape_information(arg0) -> None: ...


def _jit_flatten(*args, **kwargs) -> Any: ...


def _jit_fuser_get_fused_kernel_code(arg0, arg1) -> str: ...


def _jit_get_all_schemas() -> List[FunctionSchema]: ...


def _jit_get_custom_class_schemas() -> List[FunctionSchema]: ...


def _jit_get_emit_hooks(
    ) -> Tuple[Callable[[ScriptModule],None],Callable[[ScriptFunction],
        None]]: ...


def _jit_get_inline_everything_mode() -> bool: ...


def _jit_get_logging_option() -> str: ...


def _jit_get_num_profiled_runs() -> int: ...


def _jit_get_operation(qualified_name: str) -> tuple: ...


def _jit_get_schemas_for_operator(arg0: str) -> List[FunctionSchema]: ...


def _jit_get_te_cuda_pointwise_block_count() -> int: ...


def _jit_get_te_cuda_pointwise_block_size() -> int: ...


def _jit_get_te_cuda_pointwise_loop_levels() -> int: ...


def _jit_get_te_generate_block_code() -> bool: ...


def _jit_get_te_must_use_llvm_cpu() -> bool: ...


def _jit_has_cpp_tests() -> bool: ...


def _jit_init() -> bool: ...


def _jit_interpret_graph(arg0, arg1: tuple) -> object: ...


def _jit_is_onnx_log_enabled() -> bool: ...


def _jit_is_script_object(arg0: object) -> bool: ...


def _jit_nvfuser_clear_comparison_callback() -> None: ...


def _jit_nvfuser_enabled() -> bool: ...


def _jit_nvfuser_horizontal_mode() -> bool: ...


def _jit_nvfuser_set_comparison_callback(
    arg0: bool, arg1: function) -> None: ...


def _jit_nvfuser_single_node_mode() -> bool: ...


def _jit_object_is_non_holding(arg0) -> bool: ...


def _jit_onnx_convert_pattern_from_subblock(*args, **kwargs) -> Any: ...


def _jit_onnx_list_model_parameters(*args, **kwargs) -> Any: ...


def _jit_onnx_log(*args) -> None: ...


def _jit_opt_conditionals(arg0: bool) -> None: ...


def _jit_override_can_fuse_on_cpu(arg0: bool) -> None: ...


def _jit_override_can_fuse_on_cpu_legacy(arg0: bool) -> None: ...


def _jit_override_can_fuse_on_gpu(arg0: bool) -> None: ...


def _jit_pass_autocast(arg0) -> None: ...


def _jit_pass_batch_mm(arg0) -> None: ...


def _jit_pass_canonicalize(*args, **kwargs) -> Any: ...


def _jit_pass_canonicalize_graph_fuser_ops(arg0) -> None: ...


def _jit_pass_complete_shape_analysis(
    arg0, arg1: tuple, arg2: bool) -> None: ...


def _jit_pass_concat_frozen_linear(arg0) -> bool: ...


def _jit_pass_constant_loop_unrolling(arg0) -> bool: ...


def _jit_pass_constant_pooling(arg0) -> None: ...


def _jit_pass_constant_propagation(graph) -> bool: ...


def _jit_pass_constant_propagation_immutable_types(arg0) -> bool: ...


def _jit_pass_convert_frozen_ops_to_mkldnn(arg0) -> None: ...


def _jit_pass_create_autodiff_subgraphs(
    graph, threshold: object = ...) -> None: ...


def _jit_pass_create_functional_graphs(arg0) -> None: ...


def _jit_pass_cse(arg0) -> bool: ...


def _jit_pass_custom_pattern_based_rewrite(
    arg0: str, arg1: str, arg2) -> None: ...


def _jit_pass_custom_pattern_based_rewrite_graph(
    pattern: str, fused_node_name: str, g, value_name_pairs: List[Tuple[str,
    str]] = ...) -> None: ...


def _jit_pass_dbr_quant_remove_redundant_aliases(*args, **kwargs) -> Any: ...


def _jit_pass_dce(arg0) -> None: ...


def _jit_pass_dce_allow_deleting_nodes_with_side_effects(arg0) -> None: ...


def _jit_pass_decompose_ops(arg0) -> None: ...


def _jit_pass_dedup_module_uses(arg0) -> None: ...


def _jit_pass_erase_number_types(arg0) -> None: ...


def _jit_pass_erase_shape_information(arg0) -> None: ...


def _jit_pass_filter_non_tensor_arguments(*args, **kwargs) -> Any: ...


def _jit_pass_fixup_onnx_controlflow_node(*args, **kwargs) -> Any: ...


def _jit_pass_fold_convbn(*args, **kwargs) -> Any: ...


def _jit_pass_fold_frozen_conv_add_or_sub(arg0) -> bool: ...


def _jit_pass_fold_frozen_conv_bn(arg0) -> bool: ...


def _jit_pass_fold_frozen_conv_mul_or_div(arg0) -> bool: ...


def _jit_pass_fold_prepacking_ops(arg0) -> None: ...


def _jit_pass_functional_to_inplace_activation(arg0) -> bool: ...


def _jit_pass_fuse(arg0, arg1: bool) -> None: ...


def _jit_pass_fuse_add_relu(arg0) -> None: ...


def _jit_pass_fuse_addmm(arg0) -> bool: ...


def _jit_pass_fuse_clamp_w_prepacked_linear_conv(arg0) -> None: ...


def _jit_pass_fuse_frozen_conv_add_relu(arg0) -> None: ...


def _jit_pass_fuse_linear(arg0) -> None: ...


def _jit_pass_fuse_quantized_add_relu(arg0) -> None: ...


def _jit_pass_fuse_tensorexprs(arg0) -> None: ...


def _jit_pass_inline(arg0) -> None: ...


def _jit_pass_inline_fork_wait(arg0) -> None: ...


def _jit_pass_inline_functional_graphs(arg0) -> None: ...


def _jit_pass_inplace_to_functional_activation(arg0) -> bool: ...


def _jit_pass_insert_observers(*args, **kwargs) -> Any: ...


@overload
def _jit_pass_insert_prepack_unpack(arg0) -> None: ...


@overload
def _jit_pass_insert_prepack_unpack(arg0) -> None: ...


@overload
def _jit_pass_insert_prepacked_ops(arg0) -> None: ...


@overload
def _jit_pass_insert_prepacked_ops(arg0) -> None: ...


def _jit_pass_insert_quant_dequant(*args, **kwargs) -> Any: ...


def _jit_pass_integer_value_refinement(arg0) -> bool: ...


def _jit_pass_lint(arg0) -> None: ...


def _jit_pass_loop_unrolling(arg0) -> bool: ...


def _jit_pass_lower_all_tuples(arg0) -> None: ...


def _jit_pass_lower_graph(*args, **kwargs) -> Any: ...


def _jit_pass_metal_fold_prepacking_ops(arg0) -> None: ...


def _jit_pass_metal_fuse_clamp_w_prepacked_conv(arg0) -> None: ...


@overload
def _jit_pass_metal_insert_prepacked_ops(arg0) -> None: ...


@overload
def _jit_pass_metal_insert_prepacked_ops(arg0) -> None: ...


def _jit_pass_metal_optimize_for_mobile(*args, **kwargs) -> Any: ...


def _jit_pass_onnx(*args, **kwargs) -> Any: ...


def _jit_pass_onnx_assign_output_shape(
    arg0, arg1, arg2, arg3: bool, arg4: bool) -> None: ...


def _jit_pass_onnx_block(*args, **kwargs) -> Any: ...


def _jit_pass_onnx_cast_all_constant_to_floating(arg0) -> None: ...


def _jit_pass_onnx_clear_scope_records() -> None: ...


def _jit_pass_onnx_constant_fold(
    arg0, arg1: Dict[str,IValue], arg2: int) -> Dict[str,IValue]: ...


def _jit_pass_onnx_deduplicate_initializers(
    arg0, arg1: Dict[str,IValue], arg2: bool) -> Dict[str,IValue]: ...


def _jit_pass_onnx_eliminate_unused_items(
    arg0, arg1: Dict[str,IValue]) -> Dict[str,IValue]: ...


def _jit_pass_onnx_eval_peephole(
    arg0, arg1: Dict[str,IValue]) -> Dict[str,IValue]: ...


def _jit_pass_onnx_function_extraction(*args, **kwargs) -> Any: ...


def _jit_pass_onnx_function_substitution(arg0) -> None: ...


def _jit_pass_onnx_graph_shape_type_inference(
    arg0, arg1: Dict[str,IValue], arg2: int) -> None: ...


def _jit_pass_onnx_lint(arg0) -> None: ...


def _jit_pass_onnx_node_shape_type_inference(
    arg0, arg1: Dict[str,IValue], arg2: int) -> None: ...


def _jit_pass_onnx_peephole(arg0, arg1: int, arg2: bool) -> None: ...


def _jit_pass_onnx_preprocess(arg0) -> None: ...


def _jit_pass_onnx_preprocess_caffe2(arg0) -> None: ...


def _jit_pass_onnx_quantization_insert_permutes(
    arg0, arg1: Dict[str,IValue]) -> Dict[str,IValue]: ...


def _jit_pass_onnx_remove_inplace_ops_for_onnx(arg0, arg1) -> None: ...


def _jit_pass_onnx_remove_print(arg0) -> None: ...


def _jit_pass_onnx_scalar_type_analysis(
    graph, lowprecision_cast: bool = ..., opset_version: int) -> None: ...


def _jit_pass_onnx_set_dynamic_input_shape(
    arg0, arg1: Dict[str,Dict[int,str]], arg2: List[str]) -> None: ...


def _jit_pass_onnx_track_scope_attributes(
    arg0, arg1: Dict[str,IValue]) -> None: ...


def _jit_pass_onnx_unpack_quantized_weights(
    arg0, arg1: Dict[str,IValue], arg2: bool) -> Dict[str,IValue]: ...


def _jit_pass_optimize_for_inference(
    module, other_methods: List[str] = ...) -> None: ...


def _jit_pass_optimize_for_mobile(*args, **kwargs) -> Any: ...


def _jit_pass_optimize_frozen_graph(arg0, arg1: bool) -> None: ...


def _jit_pass_pattern_based_rewrite(*args, **kwargs) -> Any: ...


def _jit_pass_peephole(graph, disable_shape_peepholes: bool = ...) -> bool: ...


def _jit_pass_peephole_list_idioms(
    graph, refine_list_len: bool = ...) -> bool: ...


def _jit_pass_prepare_division_for_onnx(arg0) -> None: ...


def _jit_pass_propagate_device(arg0) -> bool: ...


def _jit_pass_propagate_dtype(arg0) -> bool: ...


def _jit_pass_propagate_shapes_on_graph(arg0) -> None: ...


def _jit_pass_propagate_shapes_on_graph_and_build_compute(
    *args, **kwargs) -> Any: ...


def _jit_pass_quant_finalize(*args, **kwargs) -> Any: ...


def _jit_pass_quant_fusion(arg0) -> None: ...


def _jit_pass_refine_integer_values(arg0) -> bool: ...


def _jit_pass_refine_tuple_types(arg0) -> None: ...


def _jit_pass_remove_dropout(arg0) -> None: ...


def _jit_pass_remove_expands(arg0) -> None: ...


def _jit_pass_remove_inplace_ops(arg0) -> None: ...


def _jit_pass_remove_mutation(arg0) -> bool: ...


def _jit_pass_replace_old_ops_with_upgraders(arg0) -> None: ...


def _jit_pass_replicate_dequantize(arg0) -> None: ...


def _jit_pass_run_decompositions(arg0) -> None: ...


def _jit_pass_specialize_autogradzero(arg0) -> None: ...


@overload
def _jit_pass_swap_functional_linear(arg0) -> None: ...


@overload
def _jit_pass_swap_functional_linear(arg0) -> None: ...


@overload
def _jit_pass_transform_conv1d_to_conv2d(arg0) -> None: ...


@overload
def _jit_pass_transform_conv1d_to_conv2d(arg0) -> None: ...


def _jit_pass_transpose_frozen_linear(arg0) -> bool: ...


def _jit_pass_vulkan_fold_prepacking_ops(arg0) -> None: ...


def _jit_pass_vulkan_fuse_clamp_w_prepacked_conv(arg0) -> None: ...


@overload
def _jit_pass_vulkan_insert_prepacked_ops(arg0) -> None: ...


@overload
def _jit_pass_vulkan_insert_prepacked_ops(arg0) -> None: ...


def _jit_pass_vulkan_optimize_for_mobile(*args, **kwargs) -> Any: ...


def _jit_register_decomposition_for_schema(arg0, arg1) -> None: ...


def _jit_register_shape_compute_graph_for_node(arg0, arg1) -> None: ...


def _jit_run_cpp_tests() -> None: ...


def _jit_script_class_compile(
    arg0: str, arg1: _jit_tree_views.ClassDef, arg2: Dict[str,Dict[str,
    object]], arg3: Callable[[str],object]) -> ClassType: ...


def _jit_script_compile(
    arg0: str, arg1: _jit_tree_views.Def, arg2: Callable[[str],object],
    arg3: Dict[str,object]) -> ScriptFunction: ...


def _jit_script_compile_overload(
    arg0: str, arg1: _jit_tree_views.Decl, arg2: _jit_tree_views.Def,
    arg3: Callable[[str],object], arg4: Dict[str,object],
    arg5: object) -> ScriptFunction: ...


def _jit_script_interface_compile(
    arg0: str, arg1: _jit_tree_views.ClassDef, arg2: Callable[[str],object],
    arg3: bool) -> str: ...


def _jit_set_autocast_mode(arg0: bool) -> bool: ...


def _jit_set_bailout_depth(arg0: int) -> int: ...


def _jit_set_emit_hooks(
    arg0: Callable[[ScriptModule],None], arg1: Callable[[ScriptFunction],
    None]) -> None: ...


def _jit_set_fusion_strategy(
    arg0: List[Tuple[str,int]]) -> List[Tuple[str,int]]: ...


def _jit_set_inline_everything_mode(arg0: bool) -> None: ...


def _jit_set_logging_option(arg0: str) -> None: ...


def _jit_set_logging_stream(arg0: str) -> None: ...


def _jit_set_num_profiled_runs(arg0: int) -> int: ...


def _jit_set_nvfuser_enabled(arg0: bool) -> bool: ...


def _jit_set_nvfuser_guard_mode(arg0: bool) -> bool: ...


def _jit_set_nvfuser_horizontal_mode(arg0: bool) -> bool: ...


def _jit_set_nvfuser_single_node_mode(arg0: bool) -> bool: ...


def _jit_set_nvfuser_skip_node_kind(arg0: str, arg1: bool) -> bool: ...


def _jit_set_onnx_log_enabled(arg0: bool) -> None: ...


def _jit_set_onnx_log_output_stream(arg0: str) -> None: ...


def _jit_set_profiling_executor(arg0: bool) -> bool: ...


def _jit_set_profiling_mode(arg0: bool) -> bool: ...


def _jit_set_symbolic_shapes_test_mode(arg0: bool) -> bool: ...


def _jit_set_te_cuda_pointwise_block_count(arg0: int) -> int: ...


def _jit_set_te_cuda_pointwise_block_size(arg0: int) -> int: ...


def _jit_set_te_cuda_pointwise_loop_levels(arg0: int) -> int: ...


def _jit_set_te_generate_block_code(arg0: bool) -> bool: ...


def _jit_set_te_must_use_llvm_cpu(arg0: bool) -> None: ...


def _jit_set_texpr_dynamic_shape_enabled(arg0: bool) -> None: ...


def _jit_set_texpr_fuser_enabled(arg0: bool) -> None: ...


def _jit_set_texpr_reductions_enabled(arg0: bool) -> bool: ...


def _jit_shape_compute_graph_for_node(*args, **kwargs) -> Any: ...


def _jit_symbolic_shapes_test_mode_enabled() -> bool: ...


def _jit_texpr_dynamic_shape_enabled() -> bool: ...


def _jit_texpr_fallback_allowed() -> bool: ...


def _jit_texpr_fuser_enabled() -> bool: ...


def _jit_texpr_reductions_enabled() -> bool: ...


def _jit_texpr_set_fallback_allowed(arg0: bool) -> bool: ...


def _jit_to_backend(arg0: str, arg1: handle, arg2: dict) -> object: ...


def _jit_to_backend_selective(
    arg0: handle, arg1: function, arg2: List[str]) -> object: ...


@overload
def _jit_to_static_module(arg0: Graph) -> StaticModule: ...


@overload
def _jit_to_static_module(arg0: ScriptModule) -> StaticModule: ...


def _jit_trace_graph(*args, **kwargs) -> Any: ...


def _jit_trace_module(arg0, arg1: tuple) -> None: ...


def _jit_try_infer_type(*args, **kwargs) -> Any: ...


def _jit_unflatten(arg0, arg1: IODescriptor) -> object: ...


def _last_executed_optimized_graph() -> Graph: ...


def _llvm_enabled() -> bool: ...


def _load_for_lite_interpreter(
    arg0: str, arg1: object) -> LiteScriptModule: ...


def _load_for_lite_interpreter_from_buffer(
    arg0: str, arg1: object) -> LiteScriptModule: ...


def _log_api_usage_once(arg0: str) -> None: ...


def _logging_set_logger(*args, **kwargs) -> Any: ...


def _multiprocessing_init(*args, **kwargs) -> Any: ...


def _new_symbolic_shape_symbol() -> int: ...


def _nn_module_to_mobile(arg0: ScriptModule) -> LiteScriptModule: ...


def _parallel_info(*args, **kwargs) -> Any: ...


def _parse_source_def(arg0: str) -> _jit_tree_views.Def: ...


def _propagate_and_assign_input_shapes(
    arg0: Graph, arg1, arg2: List[int], arg3: bool, arg4: bool) -> Graph: ...


def _propagate_shapes(arg0: Graph, arg1, arg2: bool) -> Graph: ...


def _register_py_class_for_device(arg0: str, arg1: object) -> None: ...


def _remove_worker_pids(*args, **kwargs) -> Any: ...


def _replace_overloaded_method_decl(
    arg0: _jit_tree_views.Decl, arg1: _jit_tree_views.Def,
    arg2: str) -> _jit_tree_views.Def: ...


def _resolve_type(
    arg0: str, arg1: _jit_tree_views.SourceRange, arg2: Callable[[str],
    object]) -> Type: ...


def _resolve_type_from_object(
    arg0: object, arg1: _jit_tree_views.SourceRange, arg2: Callable[[str],
    object]) -> Type: ...


def _run_emit_module_hook(arg0: ScriptModule) -> None: ...


def _run_tensorexpr_cpp_tests() -> None: ...


def _select_conv_backend(
    arg0, arg1, arg2, arg3, arg4, arg5, arg6: bool, arg7,
    arg8: int) -> _ConvBackend: ...


def _set_backcompat_broadcast_warn(*args, **kwargs) -> Any: ...


def _set_backcompat_keepdim_warn(*args, **kwargs) -> Any: ...


def _set_conj(arg0, arg1: bool) -> None: ...


def _set_cublas_allow_fp16_reduced_precision_reduction(
    *args, **kwargs) -> Any: ...


def _set_cublas_allow_tf32(*args, **kwargs) -> Any: ...


def _set_cudnn_allow_tf32(*args, **kwargs) -> Any: ...


def _set_cudnn_benchmark(*args, **kwargs) -> Any: ...


def _set_cudnn_deterministic(*args, **kwargs) -> Any: ...


def _set_cudnn_enabled(*args, **kwargs) -> Any: ...


def _set_default_dtype(*args, **kwargs) -> Any: ...


def _set_default_mobile_cpu_allocator(*args, **kwargs) -> Any: ...


def _set_default_tensor_type(*args, **kwargs) -> Any: ...


def _set_deterministic_algorithms(*args, **kwargs) -> Any: ...


def _set_float32_matmul_precision(*args, **kwargs) -> Any: ...


def _set_grad_enabled(*args, **kwargs) -> Any: ...


def _set_graph_executor_optimize(arg0: bool) -> None: ...


def _set_linalg_preferred_backend(arg0: _LinalgBackend) -> None: ...


def _set_mkldnn_enabled(*args, **kwargs) -> Any: ...


def _set_neg(arg0, arg1: bool) -> None: ...


def _set_qengine(*args, **kwargs) -> Any: ...


def _set_should_use_format_with_string_table(arg0: bool) -> None: ...


def _set_torch_dispatch_mode(*args, **kwargs) -> Any: ...


def _set_torch_function_mode(*args, **kwargs) -> Any: ...


def _set_tracing_state(arg0: TracingState) -> None: ...


def _set_value_trace(arg0, arg1: Value) -> None: ...


def _set_warnAlways(*args, **kwargs) -> Any: ...


def _set_worker_pids(*args, **kwargs) -> Any: ...


def _set_worker_signal_handlers(*args, **kwargs) -> Any: ...


def _show_config(*args, **kwargs) -> Any: ...


def _supported_qengines(*args, **kwargs) -> Any: ...


def _tensor_impl_raw_handle(arg0) -> capsule: ...


def _test_only_add_entry_to_op_version_map(
    arg0: str, arg1: _UpgraderEntry) -> None: ...


def _test_only_populate_upgraders(arg0: Dict[str,str]) -> None: ...


def _test_only_remove_entry_to_op_version_map(arg0: str) -> None: ...


def _test_only_remove_upgraders(arg0: Dict[str,str]) -> None: ...


def _to_dlpack(*args, **kwargs) -> Any: ...


def _tracer_set_force_outplace(arg0: bool) -> None: ...


def _tracer_set_get_unique_name_fn(arg0: function) -> None: ...


def _tracer_warn_use_python() -> None: ...


def _unset_default_mobile_cpu_allocator(*args, **kwargs) -> Any: ...


def _valgrind_supported_platform() -> bool: ...


def _valgrind_toggle() -> None: ...


def _valgrind_toggle_and_dump_stats() -> None: ...


def _vmapmode_decrement_nesting(*args, **kwargs) -> Any: ...


def _vmapmode_increment_nesting(*args, **kwargs) -> Any: ...


def _wrap_tensor_impl(arg0: capsule) -> object: ...


def autocast_decrement_nesting(*args, **kwargs) -> Any: ...


def autocast_increment_nesting(*args, **kwargs) -> Any: ...


def clear_autocast_cache(*args, **kwargs) -> Any: ...


def fork(*args, **kwargs) -> Future: ...


def get_autocast_cpu_dtype(*args, **kwargs) -> Any: ...


def get_autocast_gpu_dtype(*args, **kwargs) -> Any: ...


@overload
def get_default_dtype() -> torch.dtype: ...


@overload
def get_default_dtype() -> Any: ...


@overload
def get_default_dtype() -> Any: ...


@overload
def get_default_dtype() -> Any: ...


def get_num_interop_threads() -> int: ...


def get_num_threads() -> int: ...


def import_ir_module(
    arg0: CompilationUnit, arg1: str, arg2: object,
    arg3: dict) -> ScriptModule: ...


def import_ir_module_from_buffer(
    arg0: CompilationUnit, arg1: str, arg2: object,
    arg3: dict) -> ScriptModule: ...


@overload
def init_num_threads() -> None: ...


@overload
def init_num_threads() -> Any: ...


def is_anomaly_enabled(*args, **kwargs) -> Any: ...


def is_autocast_cache_enabled(*args, **kwargs) -> Any: ...


def is_autocast_cpu_enabled(*args, **kwargs) -> Any: ...


def is_autocast_enabled(*args, **kwargs) -> Any: ...


def is_grad_enabled(*args, **kwargs) -> Any: ...


def is_inference_mode_enabled(*args, **kwargs) -> Any: ...


def merge_type_from_type_comment(
    arg0: _jit_tree_views.Decl, arg1: _jit_tree_views.Decl,
    arg2: bool) -> _jit_tree_views.Decl: ...


def parse_ir(*args, **kwargs) -> Any: ...


def parse_schema(*args, **kwargs) -> Any: ...


def parse_type_comment(arg0: str) -> _jit_tree_views.Decl: ...


def read_vitals() -> str: ...


def set_anomaly_enabled(*args, **kwargs) -> Any: ...


def set_autocast_cache_enabled(*args, **kwargs) -> Any: ...


def set_autocast_cpu_dtype(*args, **kwargs) -> Any: ...


def set_autocast_cpu_enabled(*args, **kwargs) -> Any: ...


def set_autocast_enabled(*args, **kwargs) -> Any: ...


def set_autocast_gpu_dtype(*args, **kwargs) -> Any: ...


@overload
def set_flush_denormal(mode) -> bool: ...


@overload
def set_flush_denormal(True) -> Any: ...


@overload
def set_flush_denormal(False) -> Any: ...


def set_num_interop_threads(int) -> Any: ...


def set_num_threads(int) -> Any: ...


def set_vital(arg0: str, arg1: str, arg2: str) -> bool: ...


def unify_type_list(*args, **kwargs) -> Any: ...


def vitals_enabled() -> bool: ...


def wait(arg0: Future) -> object: ...
